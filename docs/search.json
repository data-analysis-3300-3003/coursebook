[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "coursebook",
    "section": "",
    "text": "This is the online course book for Advanced Spatial Analysis (3300) and Decisions from Data in Agriculture (3003).\nThere are rapid changes in data science and technology/sensors that are driving change across the environmental and agricultural sectors. This unit focuses on student learning through practical and applied laboratories, using Python, and collecting field data using uncrewed aerial vehicles (UAVs). Students will develop skills to manipulate, transform, analyse, and visualise big spatial and non-spatial data to provide solutions to the big landscape and agricultural questions.\nThis course will teach students foundational skills and knowledge required to implement spatial and non-spatial data analysis workflows programmatically, to handle and analyse “big” data, and to operate in cloud-based environments.\nThere are three overarching themes are:\n\nProgramming: analysis doesn’t scale without code, programming skills are required to use many software packages and tools for spatial data analysis.\nBig data: various sensors are generating databases that are growing in size and variety. Increasingly specialist software and data formats are required to handle big data.\nCloud-based environments: it’s easier to move the question to the data than to make big data mobile. Data and computer processing are often located on remote computers - we need to know how to get there.\n\n\n\nThe course outline is loosely based on the stages of a data science workflow from Wickham and Grolemund (2022) with a focus on practical geospatial data wrangling and analysis skills relevant to each stage.\n\n\n\nTwo computer labs per week unless otherwise indicated in the schedule.\n\nOne instructor-led lab.\nOne self-guided lab."
  },
  {
    "objectID": "unit-overview.html",
    "href": "unit-overview.html",
    "title": "Unit overview",
    "section": "",
    "text": "Python and programming concepts\nAn introduction to (Python) programming concepts including data types, data structures, flow control, and classes and objects. This lab will demonstrate how these concepts can be used to create Python programs that achieve data handling, analysis, and visualisation tasks. You will be working with crop yield data collected by a harvester from a field in Western Australia."
  },
  {
    "objectID": "unit-overview.html#week-2",
    "href": "unit-overview.html#week-2",
    "title": "Unit overview",
    "section": "Week 2",
    "text": "Week 2\nData I/O and geospatial data I/O\nAn introduction to file formats for tabular, vector, and raster data; best practice for reading and writing spatial and non-spatial data in Python programs; navigating directories and file systems; and, identifying suitable file formats for different tasks and use cases. You will be working with crop yield data collected by a harvester from a field in Western Australia.\n\nInstructor-led lab: Reading and writing files in Python.\nSelf-guided lab: Reading and writing geospatial data in Python.\nPractice exercise: Reading and visualising vector data layers of the disaster impact caused by Tropical Cyclone Yasa which struck Fiji in 2020."
  },
  {
    "objectID": "unit-overview.html#week-3",
    "href": "unit-overview.html#week-3",
    "title": "Unit overview",
    "section": "Week 3",
    "text": "Week 3\nData visualisation and exploratory data analysis\nUsing wheat and canola crop yield data collected by a harvester from a field in Western Australia, you will learn how to generate interactive visualisations of this data, generate different figures to explore the dataset’s structure and relationships between variables, use colour to highlight features and patterns in the dataset, and learn techniques to identify and remove noisy or error values.\n\nInstructor-led lab: Interactive data visualisation in Python.\nSelf-guided lab: Exploratory data analysis and data cleaning.\nPractice exercise: Generate interactive data visualisations and animations to explore how closing yield gaps can reduce cropland expansion and habitat loss. Based on thei Our World In Data article: To protect the world’s wildlife we must improve crop yields – especially across Africa."
  },
  {
    "objectID": "unit-overview.html#week-4",
    "href": "unit-overview.html#week-4",
    "title": "Unit overview",
    "section": "Week 4",
    "text": "Week 4\nData transformation and wrangling\nYou will learn how to implement non-spatial and spatial data transformation operations to tabular, vector, and raster data. The week’s labs will demonstrate how to combine these data transformation operations in a Python program to automate the process of transforming a large amount of geospatial data spread across many files into a tabular dataset ready for analysis. You will be working with data from a subset of the AgriFieldNet Competition Dataset (Radiant Earth Foundation and IDinsight, 2022) which has been published to encourage people to develop machine learning models that classify a field’s crop type from satellite images in India.\n\nInstructor-led lab: Raster data transformation.\nSelf-guided lab: Vector and tabular data transformation.\nPractice exercise: Demonstration of geometry operations and zonal statistics to compute the mean NDVI of sample polygons of locations impacted and not impacted by Tropical Cyclone Yasa on Vanua Levu, Fiji."
  },
  {
    "objectID": "unit-overview.html#week-5",
    "href": "unit-overview.html#week-5",
    "title": "Unit overview",
    "section": "Week 5",
    "text": "Week 5\nIntroduction to machine learning\nAn introduction to machine learning concepts and workflows, how to implement a machine learning workflow in Python, and considerations for machine learning with spatial data. You will implement two machine learning tasks. First, you will use the AgriFieldNet Competition Dataset (Radiant Earth Foundation and IDinsight, 2022) dataset to develop a crop type classifier for fields in India using Sentinel-2 remote sensing data. Second, you will develop a model to predict maize crop yields in Uganda with Sentinel-2 remote sensing data using the replication data from Lobell et al. (2019).\n\nInstructor-led lab: Introduction to machine learning with Python - classifying crop type in India.\nSelf-guided lab: Model evaluation and interpretation - predicting crop yields in Uganda."
  },
  {
    "objectID": "unit-overview.html#week-6",
    "href": "unit-overview.html#week-6",
    "title": "Unit overview",
    "section": "Week 6",
    "text": "Week 6\nIntroduction to web APIs\nAn introduction to computer-to-computer communication, client-server architectures, HTTP requests / responses, and web APIs. You will learn how to use Python to make requests to web APIs, use web APIs to download data into their programs, and scrape data from websites. You will also learn how to use the SpatioTemporal Asset Catalog (STAC) specification and STAC APIs to define and automate searches for geospatial data that meets certain query conditions from various cloud providers.\n\nInstructor-led lab: Introduction to web APIs, the requests package, and web scraping.\nSelf-guided lab: Searching archives of geospatial data in the cloud using STAC APIs."
  },
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software",
    "section": "",
    "text": "A course specific Python-enabled docker image will be provided for students to run on their own machines / uni machines with all the software and dependencies pre-installed.\nPython 3.X will be used throughout the course (unless specialist GUI software is required).\nAll labs will be delivered using Jupyter notebooks via JupyterLab."
  },
  {
    "objectID": "software.html#uni-machines",
    "href": "software.html#uni-machines",
    "title": "Software",
    "section": "Uni machines",
    "text": "Uni machines\nThis is the recommended environment for running the lab environment. Detailed instructions for launching the lab environment on the uni machines can be found in LMS. However, you need to login to the ubuntu image on the uni machines. Then open the terminal and run launch geog300agri3003."
  },
  {
    "objectID": "software.html#personal-devices",
    "href": "software.html#personal-devices",
    "title": "Software",
    "section": "Personal devices",
    "text": "Personal devices\n\nGoogle Colab\nYou can run each week’s lab using Google colab - a cloud based environment to run Jupyter notebooks. Click the colab button at the top of each lab’s notebook. It looks like:\n\nUsing Google Colab is the recommended approach to run the labs if you’re working on your own computer.\n\n\nDocker\nIf you want to run the lab’s notebooks locally in the same environment as on the uni machines, you can install docker which will let you run the lab environment.\n\n\nWindows\nInstall docker desktop for Windows here and follow the instructions.\nSystem requirements for Windows devices:\n\nWindows 11 64-bit: Home or Pro version 21H2 or higher, or Enterprise or Education version 21H2 or higher.\nWindows 10 64-bit: Home or Pro 21H1 (build 19043) or higher, or Enterprise or Education 20H2 (build 19042) or higher.\n64-bit processor.\n4GB of RAM.\n\nIf the installation has completed successfully, you should see this screen:\n\n\nPossible extra steps\nYou may see a prompt to install or update WSL2, if this does appear click the link in the message:\n\nThen download the WSL2 Linux Kernel Package by clicking on the link:\n\n\n\n\n\nThen follow the installation steps to install or update WSL 2:\n\n\n\n\n\nThen restart your computer.\nIf it’s not installed, you will need to install WSL2 must be installed. For more information about installing WSL2, see here for instructions.\n\n\nAdmin and user permissions\nIf the admin account is different to the user account on your Windows machine, follow these steps from docker - install interactively:\n\nRun Computer Management as an administrator\nGo to Local Users and Groups > Groups > docker-users\nRight-click to add the user to the docker-users group.\nLog out and login (or restart) for the changes to take effect.\n\n\n\n\nMac\nInstall docker desktop for Mac here and follow the instructions.\nSelect the correct installer for your Mac depending on whether you have an intel or silicon chip.\nSystem requirements for Mac devices:\n\nmacOS must be version 10.15 or newer\n4 GB of RAM"
  },
  {
    "objectID": "software.html#download-the-course-image",
    "href": "software.html#download-the-course-image",
    "title": "Software",
    "section": "Download the course image",
    "text": "Download the course image\n\nWindows\nOpen the command prompt or powershell and run:\ndocker pull jmad1v07/geog3300agri3003\n\n\n\n\nMac\nOpen the terminal and run:\ndocker pull jmad1v07/geog3300agri3003"
  },
  {
    "objectID": "software.html#run-the-course-image",
    "href": "software.html#run-the-course-image",
    "title": "Software",
    "section": "Run the course image",
    "text": "Run the course image\nOpen docker desktop and head to the Images tab.\n\nFind the jmad1v07/geog3300agri3003 image and click on Run.\n\nThis should bring up an Optional settings dialog. Here, we need to do two things.\nFirst of all we need to set a port, in most cases you can set this to 8888 (or any number above 1024 safely).\nSecond of all we need to mount a directory on our computer where the lab data and notebooks are stored to a directory inside the container. This means we can work with the data and notebook stored on our computer inside the containers environment (which has Python and relevant libraries installed) and all changes we make will be saved back to the directory on our machine. Hit Run to launch the container.\n\nNow, go to the Containers tab. Find the container we have just launched and click on the three vertical dots symbol ⋮ and then click View details.\n\nFinally, to access the container and our notebook environment click on the link which looks like http://127.0.0.1:8888/lab?token=fXBXBXBXBXBXBXBXBXBXXBXBBXX.\n\nThis should load the Jupyterlab environment in your browser. If it doesn’t, copy the link and paste it into your browser. If all has gone well you should see the Jupyterlab environment:"
  },
  {
    "objectID": "readings.html",
    "href": "readings.html",
    "title": "Course literature",
    "section": "",
    "text": "Python for Data Analysis by Wes Mckinney\nFundamendals of Data Visualisation by Claus Wilke"
  },
  {
    "objectID": "readings.html#technical-readings",
    "href": "readings.html#technical-readings",
    "title": "Course literature",
    "section": "Technical readings",
    "text": "Technical readings\nThe notes in the coursebook / Jupyter notebook for each week are the most important technical readings. The following readings are supplemental to the coursebook notes, but they will help with your understanding of the concepts and techniques introduced each week and it is recommended that you refer to them.\n\nWeek 1\n\nPython for Data Analysis - 2.3 Python Language Basics\nPython for Data Analysis - 3.1 Built-In Data Structures and Sequences\nPython for Data Analysis - 3.2 Functions\n\n\n\nWeek 2\n\nPython for Data Analysis - section 3.3 on Files and the operating system\nPython for Data Analysis - section 5.1 on Introduction to pandas Data Structures\nIntroduction to GeoPandas\nRasterio: Python Quickstart\nDorman (2022) - Rasters (up to the NoData mask section)\n\n\n\nWeek 3\n\nVisualisation\n\nWilke (2019) - Chapters 2, 3, 4, 5, and 21 (they are short chapters)\nPlotly Express\nPlotly Express API Reference\nPlotly Expresss arguments and input data formats\n\n\n\nData exploration and cleaning\n\nPython for Data Analysis - section7.1 on Handling missing data\nGoogle Machine Learning Guide on Good Data Analysis\n\n\n\nSubsetting pandas DataFrames\n\npandas Getting Started: How do I select specific rows and columns from a DataFrame?\nThe first few sections of the pandas docs on: Indexing and selecting data\nPython for Data Analysis - section on Indexing, selecting, and filtering\n\n\n\n\nWeek 4\n\nNumPy: the absolute basics for beginners\nPython for Data Analysis - NumPy Basics section 4.1\nPython for Data Analysis - Data Wrangling: Join, Combine, and Reshape section 8.2\nIntroduction to GeoPandas\nSpatial Joins (with GeoPandas)\n\n\n\nWeek 5\n\nPython for Data Analysis - Introduction to scikit-learn\nIntroduction to machine learning\nGoogle Machine Learning Guide on decision trees and random forests\n\n\nGeneral interest readings\n\nEyes in the sky, boots on the ground: assessing satellite and ground-based approaches to crop yield measurement and analysis\nUsing satellite imagery to understand and promote sustainable development\nMicrosoft open sources its ‘farm of the future’ toolkit –>"
  },
  {
    "objectID": "lab-1.html",
    "href": "lab-1.html",
    "title": "Introduction",
    "section": "",
    "text": "This lab will provide an introduction to programming concepts in Python. The concepts this lab will cover are:\n\ndata types and structures\nvariables and bindings\ncontrol flow, loops, and conditional execution\nclasses and objects\n\n\n\nThis lab will start by running a short Python program that loads some crop yield data collected by harvesters from disk and visualises this data on interactive maps and charts. We will then work through the program exploring how it uses a range of Python programming concepts to complete its tasks."
  },
  {
    "objectID": "lab-1.html#setup",
    "href": "lab-1.html#setup",
    "title": "Introduction",
    "section": "Setup",
    "text": "Setup\n\nRun the labs\nYou can run the labs locally on your machine or you can use cloud environments provided by Google Colab. If you’re working with Google Colab be aware that your sessions are temporary and, if required, you’ll need to take care to save, backup, and download your work.\n  \n\n\nDownload data\nIf you need to download the date for this lab, run the following code snippet.\nimport os\n\nif \"week-1\" not in os.listdir(os.getcwd()):\n    os.system('wget \"https://github.com/data-analysis-3300-3003/data/raw/main/data/week-1.zip\"')\n    os.system('unzip \"week-1.zip\"')\n\n\nInstall packages\nIf you’re working in Google Colab, you’ll need to install the required packages that don’t come with the colab environment.\nif 'google.colab' in str(get_ipython()):\n    !pip install geopandas\n    !pip install pyarrow\n    !pip install mapclassify\n    !pip install rasterio\n\n\nImport modules\nWe’ll introduce modules in detail later. But, for now, modules are collections of Python data structures and functions that we can import and use in our program. For example, pandas provides a DataFrame structure for storing tabular data and specific functions for working with tabular data. Plotly Express plotly.express provides functions for generating visualisations, importing Plotly Express means we don’t need to write our own code to generate visualisations, we can just use existing functions which makes our lives easier.\n# Import modules\nimport os\nimport pandas as pd\nimport geopandas as gpd\nimport plotly.express as px\nimport plotly.io as pio\n\n# setup renderer\nif 'google.colab' in str(get_ipython()):\n    pio.renderers.default = \"colab\"\nelse:\n    pio.renderers.default = \"jupyterlab\""
  },
  {
    "objectID": "lab-1.html#data-types",
    "href": "lab-1.html#data-types",
    "title": "Introduction",
    "section": "Data types",
    "text": "Data types\nPython programs perform operations on data to complete tasks. This can be scientific data such as crop yield or temperature measurements or it can be other forms of data necessary for the program to execute such as a file path to where data is stored on disk.\n\nBuilt-in data types\nPython comes with built-in data types that can be used to store different values. These are sometimes called scalar types as they store single values.\n\nfloat - storing floating point numeric values.\nint - storing integer numeric values.\nstr - storing text data as strings.\nbool - storing True or False as boolean values.\nNone - storing null values.\nbytes - storing raw binary data.\n\n\nNumeric data types\nint and float are numeric data types in Python and are used to store integer and floating point values, respectively.\nThe canola yield data that we have imported is of numeric type with units of tonnes/ha. Let’s represent a crop yield measurement of 0.227 tonnes/ha as data in our program and inspect its type.\n\nprint(type(0.227))\n\n<class 'float'>\n\n\n\n\nString data types\nWe also need to represent text data in our programs. In the crop yield dataset the sample id is text. In Python, text data is stored as a str type (or string type).\nText data is stored as string types by enclosing the characters in double\" or single ' quotes.\n\nprint(type(\"a string\"))\nprint(\"a string\")\n\n<class 'str'>\na string\n\n\nLet’s check how the sample id names in the canola yield dataset are represented. First, let’s remind ourselves what the DataFrame of the yield dataset looks like.\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      Latitude\n      Longitude\n      DryYield\n      Crop\n      Time\n      Heading\n      Variety\n      Elevation\n      sample_id\n      geometry\n    \n  \n  \n    \n      0\n      -31.606760\n      117.497719\n      0.227\n      5\n      11/11/2020 8:01\n      242.7\n      43Y23 RR\n      264.32\n      bf66_sample_1\n      POINT (117.49772 -31.60676)\n    \n    \n      1\n      -31.605409\n      117.496881\n      0.372\n      5\n      11/11/2020 8:02\n      344.3\n      43Y23 RR\n      265.39\n      bf66_sample_1\n      POINT (117.49688 -31.60541)\n    \n    \n      2\n      -31.603557\n      117.496855\n      0.651\n      5\n      11/11/2020 8:04\n      359.9\n      43Y23 RR\n      262.40\n      bf66_sample_1\n      POINT (117.49686 -31.60356)\n    \n    \n      3\n      -31.601549\n      117.496855\n      0.923\n      5\n      11/11/2020 8:05\n      359.8\n      43Y23 RR\n      264.61\n      bf66_sample_1\n      POINT (117.49685 -31.60155)\n    \n    \n      4\n      -31.599818\n      117.496855\n      1.216\n      5\n      11/11/2020 8:06\n      360.0\n      43Y23 RR\n      267.51\n      bf66_sample_1\n      POINT (117.49686 -31.59982)\n    \n  \n\n\n\n\n\n# get the first field name value\nfield_name = df.loc[:, \"sample_id\"].to_list()[0]\nprint(type(field_name))\nprint(field_name)\n\n<class 'str'>\nbf66_sample_1\n\n\n\n\nBoolean data types\nBoolean (bool) data types are used for storing True or False values. In Python, True or False are Boolean values and not string data types.\nBoolean data types are used to store the result of testing a condition that evaluates to true or false. For example, greater than and less than operations evaluate to true or false. We could test if our crop yield value of 0.227 is greater than 0.2 (it is and this expression should evaluate to true).\n\nprint(type(0.277 > 0.2))\nprint(0.227 > 0.2)\n\n<class 'bool'>\nTrue\n\n\nWe can use the isinstance(value, type) function to test if a data value matches a data type. Let’s test if our crop yield value is numeric or string.\n\nprint(isinstance(0.227, float))\nprint(isinstance(0.227, str))\n\nTrue\nFalse\n\n\n\n\nRecap quiz\n\n\nIf you execute x = 3.4, what data type will x be?\n\nfloat\n\n\n\n\n\nWhich data type would be most suited to record the number of apples harvested from an orchard?\n\nint - we should not be able to harvest fractions of apples.\n\n\n\n\n\nWhich data type would we use to record a farm name?\n\nstr - assuming the farm name is text data.\n\n\n\n\n\ny = 4 + 5 and z = y > 10 - what value will z be?\n\nFalse - y evaluates to 9 which is less than 10. Therefore, z will be False and of bool type."
  },
  {
    "objectID": "lab-1.html#data-structures",
    "href": "lab-1.html#data-structures",
    "title": "Introduction",
    "section": "Data structures",
    "text": "Data structures\nPython provides a series of built-in data structures that can be used to group together and store related data.\nData structures can be used to model a range of practical and real-world problems or phenomenon by combining simple data types. For example, we could use a collection of numeric data to represent a time-series of precipitation, string data to represent the weather station name, and combine string and numeric data together in a data structure to create a bespoke weather station data structure.\n\nlist - a variable length collection of objects that can be modified\ntuple - a fixed length collection of objects that cannot be modified\nset - a collection of unique objects\ndict - a collection of objects stored as key:value pairs\n\n\nLists\nLists in Python:\n\ncan be modified during a program’s execution\ncan store duplicate values\nare created by placing elements in square brackets []\nelements of a list are ordered\nelements of a list can be of different data types\n\nWe could store the sample names in our crop yield data set as a list:\n\n[\"bf66_sample_1\", \"bf66_sample_2\"]\n\n['bf66_sample_1', 'bf66_sample_2']\n\n\nLists allow us to store duplicate values. The following is a valid list.\n\n[\"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_2\"]\n\n['bf66_sample_1', 'bf66_sample_2', 'bf66_sample_2']\n\n\nA key feature of lists are that they can be modified in place. This makes lists useful data structures for tasks when the number of objects that we want to store in a collection can change during our program’s execution. We can use functions such as .append() to add objects to the end of a list.\n\nsample_id_list = [\"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_2\"]\nsample_id_list.append(\"bf66_sample_3\")\nprint(sample_id_list)\n\n['bf66_sample_1', 'bf66_sample_2', 'bf66_sample_2', 'bf66_sample_3']\n\n\n\n\nUsing lists in our Python program to read in CSV files on harvester crop yield data\n\nIn our Python program above, we took advantage of the fact that lists can be modified in place to loop over the CSV files in a directory, import them in as pandas DataFrames, and append the DataFrames to the list.\n# Combine the csv files into one data frame\ndfs = []\n\nfor i in harvester_data_files:\n    if i.endswith(\".csv\"):\n        print(f\"Loading file {i} into a Pandas DataFrame\")\n        tmp_df = pd.read_csv(os.path.join(harvester_data_path, i))\n        dfs.append(tmp_df)\nHere, we start with an empty list dfs denoted by just square brackets []. Then, successively, a new object is added to dfs using the append() function. We finish with a list storing three pandas DataFrames. This demonstrates how we change the length and contents of a list during the execution of a program. We have gone from a list with zero elements to a list a list with three elements.\n\n\n\nWe can store any Python object in a list. We can also mix the types of objects stored in lists. The following is a valid list.\n\n[1, 2, \"not a number\", None]\n\n[1, 2, 'not a number', None]\n\n\nLists are ordered collections of data. If you add an element to a list it will be appended to the last position. List items can be accessed by their index location with the first element having index 0.\n\nAside: indexing in Python\n\nAn index is an element’s location within a data structure\nOften, in Python, elements are accessed by their index position using the square brackets operator and passing an index in as an argument (e.g. the first element of x is x[0])\nIn Python, indexing starts at 0 - this means the index for the first element in a data structure is 0\nIt is important to become familiar with the concept of indexing - you will use it often as you handle data in Python\n\nLet’s demonstrate this by accessing the elements of the sample_id_list we created above.\n\nprint(sample_id_list)\nprint(\"The first element in sample_id_list is at index 0: \", sample_id_list[0])\nprint(\"The second element in sample_id_list is at index 1: \", sample_id_list[1])\nprint(\"The third element in sample_id_list is at index 2: \", sample_id_list[2])\n\n['bf66_sample_1', 'bf66_sample_2', 'bf66_sample_2', 'bf66_sample_3']\nThe first element in sample_id_list is at index 0:  bf66_sample_1\nThe second element in sample_id_list is at index 1:  bf66_sample_2\nThe third element in sample_id_list is at index 2:  bf66_sample_2\n\n\n\n\nSlicing\nWe can use index locations of elements in a list to create slices of list elements. For example, sample_id_list[0:2] would slice out the first two elements of the list. Note, the element referenced by the index in the final number of the slice is excluded.\n\nprint(sample_id_list[0:2])\n\n['bf66_sample_1', 'bf66_sample_2']\n\n\n\n\n\nTuples\nTuple in Python:\n\nelements are unchangeable (immutable)\ntuple elements are ordered\nstore a fixed-length number of elements\ncreated by placing Python objects inside parentheses ()\n\n\n(116.804075, -33.889203)\n\n(116.804075, -33.889203)\n\n\nHere, we have created a tuple with two numeric objects. Similar to lists we can access tuple elements by their index locations. Note the use of the [] operator to access elements by their index location.\n\nprint(\"First tuple element: \", (116.804075, -33.889203)[0])\n\nFirst tuple element:  116.804075\n\n\n\nprint(\"Second tuple element: \", (116.804075, -33.889203)[1])\n\nSecond tuple element:  -33.889203\n\n\nAs tuples are fixed-length and unchangeable, we cannot append elements to them in the same way we could with lists. This makes them useful data structures for storing data values which we don’t want to change. For example, coorindate pairs that describe a location’s x and y values (e.g. longitude and latitude) have two elements. Therefore, a tuple could be a suitable data format to store coordinate pairs.\nThe shape of pandas DataFrames is also a tuple. A DataFrame has two dimensions: number of rows and number of columns. Thus, a tuple is a sensible data structure for storing the shape of DataFrame objects.\n\ndf.shape\n\n(1000, 10)\n\n\nTo demonstrate that we cannot change tuple values, let’s try and update the number of rows in the tuple storing the shape of df.\ndf.shape[0] = 5\nWe have returned a TypeError informing us the tuple objects do not support item assigment (adding new items to the tuple).\nSimilar to lists, elements of a tuple are ordered and can be duplicated.\n\n\nSets\nSet in Python:\n\nunordered collection objects\nset elements cannot be duplicated\nsets are immutable\nsets are created by placing elements inside curly brackets {}\n\nLet’s create a set and demonstrate that it cannot store duplicate values.\n\n{\"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_2\", \"bf66_sample_3\"}\n\n{'bf66_sample_1', 'bf66_sample_2', 'bf66_sample_3'}\n\n\n\n{1, 2, 3, 3, 4}\n\n{1, 2, 3, 4}\n\n\nAs sets are not ordered, we cannot access their elements by numeric index locations.\n# This fails as set objects are not subscriptable\n{\"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"}[0]\nWe can access set elements by looping over them or checking if a value is in the set.\n\nfor i in {\"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"}:\n    print(i)\n\nbf66_sample_1\nbf66_sample_3\nbf66_sample_2\n\n\n\nprint(\"Checking if 'bf66_sample_1' is in the set:\")\nprint(\"bf66_sample_1\" in {\"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"})\n\nChecking if 'bf66_sample_1' is in the set:\nTrue\n\n\nSimilar to tuples, sets are unchangeable (immutable). Once created, we cannot change the set’s values in our programs.\n\n\nDictionary objects\nDictionary objects, or dict objects:\n\nstore data as a collection of key:value pairs\nDictionary objects can be changed and modified\nDictionary object elements are ordered\nWe can access dictionary elements by their key\nDictionary objects are created by placing key:value pairs inside curly brackets {}\nKeys of a dictionary object cannot be duplicated\nElements (values) of dictionary objects can be of a different type\nValues can be of different lengths\n\n\nUsing Dictionary objects to represent tabular data\nTabular data has data values stored in rows and columns. Generally, a column corresponds to a particular variable or type of data and rows correspond to observed or measured values. We can use dictionary objects to represent tabular data in Python.\nFor example, we can use the key:value pair pattern to represent a column header and column values.\n\"Elevation(m)\": [213, 222, 214, 254]\nHere, we’ve used a string object to represent the column header (the key) and a list object to represent column values (the value). Combining one or more key:value pairs in a dictionary object is a way of representing tabular data in Python.\n{\n\"Elevation(m)\": [213, 222, 214, 254],\n\"Date\": [\"20/11/2017\", \"20/11/2017\", \"20/11/2017\", \"19/11/2017\"],\n\"sample_id\": [\"bf66_sample_1\", \"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"]\n}\nLet’s create this dictionary object.\n\n{\n\"Elevation(m)\": [213, 222, 214, 254],\n\"Date\": [\"20/11/2017\", \"20/11/2017\", \"20/11/2017\", \"19/11/2017\"],\n\"sample_id\": [\"bf66_sample_1\", \"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"]\n}\n\n{'Elevation(m)': [213, 222, 214, 254],\n 'Date': ['20/11/2017', '20/11/2017', '20/11/2017', '19/11/2017'],\n 'sample_id': ['bf66_sample_1',\n  'bf66_sample_1',\n  'bf66_sample_2',\n  'bf66_sample_3']}\n\n\nKeys of dictionary objects cannot be duplicated. For example:\n\n{\n\"Elevation(m)\": [213, 222, 214, 254],\n\"Date\": [\"20/11/2017\", \"20/11/2017\", \"20/11/2017\", \"19/11/2017\"],\n\"sample_id\": [\"bf66_sample_1\", \"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"],\n\"sample_id\": [\"bf66_sample_1\", \"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"]\n}\n\n{'Elevation(m)': [213, 222, 214, 254],\n 'Date': ['20/11/2017', '20/11/2017', '20/11/2017', '19/11/2017'],\n 'sample_id': ['bf66_sample_1',\n  'bf66_sample_1',\n  'bf66_sample_2',\n  'bf66_sample_3']}\n\n\nTo access elements of a dictionary object we can refer to its key. The following code snippet extracts a list of dates from the dictionary object.\n\ndemo_dict = {\"Elevation(m)\": [213, 222, 214, 254],\n    \"Date\": [\"20/11/2017\", \"20/11/2017\", \"20/11/2017\", \"19/11/2017\"],\n    \"sample_id\": [\"bf66_sample_1\", \"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"]}\ndates = demo_dict[\"Date\"]\ndates\n\n['20/11/2017', '20/11/2017', '20/11/2017', '19/11/2017']\n\n\nDictionary objects have a get() function that we can use to extract elements.\n\ndates = demo_dict.get(\"Date\")\ndates\n\n['20/11/2017', '20/11/2017', '20/11/2017', '19/11/2017']\n\n\nDictionary objects also have a keys() function that returns a list of keys.\n\ndemo_dict.keys()\n\ndict_keys(['Elevation(m)', 'Date', 'sample_id'])\n\n\nThere is also a values() function that we can use to return a list of values.\n\ndemo_dict.values()\n\ndict_values([[213, 222, 214, 254], ['20/11/2017', '20/11/2017', '20/11/2017', '19/11/2017'], ['bf66_sample_1', 'bf66_sample_1', 'bf66_sample_2', 'bf66_sample_3']])\n\n\nAnd, the items() function returns a tuple of key-value pairs.\n\ndemo_dict.items()\n\ndict_items([('Elevation(m)', [213, 222, 214, 254]), ('Date', ['20/11/2017', '20/11/2017', '20/11/2017', '19/11/2017']), ('sample_id', ['bf66_sample_1', 'bf66_sample_1', 'bf66_sample_2', 'bf66_sample_3'])])\n\n\nWe can add elements to a dictionary object by providing a new key with corresponding values.\n\ndemo_dict[\"yield\"] = [1.45, 2.5, 3, 2.8, 5.5]\ndemo_dict\n\n{'Elevation(m)': [213, 222, 214, 254],\n 'Date': ['20/11/2017', '20/11/2017', '20/11/2017', '19/11/2017'],\n 'sample_id': ['bf66_sample_1',\n  'bf66_sample_1',\n  'bf66_sample_2',\n  'bf66_sample_3'],\n 'yield': [1.45, 2.5, 3, 2.8, 5.5]}\n\n\nYou will notice that the list of yield values we just added to the dictionary has a different number of elements to the other elements in the values slots.\n\n\nRecap quiz\n\n\nx = [1, 2, 3, 4] - what data structure is x?\n\nList\n\n\n\n\n\nq = {1, 2, 3, 4} - what data structure is q?\n\nSet\n\n\n\n\n\nWhich data structure organises its elements using key:value pairs?\n\nDictionary objects\n\n\n\n\n\nAre lists immutable data structures?\n\nNo, we can modify the values of a list and change its size (number of elements) during the program’s execution.\n\nEdit the following code snippet to retrieve and print the 3rd element in x.\nx = [1, 2, 3, 4]\n# add code here #\n\n\nanswer\n\nprint(x[2])\n\nEdit the following code snippet to retrieve and print the first element in z.\nz = (4, 5)\n# add code here #\n\n\nanswer\n\nprint(z[0])\n\nWhat is the data type of the value associated with the field key in the dict z? Retrieve this value from the dict and print its type.\nz = {\n\"name\": \"farm 1\",\n\"field\": 439,\n\"crop\": \"canola\"\n}\n# add code here #\n\n\nanswer\n\nprint(type(z[\"field\"]))"
  },
  {
    "objectID": "lab-1.html#variables",
    "href": "lab-1.html#variables",
    "title": "Introduction",
    "section": "Variables",
    "text": "Variables\nIn the program to read in and visualise crop yield data, you will have noticed this syntax pattern: variable_name = data.\nbasemap = \"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\"\n= is the assignment operator (not equals) which is assigning (or binding) the variable_name to the data object.\nThe statement basemap = \"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\" is assigning the data \"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\" to the variable name basemap. The data is string which is storing the URL for a satellite imagery basemap.\nLet’s see what the data looks like.\n\nprint(\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\")\n\nhttps://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\n\n\nNow, let’s assign the data object storing string URL to the name basemap.\n\nbasemap = \"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\"\nprint(basemap)\n\nhttps://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\n\n\nCalling print() on the variable name returns the data object that the variable name refers to.\nWe can assign any Python objects to variable names. When the variable name is used in a Python statement, the data value which the variable points to is used in the operations.\n\nx = 1\ny = 2\nz = x + y\nprint(z)\n\n3\n\n\nVariables make a program’s code easier to organise, write, and understand. We could have performed the above addition operation by just writing 1 + 2. However, this doesn’t provide us with a way to capture the result of that operation and use it again in our program without re-running 1 + 2.\nVariables provide us with a mechanism by which we retrieve and use data objects (that are stored in the computer’s memory) at various places in our program. A variable name points to the location in the computer’s memory where a data object is stored.\nWhile using the result of 1 + 2 is a trivial example, there are many cases where using variables is important. This statement reads a CSV file into our Python program: tmp_df = pd.read_csv(os.path.join(harvester_data_path, i)). To access the data stored in the CSV file we can use variable name tmp_df which points to where the data in the CSV file was loaded into memory. We don’t need to read the CSV file from disk each time we want to access its data.\nLet’s make these concepts concrete.\nWhen we assign the string \"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\" to the variable name basemap, the variable name is a pointer to the string’s data object.\n\nIf we create another variable called basemap_1 and assign it to basemap, both variables will point to the same data object (the string URL).\n\nLet’s check this.\n\nbasemap_1 = basemap\nprint(basemap_1)\n\nhttps://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\n\n\nIf we assign a new data object to basemap, basemap_1 will still point to the original string data.\n\n\nbasemap = [1, 2, 3, 4, 5]\nprint(basemap)\nprint(basemap_1)\n\n[1, 2, 3, 4, 5]\nhttps://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\n\n\nIf we assign basemap_1 to a new data object the string data for URL will no longer be accessible in our program and will eventually be removed from the computer’s memory.\n\nVariable names\nThere are rules that need to be followed when creating variable names:\n\nvariable names can only be text letters (A-Z, a-z), numbers (0-9), or underscores (_)\nvariable names cannot begin with a number\nvariable names cannot include whitespace\nvariable names cannot be reserved keywords such True, False, if\n\nThere are also some conventions that can be followed to help write programs that are easy to follow:\n\nuse a consistent style for writing variable names - snake_case where words are separated by underscores is recommended by the PEP8 style guide for Python code\nuse a descriptive variable name so it helps you understand what kind of data it is referring to"
  },
  {
    "objectID": "lab-1.html#control-flow",
    "href": "lab-1.html#control-flow",
    "title": "Introduction",
    "section": "Control flow",
    "text": "Control flow\nSo far we have demonstrated how we can represent information and concepts in our program as different data types and using different data structures. However, we are not using our program as a data storage device. We are using it to complete tasks with this data.\nControl flow refers to the sequence of steps that our program takes from start to finish when it is run.\nThe most simple form of control flow is executing statements from top to bottom as they are written in your script.\n\nprint(\"this statement is executed first\")\nprint(\"and this statement is executed second\")\n\nthis statement is executed first\nand this statement is executed second\n\n\n\nLoops\nLoops use a for statement that allows us to iterate over items in a sequence. For example, if x is a list [1, 2, 3] then:\nfor i in x:\n    print(i)\nwill print the values of 1, 2, and 3 in turn for each iteration of the loop, i, takes on the value of the corresponding element in x.\nFor loops are useful if we want to iterate over (repeat) a block of statements using different values from a sequence of items in turn. If we wanted to add 10 to each element of x we could write a for loop as:\nfor i in x:\n    print(i + 10)\nLet’s demonstrate this.\n\nx = [1, 2, 3]\n\nfor i in x:\n    print(i + 10)\n\n11\n12\n13\n\n\nIt is important to note that the statements inside the for loop must be indented.\nLet’s refer back to our program to read in crop yield data and see a use of for loops.\n# Combine the csv files into one data frame\ndfs = []\n\nfor i in harvester_data_files:\n    if i.endswith(\".csv\"):\n        print(f\"Loading file {i} into a Pandas DataFrame\")\n        tmp_df = pd.read_csv(os.path.join(harvester_data_path, i))\n        dfs.append(tmp_df)\nHere, the for loop is iterating over a list of file paths to CSV files storing crop yield data. For each of the CSV files in the list, the data is read into a variable tmp_df in turn, and, then appended to the list dfs. This is an example of how we can loop over a series of files in a folder on our computer and read their data into our Python program.\nLet’s modify the for loop to illustrate this.\n\n# Load the canola yield data from the harvester\nharvester_data_path = os.path.join(os.getcwd(), \"week-1\")\n\n# Get a list of canola yield data\nharvester_data_files = os.listdir(harvester_data_path)\n\n# Check we have a list of csv files\nprint(harvester_data_files)\n\n# loop over elements in harvester_data_files\n# i takes on the value of a path to a csv file\nfor i in harvester_data_files: \n    if i.endswith(\".csv\"):\n        print(\" \")\n        print(\"**********************************************************\")\n        print(f\"We are currently loading file {i} into a Pandas DataFrame\")\n        tmp_df = pd.read_csv(os.path.join(harvester_data_path, i))\n        print(tmp_df.head())\n        dfs.append(tmp_df)\n\nprint(\" \")\nprint(f\"We have a list of {len(dfs)} Pandas DataFrames read from csv files\")   \n\n['.DS_Store', '.ipynb_checkpoints', 'canola-yield-df-1.csv', 'canola-yield-df-2.csv', 'canola-yield-df-3.csv']\n \n**********************************************************\nWe are currently loading file canola-yield-df-1.csv into a Pandas DataFrame\n    Latitude   Longitude  DryYield  Crop             Time  Heading   Variety  \\\n0 -31.606760  117.497719     0.227     5  11/11/2020 8:01    242.7  43Y23 RR   \n1 -31.605409  117.496881     0.372     5  11/11/2020 8:02    344.3  43Y23 RR   \n2 -31.603557  117.496855     0.651     5  11/11/2020 8:04    359.9  43Y23 RR   \n3 -31.601549  117.496855     0.923     5  11/11/2020 8:05    359.8  43Y23 RR   \n4 -31.599818  117.496855     1.216     5  11/11/2020 8:06    360.0  43Y23 RR   \n\n   Elevation      sample_id  \n0     264.32  bf66_sample_1  \n1     265.39  bf66_sample_1  \n2     262.40  bf66_sample_1  \n3     264.61  bf66_sample_1  \n4     267.51  bf66_sample_1  \n \n**********************************************************\nWe are currently loading file canola-yield-df-2.csv into a Pandas DataFrame\n    Latitude   Longitude  DryYield  Crop             Time  Heading   Variety  \\\n0 -31.600453  117.493947     0.824     5  11/12/2020 5:18    360.0  43Y23 RR   \n1 -31.598607  117.493947     0.733     5  11/12/2020 5:19    359.8  43Y23 RR   \n2 -31.596753  117.493947     0.814     5  11/12/2020 5:20      0.2  43Y23 RR   \n3 -31.594771  117.493947     0.505     5  11/12/2020 5:22      0.4  43Y23 RR   \n4 -31.592741  117.493947     0.477     5  11/12/2020 5:23      0.1  43Y23 RR   \n\n   Elevation      sample_id  \n0     269.18  bf66_sample_2  \n1     275.82  bf66_sample_2  \n2     278.69  bf66_sample_2  \n3     275.98  bf66_sample_2  \n4     271.18  bf66_sample_2  \n \n**********************************************************\nWe are currently loading file canola-yield-df-3.csv into a Pandas DataFrame\n    Latitude   Longitude  DryYield  Crop             Time  Heading   Variety  \\\n0 -31.595314  117.487245     0.336     5  11/12/2020 8:30    180.4  43Y23 RR   \n1 -31.597407  117.487246     0.428     5  11/12/2020 8:32    178.9  43Y23 RR   \n2 -31.599544  117.487245     0.287     5  11/12/2020 8:33    180.0  43Y23 RR   \n3 -31.601671  117.487245     0.081     5  11/12/2020 8:34    179.6  43Y23 RR   \n4 -31.600163  117.487372     0.271     5  11/12/2020 8:36    359.9  43Y23 RR   \n\n   Elevation      sample_id  \n0     273.03  bf66_sample_3  \n1     271.27  bf66_sample_3  \n2     267.35  bf66_sample_3  \n3     271.18  bf66_sample_3  \n4     267.91  bf66_sample_3  \n \nWe have a list of 6 Pandas DataFrames read from csv files\n\n\n\n\nConditional execution\nConditional execution is a form of control flow that allows for branches in the sequence that statements are executed. A boolean condition is tested, and, if it evaluates to True then one set of statements are executed and if it evaluates to False a different set of statements are executed.\nConditions are tested within if blocks:\nif True:\n    these statements are executed\nelse:\n    these statements are executed\nA simple example:\nx = 11\n\nif x >= 10:\n    print(\"x is greater than or equal to 10\")\nIn this instance, the statements inside the if block will be executed as x is 11 and so greater than 10.\nHowever, if we change the value of x to 9 the statements inside the if block will not be executed.\nx = 9\n\nif x >= 10:\n    print(\"x is greater than or equal to 10\")\n\nx = 11\n\nif x >= 10:\n    print(\"x is greater than or equal to 10\")\n\nx is greater than or equal to 10\n\n\n# nothing should be printed\nx = 9\n\nif x >= 10:\n    print(\"x is greater than or equal to 10\")\nSimilar to for loops, the statements inside the if block should be indented.\nWe can use else blocks for statements that can be executed if the if statement evaluates to False.\nx = 9\n\nif x >= 10:\n    print(\"x is greater than or equal to 10\")\nelse:\n    print(\"x is less than 10\")\n\nx = 9\n\nif x >= 10:\n    print(\"x is greater than or equal to 10\")\nelse:\n    print(\"x is less than 10\")\n\nx is less than 10\n\n\nThere are many uses for if statements in Python programs. An if statement was used when we read in CSV files of harvester data.\n# Combine the csv files into one data frame\ndfs = []\n\nfor i in harvester_data_files:\n    if i.endswith(\".csv\"):\n        print(f\"Loading file {i} into a Pandas DataFrame\")\n        tmp_df = pd.read_csv(os.path.join(harvester_data_path, i))\n        dfs.append(tmp_df)\nHere, the if statement is being used to check the file path is referring to a CSV file. Only if this is True does our program try to read the file into a pandas DataFrame.\n\nRecap quiz\nWrite a for loop to subtract 3 from every element in a tuple s and print the result?\ns = (1, 2, 3)\n# add code here #\n\n\nanswer\n\nfor i in s: \n    print(i - 3)\n\n\n\nHow would you iterate over list of file paths?\n\nUsing a for loop.\n\nWrite a for loop to subtract 3 from every element in the tuple s and append the result to a list q?\nq = []\ns = (1, 2, 3)\n# add code here #\n\n\nanswer\n\nfor i in s: \n    q.append(i - 3)\n\nprint(q)\n\nWrite a loop to subtract 3 from every element in the tuple s and append the result to a list q if the result is less than 0?\nq = []\ns = (1, 2, 3)\n# add code here #\n\n\nanswer\n\nfor i in s:\n    if i -3 < 0:\n        q.append(i - 3)\n\nprint(q)"
  },
  {
    "objectID": "lab-1.html#classes-and-objects",
    "href": "lab-1.html#classes-and-objects",
    "title": "Introduction",
    "section": "Classes and Objects",
    "text": "Classes and Objects\nWe have mentioned a few times that Python programs comprise objects. We will now define what an object is and how the concept of an object relates to the data types and structures we have looked at above.\n\nObjects\nAn object is a more general concept in programming. An object in a computer program has:\n\nproperties or attributes (data)\nbehaviour (methods or functions that do things with object data).\n\nObjects provide a way to add structure to a program by combining related data and behaviours.\nAlongside the built-in data types and structures, we can create objects that are customised and useful for specific tasks or representing specific kinds of data or real-world problems. Often, custom data types will combine the built-in data types and structures, or other custom objects, to create objects that represent more complex concepts.\n\n\nClasses\nA class is a definition of an object. The class defines the object’s data and methods. An object is an instance of a class in our programs.\nAn object’s data (sometimes called its properties or attributes) can be built-in Python data types or structures or custom classes. An object’s methods are functions that can be used to transform data or implement other behaviour that is relevant to the object. For example, an object representing a table is more complex than a list.\n\npandas DataFrames\nFor most use cases there are existing classes that have already been developed and can be used in our programs. Keeping with the idea of working with tabular data, pandas provides a DataFrame class to work with tabular data. In our Python program to visualise the crop yield data we read the tabular data stored in CSV files into pandas DataFrames.\nA pandas DataFrame is a far more comprehensive class for handling tabular data. Compared to our small example of using a dictionary object to store tabular data, a pandas DataFrame implements well defined data structures for tabular data and provides a suite of useful methods (functions) for analysing and processing tabular data.\n\n\nDataFrame Properties\nThe class DataFrame is a data structure for “Two-dimensional, size-mutable, potentially heterogeneous tabular data”. It has the following properties:\n\ndata - the tabular data stored in the data frame\nindex - the row index (row labels)\ncolumns - the column headers\ndtype - the data types of each column\n\n\nA pandas DataFrame stores its values in rows and columns. There is a list of column headers (which should provide a helpful description of what kind of data is in each column) and a row index.\nThe values in columns are pandas Series objects. A Series is an array of the same type data.\nThe pandas DataFrame object stores a range of properties that are useful for working with tabular data. You can look up the documentation for a DataFrame here. The properties listed do not have parentheses after their name (). Let’s look at the properties under attributes and underlying data. We can see the DataFrame has a values property which is the actual data values in the table and a shape property which tells us the shape of the table (number of rows and columns).\n\nMost of the time we will explore classes using their documentation websites. Let’s read a CSV file into a pandas DataFrame and explore its properties.\n\n# Load the canola yield data from the harvester\nharvester_data_path = os.path.join(os.getcwd(), \"week-1\", \"canola-yield-df-1.csv\")\n\ndf = pd.read_csv(harvester_data_path)\n\n# check that df is a DataFrame\ntype(df)\n\npandas.core.frame.DataFrame\n\n\n\n# Get the shape property of the DataFrame\ndf.shape\n\n(500, 9)\n\n\nA tuple data structure is used to store the shape property of a DataFrame.\n\n# Get the values of the DataFrame\ndf.values\n\narray([[-31.60675982, 117.4977191, 0.227, ..., '43Y23 RR', 264.32,\n        'bf66_sample_1'],\n       [-31.60540873, 117.4968805, 0.372, ..., '43Y23 RR', 265.39,\n        'bf66_sample_1'],\n       [-31.60355699, 117.4968552, 0.651, ..., '43Y23 RR', 262.4,\n        'bf66_sample_1'],\n       ...,\n       [-31.60688574, 117.493947, 0.476, ..., '43Y23 RR', 271.19,\n        'bf66_sample_1'],\n       [-31.60480349, 117.493947, 0.392, ..., '43Y23 RR', 269.8,\n        'bf66_sample_1'],\n       [-31.60238646, 117.4939473, 0.649, ..., '43Y23 RR', 264.1,\n        'bf66_sample_1']], dtype=object)\n\n\n\n\nDataFrame methods\nHowever, a DataFrame is more than just an object for storing data. It is also where we can find a wide range of functions for working with tabular data - the class methods. Go back to the documentation for a DataFrame here. The DataFrame methods are indicated by the parentheses after their name ().\nThere are methods to help us inspect the DataFrame values. The info() method prints a concise summary table of the DataFrame, there a range of methods for performing mathemtatical computations / descriptive stats, and methods for reading data on disk into DataFrames.\nLet’s explore how we can use some of these methods to work with tabular data in DataFrames.\nThe DataFrame referenced by df has an info() method. Let’s use it.\n\n# Load the canola yield data from the harvester\nharvester_data_path = os.path.join(os.getcwd(), \"week-1\", \"canola-yield-df-1.csv\")\n\ndf = pd.read_csv(harvester_data_path)\n\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 500 entries, 0 to 499\nData columns (total 9 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   Latitude   500 non-null    float64\n 1   Longitude  500 non-null    float64\n 2   DryYield   500 non-null    float64\n 3   Crop       500 non-null    int64  \n 4   Time       500 non-null    object \n 5   Heading    500 non-null    float64\n 6   Variety    500 non-null    object \n 7   Elevation  500 non-null    float64\n 8   sample_id  500 non-null    object \ndtypes: float64(5), int64(1), object(3)\nmemory usage: 35.3+ KB\n\n\nThe info() method has printed out a summary of the DataFrame for us. A DataFrame also has a mean() method to quickly compute the average of values in a column.\n\ndf.mean(numeric_only=True)\n\nLatitude     -31.598355\nLongitude    117.496685\nDryYield       0.634416\nCrop           5.000000\nHeading      174.047400\nElevation    265.177260\ndtype: float64\n\n\nYou will notice that we passed numeric_only=True when using the mean() method. Head the the mean() documentation to see what this does.\n\n\n\nMethods and functions\nFunctions are executed to perform a task using data. You can spot functions by () appearing after the function name. Functions can take input data - this is the function’s arguments - and use these inputs to complete it’s task.\nFunctions can return data back to the Python program, display data on your screen, or save data to disk.\nFor example, the print() function takes data as an argument and prints it on your display as text. For example, print(\"hello\") would print hello on your screen. The df = pd.read_csv(\"a_csv_file.csv\") is a function within the pandas package the takes in a path to a CSV file as an argument and reads the data from that file into a DataFrame referenced by df.\nMethods are functions that belong to a class. For example, the mean() method of the pandas DataFrame can be called by accessing it via a DataFrame() object (e.g df.mean()). Methods often provide functionality related to the “topic” of the class they’re associated with. For example, DataFrame methods provide functions related to working tabular data in DataFrame objects; dictionary objects have specialist methods geared for retrieving and setting data elements in dictionaries; string objects have methods for manipulating text (e.g. the lower() of a string object will convert all text characters to lower case).\nThe general pattern for executing a function / method is:\n\nThe function is called and any data are passed in as arguments inside ()\nThe function performs operations on the data passed in\nThe function returns the result of operating on the data\n\nAs everything in Python is an object, lists and string objects have methods. You can see the methods associated with an object by typing the object name, dot operator, and pressing tab.\nFor example, if farm_name = \"my farm\", farm_name.<press_tab> will print a list of string object methods.\nTry this below and explore string and list methods, and how they can be used to transform your data.\nfarm_name = \"my farm\"\n# uncomment below to see string methods\n# farm_name.<press_tab>\na_list = [1, 2, 3]\n# uncomment below to see list methods\n# a_list.<press_tab>\n\n\nInstances\nAbove we said that a class is a definition of an object. The class never has any data stored in it or executes any of its methods - it’s just a template for a particular type of object. Objects are instances of a class.\nWhen we executed the statement df = pd.read_csv(\"csv_file.csv\") we are creating an instance object of the DataFrame class which is stored in the computer’s memory.\n\n\nDot notation\nWe use the . operator to access properties and methods of class. For example to access the shape property of a DataFrame we write df.shape and to access the info() method we write df.info()."
  },
  {
    "objectID": "lab-1.html#modules",
    "href": "lab-1.html#modules",
    "title": "Introduction",
    "section": "Modules",
    "text": "Modules\nThere is one final concept to cover that is used in our program to read and visualise harvester yield data. The very first lines of the program.\n# Import modules\nimport os\nimport pandas as pd\nimport geopandas as gpd\nimport plotly.express as px\nHere, we are importing modules into our script. A module is a Python file (a file with a .py ending) that contains class definitions and functions. When we import a module into our program we can use the classes defined in the module.\nFor example, we have used the method os.path.join() from the os module in our program. This function takes string data describing parts of a file path and joins them together to create path to a directory or file.\n\nharvester_data_path = os.path.join(os.getcwd(), \"data\", \"week-1\", \"canola-yield-df-1.csv\")\nprint(harvester_data_path)\n\n/home/jovyan/work/data/week-1/canola-yield-df-1.csv\n\n\nInside the os.path.join() function you will see that we use the os.getcwd() method from the os module. This returns the current working directory.\n\nos.getcwd()\n\n'/home/jovyan/work'\n\n\nYou will see that we imported pandas as pd. This means we can refer to pandas as pd in our script. For example, to access the read_csv() function we write pd.read_csv() and not pandas.read_csv(). This is just a convenience to make the script less cluttered. The following would also be valid.\nimport pandas\ndf = pandas.read_csv(\"file.csv\")"
  },
  {
    "objectID": "lab-1-practice-exercises.html",
    "href": "lab-1-practice-exercises.html",
    "title": "Week 1 - Practice Exercises",
    "section": "",
    "text": "This notebook contains a series of practice exercises related to the content in week 1’s lab. It is designed to help you become more familiar with the Python programming concepts introduced in lab 1 and practice writing simple Python statements to achieve tasks."
  },
  {
    "objectID": "lab-1-practice-exercises.html#data-types",
    "href": "lab-1-practice-exercises.html#data-types",
    "title": "Week 1 - Practice Exercises",
    "section": "Data types",
    "text": "Data types\n\nNumeric data types\n1.34 is assigned to the variable a, can you print the data referenced by variable a on your display?\n## add code here ##\n\n\nanswer\n\na = 1.34\nprint(a)\n\n\n\nCan you add 8 and 2 and assign the result to the variable name z?\n## add code here ##\n\n\nanswer\n\nz = 8 + 2\nprint(z)\n\n\n\nCan you check what data type 4 is?\n## add code here ##\n\n\nanswer\n\nprint(type(4))\n\n\n\n\n\nString data types\nCan you check what data type \"hello\" is?\n## add code here ##\n\n\nanswer\n\nprint(type(\"hello\"))\n\nWe can represent multiline strings by enclosing the text values inside three \"\"\" or '''.\nFor example:\na_longer_string = '''\nThis is a multiline\nstring object.\n'''\nString objects have a range of methods for transforming text data. You can see a list of the string methods here.\nCan you use the upper() method to convert this string’s text characters to upper case: \"Hello!\"?\n## add code here ##\n\n\nanswer\n\nprint(\"Hello!\".upper())\n\nCan you use the find() method to find the index location of \"object\" in this multiline string?\na_longer_string = '''\nThis is a multiline\nstring object.\n'''\n## add code here ##\n\n\nanswer\n\na_longer_string = '''\nThis is a multiline\nstring object.\n'''\nprint(a_longer_string.find(\"object\"))\n\nThe endswith() method is a useful tool for checking if a string ends with a certain sequence of text values. We use this often to check if a filename ends with a certain format.\nCan you use the endswith() method to check if the string \"an_image.tif\" ends with the \".tif\" extension?\n## add code here ##\n\n\nanswer\n\nprint(\"an_image.tif\".endswith(\".tif\"))"
  },
  {
    "objectID": "lab-1-practice-exercises.html#data-structures",
    "href": "lab-1-practice-exercises.html#data-structures",
    "title": "Week 1 - Practice Exercises",
    "section": "Data Structures",
    "text": "Data Structures\nWhen pracitcing using data structures to store collections of values, think about how you can use data structures to model a range of data formats or real-world datasets (e.g. spreadsheets, data from weather stations, image pixels).\n\nLists\nCan you use the len() function to find out the length (number of elements) in this list: a_list = [1, 2, 3]?\n## add code here ##\n\n\nanswer\n\na_list = [1, 2, 3]\nprint(len(a_list))\n\n\n\nCan you select the first element of this list: a_list = [1, 2, 3]?\n## add code here ##\n\n\nanswer\n\na_list = [1, 2, 3]\nprint(a_list[0])\n\n\n\nCan you slice out the last two elements of this list: a_list = [1, 2, 3]?\n## add code here ##\n\n\nanswer\n\nRemember, the last index location in the slice is exclusive!\na_list = [1, 2, 3]\nprint(a_list[1:3]) \n\n\n\nCan you add the string \"modified\" to the list: text_list = [\"lists\", \"can\", \"be\"]?\n## add code here ##\n\n\nanswer\n\nRemember, lists are mutable data structures!\ntext_list = [\"lists\", \"can\", \"be\"]\nprint(text_list.append(\"modified\"))\n\n\n\nCan you replace the first animal in this list with the string \"cow\": animal_list = [\"sheep\", \"horse\", \"pig\"]?\n## add code here ##\n\n\nanswer\n\nRemember, lists are mutable data structures!\nanimal_list = [\"sheep\", \"horse\", \"pig\"]\nanimal_list[0] = \"cow\"\nprint(animal_list) \n\n\n\nAlong with using index locations and slices, we can also use list methods to modify list elements. The insert() method takes an index location and value as arguments, and inserts the value into the location specified by the index.\nFor example,\na_list = [1, 2, 3]\na_list.insert(0, 4)\nprint(a_list)\nShould return [4, 1, 2, 3].\nCan you add the number 5 to the second index location in the list a_list = [4, 1, 2, 3]?\n## add code here ##\n\n\nanswer\n\nRemember, lists are mutable data structures!\na_list = [4, 1, 2, 3]\na_list.insert(1, 5)\nprint(a_list)\n\n\n\nNote, the use of the . operator to access an object’s methods.\nThe pop() method of a list removes a value at the specified index location, which is passed in as an argument.\nCan you use the pop() method to remove the third element of a_list = [1, 2, 3, 4, 5]?\n## add code here ##\n\n\nanswer\n\na_list = [1, 2, 3, 4, 5]\na_list.pop(2)\nprint(a_list)"
  },
  {
    "objectID": "lab-1-practice-exercises.html#tuples",
    "href": "lab-1-practice-exercises.html#tuples",
    "title": "Week 1 - Practice Exercises",
    "section": "Tuples",
    "text": "Tuples\nHow to you create a tuple with one element?\n## add code here ##\n\n\nanswer\n\nYou must include a comma after the data value. Otherwise it would be interpreted as a integer if a single digit, for example.\na_tuple = (1,)\n\n\n\nCan you use the len() function to find out the length (number of elements) in this tuple: a_tuple = (0, 1, 2, 3)?\n## add code here ##\n\n\nanswer\n\na_tuple = (0, 1, 2, 3)\nprint(len(a_tuple))\n\n\n\nCan you get the value of the second element in this tuple: a_tuple = (0, 1, 2, 3)?\n## add code ##\n\n\nanswer\n\na_tuple = (0, 1, 2, 3)\nprint(a_tuple[1])\n\n\n\n\nDictionaries\nCan you access the list of temperature values from this dict?\nweather_station_data = {\n\"name\": \"York\",\n\"date\": [\"2020-01-01\", \"2020-01-02\", \"2020-01-03\", \"2020-01-04\"],\n\"temperature\": [34, 33, 38, 27],\n\"precipitation\": [0, 0, 0, 0.1]\n}\n## add code here ##\n\n\nanswer\n\nweather_station_data = {\n\"name\": \"York\",\n\"date\": [\"2020-01-01\", \"2020-01-02\", \"2020-01-03\", \"2020-01-04\"],\n\"temperature\": [34, 33, 38, 27],\n\"precipitation\": [0, 0, 0, 0.1]\n}\n\nprint(weather_station_data[\"temperature\"])\n\nCan you add this list of wind speeds ([23, 10, 5, 15]) to the weather_station_data dictionary under the \"wind_speed\" key?\n## add code here ##\n\n\nanswer\n\nweather_station_data = {\n\"name\": \"York\",\n\"date\": [\"2020-01-01\", \"2020-01-02\", \"2020-01-03\", \"2020-01-04\"],\n\"temperature\": [34, 33, 38, 27],\n\"precipitation\": [0, 0, 0, 0.1]\n}\nweather_station_data[\"wind_speed\"]=[23, 10, 5, 15]\nprint(weather_station_data)"
  },
  {
    "objectID": "lab-1-practice-exercises.html#control-flow",
    "href": "lab-1-practice-exercises.html#control-flow",
    "title": "Week 1 - Practice Exercises",
    "section": "Control flow",
    "text": "Control flow\n\nFor loops\nCan you write a for loop that iterates over the tuple (0, 1, 2, 3, 4) and adds two to each value in-turn and prints the result?\n## add code here ##\n\n\nanswer\n\nfor i in (0, 1, 2, 3, 4):\n    print(i + 2)\n\n\n\nCan you create an empty list using the square brackets (my_list = []), then iterate over the tuple (0, 1, 2, 3, 4), add two to each value in-turn, and append it to my_list?\n## add code here ##\n\n\nanswer\n\nmy_list = []\nfor i in (0, 1, 2, 3, 4):\n    my_list.append(i)\n\nprint(my_list)"
  },
  {
    "objectID": "lab-2.html",
    "href": "lab-2.html",
    "title": "Introduction",
    "section": "",
    "text": "Data analysis tasks involve reading data stored in files on disks, servers in the cloud, or recorded by sensors. Also, we need to save the results of our analysis or datasets we have generated to files.\nThere are a range of data types (e.g. string / text, numeric, datetime) and ways of characterising data such as tabular data, images and arrays, and spatial and non-spatial data. This necessitates storing data with different file formats. It’s important to be able to read and write data from and to different file formats into and out of Python data structures that we can analyse in our programs.\nThere are costs involved in storing and transferring data. These can be time costs associated with the time taken to read data from disk into the computer’s memory or transferring data from one computer to another over a network. Or, they can be financial costs associated with storing the data (the cost of hard drives increases with storage capacity and cloud storage providers charge by the byte).\nThe term big data refers to the increasing volume, variety, and velocity of data. Larger and more diverse datasets are being generated more quickly. To be able to handle big data it is important to select appropriate file formats for efficient storage and reading / writing (or input / output - I/O).\n\n\nIn this lab we will write Python programs that can read crop yield data collected from harvesters and satellite images of the same field into data structures that we can analyse and visualise.\nA solid understanding of how to read and write different types of data from and to files is a key skill for data analysis. This week’s lab will build these skills and provide an introduction to:\n\nfiles, directories, and data storage\nreading and writing files in Python\ntabular, image, and geospatial file formats\nspecialist file formats for the web, big data, and cloud computing\nselecting different data formats for specific analysis or storage tasks"
  },
  {
    "objectID": "lab-2.html#setup",
    "href": "lab-2.html#setup",
    "title": "Introduction",
    "section": "Setup",
    "text": "Setup\n\nRun the labs\nYou can run the labs locally on your machine or you can use cloud environments provided by Google Colab. If you’re working with Google Colab be aware that your sessions are temporary and you’ll need to take care to save, backup, and download your work.\n  \n\n\nDownload data\nIf you need to download the date for this lab, run the following code snippet.\nimport os\n\nif \"week-2\" not in os.listdir(os.getcwd()):\n    os.system('wget \"https://github.com/data-analysis-3300-3003/data/raw/main/data/week-2.zip\"')\n    os.system('unzip \"week-2.zip\"')\n\n\nWorking in Colab\nIf you’re working in Google Colab, you’ll need to install the required packages that don’t come with the colab environment.\nif 'google.colab' in str(get_ipython()):\n    !pip install geopandas\n    !pip install pyarrow\n    !pip install mapclassify\n    !pip install rasterio\n\n\nImport modules\nimport pandas as pd\nimport geopandas as gpd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport rasterio\nimport json\nimport os\nimport folium\nimport plotly.express as px\nimport plotly.io as pio\nimport pprint\n\n# setup renderer\nif 'google.colab' in str(get_ipython()):\n    pio.renderers.default = \"colab\"\nelse:\n    pio.renderers.default = \"jupyterlab\""
  },
  {
    "objectID": "lab-2.html#a-python-program-to-read-a-file",
    "href": "lab-2.html#a-python-program-to-read-a-file",
    "title": "Introduction",
    "section": "A Python program to read a file",
    "text": "A Python program to read a file\nLet’s start with a simple program to open a CSV file, read some data from it into memory, and then close the connection to the file.\n\n# path to csv file\nelev_csv_path = os.path.join(os.getcwd(), \"week-2\", \"week-2-bf66-elevation.csv\")\nprint(\"path to elevation csv file:\", elev_csv_path)\n\n# open the file and read the first 1000 characters\nf = open(elev_csv_path, \"r\", encoding=\"utf-8\")\ndata = f.read(1000)\nf.close()\n\nprint(\"\")\nprint(\"The first 1000 characters of the csv file area:\")\nprint(data)\n\npath to elevation csv file: /home/jovyan/work/week-2/week-2-bf66-elevation.csv\n\nThe first 1000 characters of the csv file area:\nNorthing,Easting,Lat,Lon,Elevation\n6503882.129,545428.0052,-31.59926178,117.4788733,268.92\n6503806.024,545427.6719,-31.59994843,117.4788733,265.908\n6503881.794,545504.4826,-31.59926178,117.4796795,268.171\n6503805.688,545504.1488,-31.59994843,117.4796795,265.413\n6503729.582,545503.8149,-31.60063507,117.4796795,263.08\n6503653.477,545503.481,-31.60132172,117.4796795,260.739\n6504185.881,545582.2978,-31.5965152,117.4804856,273.014\n6504109.775,545581.9634,-31.59720185,117.4804856,273.273\n6504033.67,545581.629,-31.59788849,117.4804856,273.896\n6503957.564,545581.2946,-31.59857514,117.4804856,272.369\n6503881.458,545580.9601,-31.59926178,117.4804856,268.96\n6503805.352,545580.6257,-31.59994843,117.4804856,264.807\n6503729.246,545580.2913,-31.60063507,117.4804856,262.857\n6503653.141,545579.9568,-31.60132172,117.4804856,260.894\n6504337.756,545659.4474,-31.59514191,117.4812918,274.777\n6504261.651,545659.1125,-31.59582856,117.4812918,273.813\n6504185.545,545658.7775,-31.5965152,117.4812918,272.371\n6504"
  },
  {
    "objectID": "lab-2.html#files-and-io",
    "href": "lab-2.html#files-and-io",
    "title": "Introduction",
    "section": "Files and I/O",
    "text": "Files and I/O\n\nFiles\nA file is data that is stored on a disk. Data in files is stored as a sequence bytes in binary format (values of zero or one).\n\n\nBinary\nA binary number is represented using only the digits 1 or 0. The binary number system is a base-2 number system (as it has only two symbols).\nThe decimal number 0 in binary is 0:\n\\(0 = (0 \\cdot 2^{0})\\)\nThe decimal number 1 in binary is 1:\n\\(1 = (1 \\cdot 2^{0})\\)\nThe decimal number 2 in binary is 10:\n\\(2 = (1 \\cdot 2^{1}) + (0 \\cdot 2^{0})\\)\nThe decimal number 3 in binary is 11:\n\\(3 = (1 \\cdot 2^{1}) + (1 \\cdot 2^{0})\\)\nThe decimal number 4 in binary is 100:\n\\(4 = (1 \\cdot 2^{2}) + (0 \\cdot 2^{1}) + (0 \\cdot 2^{0})\\)\nYou don’t need to know the details of the binary number system here, but the key things to take away are:\n\nnumbers are stored in binary using the digits 1 or 0\nlarger numbers require more binary digits\nlarger numbers, therefore, require more storage space\n\nThere are plenty of resources online to learn more about number systems. This is a short article on The History of Numbers.\nBits\nA single binary digit is a bit. Looking at the pattern above we can store the numbers 0 and 1 using a 1-bit binary number. We can store the numbers 2 and 3 using a 2-bit binary number. We can store the number 4 using a 3-bit binary number. For every extra bit we double the numbers that can be stored in binary.\n\n1 bits = 2 numbers (0 and 1)\n2 bits = 4 numbers (0 to 3)\n3 bits = 8 numbers (0 to 7)\n4 bits = 16 numbers (0 to 15)\n5 bits = 32 numbers (0 to 31)\n6 bits = 64 numbers (0 to 63)\n7 bits = 128 numbers (0 to 128)\n8 bits = 256 numbers (0 to 255)\n\nBytes\nA byte is an 8-bit binary number. With a single byte we can represent 256 different numbers. Computer storage is measured in bytes:\n\n1 Kilobyte (KB) is about 1,000 bytes.\n1 Megabyte (MB) is about 1,000,000 bytes.\n1 Gigabyte (GB) is about 1,000,000,000 bytes.\n\nA greyscale image file can store each pixel’s colour as an 8-bit number or as a single byte. Black is represented as the number 0 (00000000), white is the number 255 (11111111), and shades of grey are intermediate numbers (00000001 to 11111110).\nIf this greyscale image has 100x100 pixels (10,000 pixels), how many bytes of storage does this image require?\n\\(10000 bytes = 10000 pixels \\cdot 1 byte\\) as each pixel requires 1 byte of storage.\nGenerally, a common text character such as upper and lower case letters (A-Z, a-z) and symbols (!, @, # etc.) requires a byte of storage. The CSV file we read above stores text characters. We can use the os.stats() function to inspect the stats of this file in storage. Let’s pass the path to the week-2-bf66-elevation.csv file into the os.stats() function and see how many bytes are required to store this file.\n\nelev_csv_path = os.path.join(os.getcwd(), \"week-2\", \"week-2-bf66-elevation.csv\")\nfile_stats = os.stat(elev_csv_path)\nprint(\"File Size in Bytes is:\",  file_stats.st_size)\n\nFile Size in Bytes is: 23845"
  },
  {
    "objectID": "lab-2.html#file-formats",
    "href": "lab-2.html#file-formats",
    "title": "Introduction",
    "section": "File formats",
    "text": "File formats\nA file format describes how data is encoded as binary sequences in files (sequences of 1 and 0 digits). The filename’s extension indicates the file format used (e.g. .jpg is a JPEG file, .tif is a TIFF or GeoTIFF file, .csv is a CSV file). Some file formats also include a header or magic number inside the file that indicates what the file format is. The header can also include some metadata information about the file.\n\nA Portable Network Graphics (PNG) file is a common file format for storing image data. It is identified by a .png ending and consists of sections of bytes on disk arranged as:\n\nPNG signature including a magic number for the start of the file and a PNG file identifier.\nImage header with image metadata such as the size of the image.\nImage data.\nImage end to indicate the end of the PNG file on disk.\n\n\nDifferent file formats encode data in different ways, and, thus, have different strengths and weaknesses. Some file formats prioritise efficient storage (compression) of data on disk (small file sizes and quick transfer), other prioritise quick read and writing of data, and others prioritise cross-platform compatibility or interpretation.\nThe various file formats for storing vector geospatial data provide a good illustration of how different formats store the same data but in ways that are better suited for different applications and uses. This is discussed here and here.\nMany of you will have used shapefiles as a format for storing vector geospatial data. A strength of shapefiles is the range of software applications that can read and write data from and to them. However, they have drawbacks which mean they’re not suited to some use cases:\n\nMultifile format which makes data handling harder (you need a .shp, .shx, .prj, and .dbf file).\nFile size is limited to 2 GB which is prohibits their use for storing large datasets.\nAttribute names are limited to 10 characters which can preclude using descriptive attribute and column names.\nEach shapefile can only store one type of geometry (point or line or polygon) which prohibits representing complex geographic features in a single file.\nNo null value which can introduce complications for handling missing data.\nData types are limited to 256 characters which precludes storing large numbers / text strings.\n\nIt is important to be aware of the characteristics of particular file formats and what their limits or benefits mean for your analysis. A simple example of why this is important: we’ve processed several harvester yield datasets from different fields into a single dataset and want to save this dataset to file. If this dataset is larger than 2GB and we try and save to a shapefile there will be data loss."
  },
  {
    "objectID": "lab-2.html#directories-and-file-systems",
    "href": "lab-2.html#directories-and-file-systems",
    "title": "Introduction",
    "section": "Directories and file systems",
    "text": "Directories and file systems\nFiles are organised within a hierarchy of directories and sub-directories (or folders) in a computer system. We’re working in a Linux environment so the directory hierachy starts at the root denoted by /. Sub-directories are separated by /.\nA program has a current working directory which is its current location within the directory hierarchy.\nWe can get the current working directory by calling the os.getcwd() function.\n\nos.getcwd()\n\n'/home/jovyan/work'\n\n\nWe can get a list of files and sub-directories within the current working directory by calling the os.listdir() function.\nos.listdir()\nA path describes the location of a file within the computer system’s directory structure. We can create paths to files using the os.path.join() function. We pass in string data representing sub-directories and filenames and the os.path.join() function creates a file path.\nLet’s get the file path for this notebook file: lab-2.ipynb.\n\nos.path.join(os.getcwd(), \"lab-2.ipynb\")\n\n'/home/jovyan/work/lab-2.ipynb'"
  },
  {
    "objectID": "lab-2.html#files-in-python",
    "href": "lab-2.html#files-in-python",
    "title": "Introduction",
    "section": "Files in Python",
    "text": "Files in Python\nIn Python, it is possible to read and write files in text and binary modes.\n\nText mode\nText mode involves reading and writing string data from and to the file.\nA text file contains encoded characters. ASCII and Unicode are character sets that define how characters (e.g. 1, 2, 3, 66, A, b, !) are encoded in binary (sequences of 1 and 0 digits) in a file.\nA character set translates characters into numbers and an encoding translates numbers into binary.\n\nASCII\nASCII stands for the American Standard Code for Information Interchange and has encodings for 128 English characters, numbers, and some special characters. ASCII characters are encoded using 7-bits. You can see the full ASCII character set here.\nIn ASCII, uppercase G is represented by the number 71, uppercase I is represented by the number 73, and uppcase S is represented by the number 83.\nThus, GIS in ASCII is written as 71 73 83 in its numeric representation and 01000111 01001001 01010011 in its binary representation (i.e. how it would be stored in a file).\n\n\nUnicode\nUnicode is a more modern and comprehensive character set of text symbols covering modern and ancient languages. Common encodings of the Unicode character set are UTF-8 and UTF-16. The Unicode character set includes over 1,000,000 characters and aims to be a universal system for representing and storing text in computer systems.\nUnicode characters can be encoded in UTF-8 using one to four bytes. More common symbols (e.g. the ASCII character set) are encoded using one byte for efficient storage.\nThe Python docs suggest UTF-8 is the modern de-facto standard so it is often the default encoding or a good one to choose if you are not sure how your data is encoded.\n\n\n\nBinary mode\nReading files in binary mode does not assume that specific bytes represent human readable characters. When reading files in binary mode, sequences of bytes are read from the file into Python bytes objects in memory. Images such as JPEG files would be read in binary mode.\nTo be clear, both text and binary data is stored in binary format on disks. However, when reading in text data the binary data on disk is converted to text characters based on the encoding scheme used and read into string objects. When reading data in binary mode the binary data is read straight into memory as bytes objects. Reading and writing data in text mode will be slower because of the encoding overhead.\n\n\nOpening files\nThe open() function opens a connection to a file on disk, or creates a new file if it does not exist, and returns a file connection object.\nTypically, open() is called by specifying a filename, mode, and encoding as arguments: open(filename, mode, encoding).\n\nfilename: the path and filename of the file to be opened.\nmode: the mode to open the connection to file in. To open files in text mode use r for read only, w for write only, a for appending data to the file, r+ for reading and writing. To open files in binary mode use rb for read only, wb for write only, and rb+ for reading and writing.\nthe default is to open connections in text mode - be careful if you are opening a connection to a file that is not text data.\nencoding: the encoding of the data in the file.\n\nLet’s open up a connection to a CSV file and explore the file object that’s returned.\n# open a connection to a csv file\n# path to csv file\nelev_csv_path = os.path.join(os.getcwd(), \"week-2\", \"week-2-bf66-elevation.csv\")\n\n# open the file \nf = open(elev_csv_path, \"r\", encoding=\"utf-8\")\nWe’ve opened a connection to a CSV file in read mode \"r\" and with a utf-8 encoding. This has returned to us f, a variable pointing to a file object.\nWhat kind of object is f pointing to?\n\ntype(f)\n\n_io.TextIOWrapper\n\n\nVariable f is pointing at a file object, or, more specifically, an _io.TextIOWrapper type object. The IO stands for input / output which is another way of saying reading and writing data. The Text refers to the fact that f will be able to read data to string Python objects or write data from string Python objects to binary in files (i.e. it’s reading in text mode). The conversion from string to binary and binary to string is determined by the encoding (e.g. UTF-8 or ASCII).\nThe file object f is a connection to a file and it provides the methods to read (write) data from (to) this file via the connection.\n\n\nReading files\nA read operation will copy bytes from the file on disk to the computer’s memory. The file object,f, has the read() and readline() methods.\nThe read(size=n) method in text mode will read n characters from the file. If n is omitted or is a negative number the read() function will read all of the characters in the file.\nThe readline() will read until a newline in the text file. Text files have newline characters that denote the end of a line. On Windows the newline character is \\r\\n and on Linux / MacOS it is \\n.\nLet’s test out the read() and readline() methods.\n\n# read first 1000 characters from the csv file connected to by f\nchars_1000 = f.read(1000)\nprint(chars_1000)\n\nNorthing,Easting,Lat,Lon,Elevation\n6503882.129,545428.0052,-31.59926178,117.4788733,268.92\n6503806.024,545427.6719,-31.59994843,117.4788733,265.908\n6503881.794,545504.4826,-31.59926178,117.4796795,268.171\n6503805.688,545504.1488,-31.59994843,117.4796795,265.413\n6503729.582,545503.8149,-31.60063507,117.4796795,263.08\n6503653.477,545503.481,-31.60132172,117.4796795,260.739\n6504185.881,545582.2978,-31.5965152,117.4804856,273.014\n6504109.775,545581.9634,-31.59720185,117.4804856,273.273\n6504033.67,545581.629,-31.59788849,117.4804856,273.896\n6503957.564,545581.2946,-31.59857514,117.4804856,272.369\n6503881.458,545580.9601,-31.59926178,117.4804856,268.96\n6503805.352,545580.6257,-31.59994843,117.4804856,264.807\n6503729.246,545580.2913,-31.60063507,117.4804856,262.857\n6503653.141,545579.9568,-31.60132172,117.4804856,260.894\n6504337.756,545659.4474,-31.59514191,117.4812918,274.777\n6504261.651,545659.1125,-31.59582856,117.4812918,273.813\n6504185.545,545658.7775,-31.5965152,117.4812918,272.371\n6504\n\n\n\n# read 10 lines of the csv file \nfor i in range(0, 10):\n    print(f.readline())\n\n109.439,545658.4425,-31.59720185,117.4812918,273.274\n\n6504033.333,545658.1076,-31.59788849,117.4812918,272.729\n\n6503957.227,545657.7726,-31.59857514,117.4812918,270.546\n\n6503881.122,545657.4376,-31.59926178,117.4812918,267.788\n\n6503805.016,545657.1026,-31.59994843,117.4812918,264.559\n\n6503728.91,545656.7676,-31.60063507,117.4812918,262.08\n\n6504641.842,545737.2702,-31.59239533,117.482098,273.551\n\n6504565.737,545736.9348,-31.59308198,117.482098,273.001\n\n6504489.631,545736.5993,-31.59376862,117.482098,274.043\n\n6504413.525,545736.2638,-31.59445527,117.482098,274.396\n\n\n\nYou might notice that the call to readline() does not start with the row of column headers. This is because the file object f keeps a record of a position in the file up to where it has read bytes from. The call to readline() will start reading lines of characters from the file where the previous call to read(1000) finished.\nWe can use the tell() method to see a file object’s current position in a file.\n\nprint(f\"current position in the file is {f.tell()}\")\n\ncurrent position in the file is 1588\n\n\nThe reason that read() or readline() provide the option to read data in n characters at a time or line by line is to help you avoid reading in more data than can fit in your computer’s memory. If you had a large file and called read() on it, without specifying the number of characters to read, it could fill up your memory.\nAs we’re reading from the file in text mode, the binary data from the file should be converted to Python string objects. We can check this.\n\ntype(chars_1000)\n\nstr\n\n\n\n\nWriting files\nThe write() method of the file object writes Python objects (e.g. strings) to files. The data will then be stored on disk in a specified format until it is read again by another program.\nWhen writing data in text mode Python string objects (characters) are encoded (e.g. using ASCII or UTF-8) and stored as bytes on the disk.\nLet’s demonstrate a write operation by writing the 1000 characters stored in chars_1000 to a new file. First, we need to open a connection to the new file in write mode and specify an encoding.\nf2 = open(\"write_demo.csv\", \"w\", encoding=\"utf-8\")\nNow, we can call the write() method of the file object f2 and pass write() the variable chars_1000 which points to 1000 characters stored as a string object. If the write is successful, it should return a number telling us how many characters were written (it should be 1000) and you should be able to see the file write_demo.csv in your current working directory.\n\nf2.write(chars_1000)\n\n1000\n\n\n\n\nClosing files\nAfter you have finished reading or writing data from and to the file, it is important to close() the connection to the file. The file object’s close() method does this.\nOnce the close() method has been called on a file object it is no longer possible to read or write data from and to the file. This is important to prevent accidental data loss or corruption.\nWe have two open file connections, let’s close them.\nf.close()\nf2.close()"
  },
  {
    "objectID": "lab-2.html#context-managers",
    "href": "lab-2.html#context-managers",
    "title": "Introduction",
    "section": "Context managers",
    "text": "Context managers\nContext managers - the “correct” way to read and write data from and to files in Python.\nAbove we have gone through the process of opening connections to files, reading and writing data, and closing connections to files. However, there are lots of moving parts to this approach as you need to keep track of which connections are open to which files and to ensure you close connections when they are no longer needed. As applications grow and work with more data this can require handling many file connections which adds complexity and increases potential for mistakes / errors. Such mistakes / errors can result in data loss, corrupting files, or reduced security if file connections to private data are leaked.\nThere are two “better” ways to read and write data in Python:\n\nusing context managers.\nusing methods and functions provided by packages (e.g. pandas read_csv() function).\n\nLet’s open a file and read data from it using a context manager. A context manager ensures that connections to files are properly closed without explicitly having to code for it.\nTo create a context, use the with statement.\nWe’ve already demonstrated how to open, read, and write data in text mode from a CSV file. Let’s use a context manager to demonstrate how to work with files in binary mode. Above we introduced the PNG file format for storing image data. We have a PNG file showing a Google Earth aerial image of the field we’re working in. The first few bytes of the PNG file should be the PNG signature including a magic number for the start of the file and an ASCII representation of the letters PNG.\n\npng_file_path = os.path.join(os.getcwd(), \"week-2\", \"week-2-bf66-low-res.png\")\n\nwith open(png_file_path, \"rb\") as f:\n    print(f.read(1)) # read and print the first byte\n    print(f.read(3)) # read and print the second, third, and fourth bytes\n\nb'\\x89'\nb'PNG'\n\n\nYou will note that we opened a connection to the PNG file in rb mode. This indicates we are reading data in binary mode. Here, instead of reading in the data a character at a time (as we did when reading data in text mode) we are reading in n bytes of data.\nYou will also note when printing the binary data that is read from the PNG file there is a b in front of the text. This indicates the data being printed is of bytes type.\nFinally, you will notice that we did not need to close() the file connection f as this is handled for us by working within the context of the with statement.\nThis is what the data in the PNG file we have just been reading looks like.\n\n\n\nImagery (c) 2022 CNES | Airbus, Imagery (c) 2022 | Airbus, Landsat | Copernicus, Maxar Technologies, Map Data (c) 2022"
  },
  {
    "objectID": "lab-2.html#pandas-io",
    "href": "lab-2.html#pandas-io",
    "title": "Introduction",
    "section": "Pandas I/O",
    "text": "Pandas I/O\nMany Python packages provide functions and methods to read and write data that safely open and close connections to files.\nThe pandas read_csv() function reads CSV data from disk into a pandas DataFrame object in a single line of code without us needing to explicitly close a connection to the file.\nLet’s read some canola yield data collected by a harvester and stored as a CSV file into our program using the pandas read_csv() function.\n\ncanola_yield_df = pd.read_csv(os.path.join(os.getcwd(), \"week-2\", \"week-2-bf66-canola-yield.csv\"))\nprint(f\"The shape of the canola yield DataFrame is {canola_yield_df.shape}\")\n\nThe shape of the canola yield DataFrame is (80755, 8)\n\n\n\ncanola_yield_df.head()\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      Longitude\n      Latitude\n      Crop\n      Time\n      Variety\n      DryYield\n      Elevation\n    \n  \n  \n    \n      0\n      0\n      117.497719\n      -31.606760\n      5\n      11/11/2020 8:01\n      43Y23 RR\n      0.227\n      264.32\n    \n    \n      1\n      1\n      117.497693\n      -31.606743\n      5\n      11/11/2020 8:01\n      43Y23 RR\n      0.480\n      264.34\n    \n    \n      2\n      2\n      117.497671\n      -31.606733\n      5\n      11/11/2020 8:01\n      43Y23 RR\n      0.568\n      264.42\n    \n    \n      3\n      3\n      117.497659\n      -31.606738\n      5\n      11/11/2020 8:01\n      43Y23 RR\n      0.629\n      264.48\n    \n    \n      4\n      4\n      117.497646\n      -31.606742\n      5\n      11/11/2020 8:01\n      43Y23 RR\n      0.627\n      264.60\n    \n  \n\n\n\n\nPandas provides a range of convenient functions for reading and writing data - you can find a list of them here."
  },
  {
    "objectID": "lab-2.html#parquet-files",
    "href": "lab-2.html#parquet-files",
    "title": "Introduction",
    "section": "Parquet files",
    "text": "Parquet files\nSo far we have been working with data in CSV format. The CSV format has many strengths for storing tabular data including:\n\nmany software applications provide tools to read and write CSV data.\nthe data structure is relatively intuitive with human readable characters encoded in binary, data values (fields) comprise binary representations of characters and are separated by comma symbols (hence the name), and rows (records) are separated by newline symbols.\nflexibility to choose different encodings of the text data.\n\nHowever, CSV files require that each data value is stored even if there is lots of repetition. For example, if there is a column that denotes the field name or id, for every row in the table the field name or id value would be repeated. As datasets get large, this can cause CSV files to increase in size which has subsequent storage costs.\nAn alternative file format for storing tabular is parquet. Parquet files are optimised for storage. This provides more efficient use of hard drives, cheaper cloud storage costs, and quicker transmission of data over the internet.\nParquet files have several optimisations for storing tabular data. Whereas CSV files are based around row storage, parquet files are based on column storage.\n\nParquet files can optimise storage of tabular data using run length encoding and dictionary encoding.\nRun length encoding is useful for reducing storage when there are runs of the same value within a column. For example, in the canola_yield_df DataFrame the values in the Crop column repeat. Instead of storing every value, we can store the two values: the value that repeats and the number of repetitions in the column (e.g. (5, 80755) - instead of storing the number 5 80,755 times as would be the case in a CSV file we can just store two numbers 5 and 80,755). Run length encoding is not suited for CSV files as the data is stored by row, and, often, within a row you’ll have data of different types (e.g. string / text, numeric, and dates). This structure doesn’t lend itself to encoding runs of the same value - repitition in tabular data generally runs down columns not across rows.\nDictionary encoding is useful when we need to store large values (e.g. long names or large numbers). Instead of writing the large value repeatedly in the file a smaller value is written and there is a dictionary which acts as a look up table to correspond the small value to the actual large value. This means the large value only needs to be stored once.\nFor a single field, we have 80,755 records (rows) in the DataFrame. If we scaled up this analysis to work with data collected from harvesters across many fields in Western Australia we would quickly accumulate a large volume of data. At some stage we will hit issues with storing and transferring the data and it might be appropriate to switch from CSV to parquet files for data storage.\ncanola_yield_df.to_parquet(os.path.join(os.getcwd(), \"week-2\", \"week-2-bf66-canola-yield.parquet\"))\nLet’s compare the size of the CSV file storing the canola yield data and the parquet file we just saved. The parquet file should be much smaller.\n\nfile_stats_csv = os.stat(os.path.join(os.getcwd(), \"week-2\", \"week-2-bf66-canola-yield.csv\"))\nprint(\"CSV file size in bytes is:\",  file_stats_csv.st_size)\nfile_stats_parquet = os.stat(os.path.join(os.getcwd(), \"week-2\", \"week-2-bf66-canola-yield.parquet\"))\nprint(\"Parquet file size in bytes is:\",  file_stats_parquet.st_size)\n\nCSV file size in bytes is: 5697740\nParquet file size in bytes is: 1549996"
  },
  {
    "objectID": "lab-2-self-guided.html",
    "href": "lab-2-self-guided.html",
    "title": "Introduction",
    "section": "",
    "text": "Data analysis tasks involve reading data stored in files on disks, servers in the cloud, or recorded by sensors. Also, we need to save the results of our analysis or datasets we have generated to files.\n\n\nIn this lab we will write a program that can convert crop yield data collected from a harvester into a geospatial data structure for vector data and write this data to disk using a geospatial file format. You will also write a program that can read geospatial image (raster) data from files into array objects that can be analysed in Python programs.\nThis lab will introduce:\n\ngeospatial data file formats\ntechniques for reading and writing from geospatial data from and to files\nPython data structures for representing vector data (GeoDataFrame objects)\nPython data structures for representing raster data (NumPy ndarray objects)"
  },
  {
    "objectID": "lab-2-self-guided.html#setup",
    "href": "lab-2-self-guided.html#setup",
    "title": "Introduction",
    "section": "Setup",
    "text": "Setup\n\nRun the labs\nYou can run the labs locally on your machine or you can use cloud environments provided by Google Colab. If you’re working with Google Colab be aware that your sessions are temporary and you’ll need to take care to save, backup, and download your work.\n  \n\n\nDownload data\nIf you need to download the date for this lab, run the following code snippet.\nimport os\n\nif \"week-2\" not in os.listdir(os.getcwd()):\n    os.system('wget \"https://github.com/data-analysis-3300-3003/data/raw/main/data/week-2.zip\"')\n    os.system('unzip \"week-2.zip\"')\n\n\nWorking in Colab\nIf you’re working in Google Colab, you’ll need to install the required packages that don’t come with the colab environment.\nif 'google.colab' in str(get_ipython()):\n    !pip install geopandas\n    !pip install pyarrow\n    !pip install mapclassify\n    !pip install rasterio\n\n\nImport modules\nimport pandas as pd\nimport geopandas as gpd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport rasterio\nimport json\nimport os\nimport folium\nimport plotly.express as px\nimport plotly.io as pio\nimport pprint\n\n# setup renderer\nif 'google.colab' in str(get_ipython()):\n    pio.renderers.default = \"colab\"\nelse:\n    pio.renderers.default = \"jupyterlab\""
  },
  {
    "objectID": "lab-2-self-guided.html#geospatial-data",
    "href": "lab-2-self-guided.html#geospatial-data",
    "title": "Introduction",
    "section": "Geospatial data",
    "text": "Geospatial data\nGeospatial data is used to take geographic features or phenomenon and represent them as data in computer program or file.\nThere are two main types of geospatial data:\n\nvector data - point, line, or polygon geometries\nraster data - images and arrays\n\nThere are two components to geospatial data:\n\nPositional information describing location, shape, and extent (e.g. an (x, y) coordinate pair representing the location of a weather station).\nAttribute information describing characteristics of the phenomenon or entity (e.g. a name:value pair recording the name of the weather station name:'Perth Airport').\n\n\nRaster data model\nRaster data breaks the Earth’s surface up into a grid of cells (pixels). Each pixel is assigned a value that corresponds to the geographic feature or phenomenon of interest. For example, pixels in a raster precipitation dataset would be assigned a numeric value that represents the amount of precipitation that fell at that location. Pixels in a land cover map would have an integer value that corresponds to a particular land cover class label. The values assigned to pixels in a raster dataset are the attribute information.\n\nThe size of the pixels relative to their position on the Earth’s surface determines the spatial detail that can be resolved in the raster dataset. A land cover map with pixels that represent a 1 km x 1 km portion of the Earth’s surface will not be able to identify features such as individual buildings.\n\n\n\nVector data model\nVector data uses point, line, or polygon geometries to represent geographic features.\nCoordinate pairs: point locations or the vertices in lines and polygons are represented using coordinate pairs. The coordinate pairs indicate where that feature is located on the Earth’s surface (relative to an origin); longitude and latitute are commonly used as coordinate pairs.\nAttribute information: vector data also stores non-spatial attribute information which describe characteristics of the geographic phenomenon or entity represented by the geometry feature."
  },
  {
    "objectID": "lab-2-self-guided.html#geopandas-geodataframe",
    "href": "lab-2-self-guided.html#geopandas-geodataframe",
    "title": "Introduction",
    "section": "GeoPandas GeoDataFrame",
    "text": "GeoPandas GeoDataFrame\nA GeoPandas GeoDataFrame is a tabular data structure for storing vector geospatial data and is based on a regular pandas DataFrame.\nA GeoDataFrame consists of columns of non-spatial attributes similar to a pandas DataFrame. However, a GeoDataFrame also has a geometry column which is a GeoSeries of geometries for the spatial data associated with each row.\nIn Python, geometries are represented as Shapely Geometry objects. The geometry column in a GeoPandas GeoDataFrame is a Series of Shapely Geometry objects. Printing a Shapely Geometry object returns a Well Known Text (WKT) string description of the geometry (e.g. POINT (0, 1)). The geometry column of a GeoDataFrame (or a GeoSeries) can be viewed as a sequence of Shapely Geometry objects:\na_geoseries = [POINT (0, 1), POINT (0, 2), POINT (2, 3)]\nShapely provides tools for representing geometries in Python programs. It does not provide tools for reading geometry data from disk or handling attribute data. GeoPandas GeoDataFrame and GeoSeries combine Shapely’s functionality for handling geometries with tools for reading and writing vector data, handling attributes, and visualisation. Therefore, we will focus on using GeoDataFrames in these labs.\nLet’s convert a CSV file with longitude, latitude, and elevation columns into a GeoDataFrame. First, let’s read the CSV file in as a pandas DataFrame.\n\nelev_df = pd.read_csv(os.path.join(os.getcwd(), \"week-2\", \"week-2-bf66-elevation.csv\"))\nelev_df.head()\n\n\n\n\n\n  \n    \n      \n      Northing\n      Easting\n      Lat\n      Lon\n      Elevation\n    \n  \n  \n    \n      0\n      6503882.129\n      545428.0052\n      -31.599262\n      117.478873\n      268.920\n    \n    \n      1\n      6503806.024\n      545427.6719\n      -31.599948\n      117.478873\n      265.908\n    \n    \n      2\n      6503881.794\n      545504.4826\n      -31.599262\n      117.479680\n      268.171\n    \n    \n      3\n      6503805.688\n      545504.1488\n      -31.599948\n      117.479680\n      265.413\n    \n    \n      4\n      6503729.582\n      545503.8149\n      -31.600635\n      117.479680\n      263.080\n    \n  \n\n\n\n\nNow, let’s use the longtitude and latitude columns in the DataFrame to convert the elevation data into a GeoPandas GeoDataFrame.\n\n# Convert the elevation data to a spatial format\npoints = gpd.points_from_xy(elev_df[\"Lon\"], elev_df[\"Lat\"], crs=\"EPSG:4326\")\nprint(f\"points is of type {type(points)}\")\n\nelev_gdf = gpd.GeoDataFrame(elev_df, geometry=points)\nprint(f\"elev_gdf is of type {type(elev_gdf)}\")\n\nelev_gdf.head()\n\npoints is of type <class 'geopandas.array.GeometryArray'>\nelev_gdf is of type <class 'geopandas.geodataframe.GeoDataFrame'>\n\n\n\n\n\n\n  \n    \n      \n      Northing\n      Easting\n      Lat\n      Lon\n      Elevation\n      geometry\n    \n  \n  \n    \n      0\n      6503882.129\n      545428.0052\n      -31.599262\n      117.478873\n      268.920\n      POINT (117.47887 -31.59926)\n    \n    \n      1\n      6503806.024\n      545427.6719\n      -31.599948\n      117.478873\n      265.908\n      POINT (117.47887 -31.59995)\n    \n    \n      2\n      6503881.794\n      545504.4826\n      -31.599262\n      117.479680\n      268.171\n      POINT (117.47968 -31.59926)\n    \n    \n      3\n      6503805.688\n      545504.1488\n      -31.599948\n      117.479680\n      265.413\n      POINT (117.47968 -31.59995)\n    \n    \n      4\n      6503729.582\n      545503.8149\n      -31.600635\n      117.479680\n      263.080\n      POINT (117.47968 -31.60064)\n    \n  \n\n\n\n\n\nRecap quiz\nYou will need to refer to the GeoPandas documentation to answer these questions.\n\n\nWhat does executing the GeoDataFrame method points_from_xy() return?\n\npoints_from_xy() expects a pandas Series objects for x and y coordinates and coordinate reference system. It will return to a GeoPandas GeometryArray object which stores a POINT geometry object for each x and y pair and can be converted into a GeoSeries object.\n\n\n\n\n\nThe GeoDataFrame() constructor function can take three arguments. What are these arguments and how do they enable the creation of a GeoDataFrame object?\n\nThe GeoDataFrame() constructor function requires a pandas DataFrame as its first argument. This data is the non-spatial attributes. The second (optional) argument is a GeoPandas object which stores geometry objects associated with each row (this could also be a string denoting the column of a DataFrame storing geometries. The third (optional) argument is a crs denoting the coordinate reference system for the geometry data."
  },
  {
    "objectID": "lab-2-self-guided.html#geojson",
    "href": "lab-2-self-guided.html#geojson",
    "title": "Introduction",
    "section": "GeoJSON",
    "text": "GeoJSON\nSo far we have been reading and writing non-spatial tabular data. Parquet and CSV files are well suited for storing tabular data.\nHowever, there are different ways of structuring data, some datasets don’t lend themselves to tabular structures, and there are different uses of data files than storage on disk.\nJSON data (JavaScript Object Notation for its full name) is a widely used format for data interchange (exchanging data between programs, computers, clients, and servers).\nJSON represents data as key:value pairs enclosed within curly brackets {} (you might notice the similarity with Python’s dictionary data structure).\nThis is an example of JSON data:\n{\n    \"title\": \"Introducing JSON\",\n    \"url\": \"https://www.json.org/json-en.html\"\n}\nThe values in JSON data can include text (strings), numbers, arrays (lists), and nested JSON objects. Like the CSV format, JSON is a text based format where human readable characters are encoded in binary using UTF-8 or UTF-16.\nGeoJSON is an extension of the JSON format for storing and exchanging spatial data. One of GeoJSON’s uses is sending spatial data to web browsers to render as layers on web maps.\nGeoJSON represents geographic features as vector data (points, lines, and polygon geometries) and can also store non-spatial attribute information.\nSpatial data in GeoJSON are represented using geometry types which include:\nPoint\n{\"type\": \"Point\", \"coordinates\": [1, 1]}\nLineString\n{\"type\": \"LineString\", \"coordinates\": [[1, 1], [2, 2]]}\nPolygon\n{\"type\": \"Polygon\", \"coordinates\": [[[1, 1], [2, 2], [1, 2], [1, 1]]]}\nFeature types include attribute data as properties with geometry types.\n{\n    \"type\": \"Feature\",\n    \"geometry\": {\n        \"type\": \"Point\",\n        \"coordinates\": [0, 0]\n    }, \n    \"properties\": {\n        \"name\": \"Perth Airport\"\n    }\n}\nA FeatureCollection is a collection of Features.\n{\n    \"type\": \"FeatureCollection\",\n    \"features\": [\n        {\n            \"type\": \"Feature\",\n            \"geometry\": {\n                \"type\": \"Point\",\n                \"coordinates\": [0, 0]\n            }, \n            \"properties\": {\n                \"name\": \"Perth Airport\"\n            }\n        },\n        {\n            \"type\": \"Feature\",\n            \"geometry\": {\n                \"type\": \"Point\",\n                \"coordinates\": [10, 1]\n            }, \n            \"properties\": {\n                \"name\": \"Broome Airport\"\n            }\n        }\n        \n    ]\n}\nYou can read More than you ever wanted to know about GeoJSON for a description of the GeoJSON format.\nLet’s get the first two rows of the GeoDataFrame and convert them to GeoJSON format. GeoDataFrames have a to_json() method which can be used to convert the data in the GeoDataFrame into a string object in GeoJSON format.\n\n# Get the first two rows of the elevation GeoDataFrame and convert to GeoJSON\nelev_gdf_2 = elev_gdf.iloc[0:2, :]\nelev_gdf_2\n\n\n\n\n\n  \n    \n      \n      Northing\n      Easting\n      Lat\n      Lon\n      Elevation\n      geometry\n    \n  \n  \n    \n      0\n      6503882.129\n      545428.0052\n      -31.599262\n      117.478873\n      268.920\n      POINT (117.47887 -31.59926)\n    \n    \n      1\n      6503806.024\n      545427.6719\n      -31.599948\n      117.478873\n      265.908\n      POINT (117.47887 -31.59995)\n    \n  \n\n\n\n\n\nelev_geojson_2 = elev_gdf_2.to_json()\nprint(f\"The GeoJSON data is stored as a {type(elev_geojson_2)} type object\")\nprint(\"\")\npprint.pprint(elev_geojson_2)\n\nThe GeoJSON data is stored as a <class 'str'> type object\n\n('{\"type\": \"FeatureCollection\", \"features\": [{\"id\": \"0\", \"type\": \"Feature\", '\n '\"properties\": {\"Northing\": 6503882.129, \"Easting\": 545428.0052, \"Lat\": '\n '-31.59926178, \"Lon\": 117.4788733, \"Elevation\": 268.92}, \"geometry\": {\"type\": '\n '\"Point\", \"coordinates\": [117.4788733, -31.59926178]}}, {\"id\": \"1\", \"type\": '\n '\"Feature\", \"properties\": {\"Northing\": 6503806.024, \"Easting\": 545427.6719, '\n '\"Lat\": -31.59994843, \"Lon\": 117.4788733, \"Elevation\": 265.908}, \"geometry\": '\n '{\"type\": \"Point\", \"coordinates\": [117.4788733, -31.59994843]}}]}')\n\n\nIn Python, the GeoJSON data that we have generated from our GeoDataFrame is stored as a string object. GeoJSON (and JSON) is a text-based data similar to CSV files. However, unlike the CSV format where data has a tabular structure with records arranged by row the GeoJSON data is based around nested objects of key:value pairs.\nAs we have subsetted the first two rows of our GeoDataFrame and converted them to GeoJSON we have generated a FeatureCollection object with two Features.\nEach row in the GeoDataFrame is converted to a Feature and each Feature has the column values per row stored in a properties object - these are the non-spatial attributes associated with each Point feature. The spatial information is stored in a geometry object which contains two key:value pairs. The value associated with the type key tells us this is a Point geometry and the array value associated with coordinates key defines the location.\nCompare the tabular display of the GeoDataFrame to the print of the GeoJSON to see how the non-spatial and spatial information in the table structure is converted to the GeoJSON nested format.\nWe can save a GeoDataFrame to GeoJSON using the GeoDataFrame’s to_file() method and setting the driver argument to GeoJSON.\n# Save the elevation GeoDataFrame to a GeoJSON file\nelev_gdf.to_file(os.path.join(os.getcwd(), \"week-2\", \"week-2-bf66-elevation.geojson\"), driver=\"GeoJSON\")\nCheck the GeoJSON file has saved to the directory specified. As it is text data, if you click on it you should be able to inspect its format in a text editor.\n\nRecap quiz\n\n\nIdentify two differences between the GeoJSON file format and a GeoPandas GeoDataFrame\n\n\n\nA GeoDataFrame is used to store geospatial data in memory for Python programs. A GeoJSON file format describes how geospatial data should be encoded when it is stored on disk.\n\n\nA GeoDataFrame uses a tabular structure to organise non-spatial and spatial attributes with each row corresponding to a feature. GeoJSON format uses dictionary-like structure of key:value pairs with geographic data (coordinates) stored as values with a geometry key and attribute data stored as values with a properties key.\n\n\n\nYou saved the elevation data to a GeoJSON file at this path: os.path.join(os.getcwd(), \"week-2\", \"week-2-bf66-elevation.geojson\").\nHead to the GeoPandas documentation and look up how to read files into GeoDataFrame objects. Read the elevation.geojson file into a GeoDataFrame referenced by the variable elev_from_file.\n## ADD CODE HERE ##\n\n\nanswer\n\nelev_from_file = gpd.read_file(os.path.join(os.getcwd(), \"week-2\", \"week-2-bf66-elevation.geojson\"))\nelev_from_file.head()\nNote, this answer assumes GeoPandas has been imported as gpd.\n\nWrite the data referenced by elev_from_file to disk as a GeoPackage.\n## ADD CODE HERE ##\n\n\nanswer\n\nelev_from_file.to_file(os.path.join(os.getcwd(), \"week-2\", \"week-2-bf66-elevation.gpkg\"), driver=\"GPKG\")"
  },
  {
    "objectID": "lab-2-self-guided.html#geotiff",
    "href": "lab-2-self-guided.html#geotiff",
    "title": "Introduction",
    "section": "GeoTIFF",
    "text": "GeoTIFF\nWe have demonstrated how we can read and write tabular data and vector geospatial data from and to files. However, many geospatial datasets are based on the raster data model where values are assigned to pixels and pixels represent locations on the Earth’s surface.\nA common source of raster data are remote sensing images captured by sensors on uncrewed aerial vehicles, aircraft, or satellites. Optical remote sensing images store the measured reflectance of light off the Earth’s land surface in different wavelenghts. Raster remote sensing images are often stored using the GeoTIFF format.\nA GeoTIFF file is based on the Tagged Image File Format (or .tiff file) which is a general format for storing image data. A TIFF file comprises:\n\na TIFF header which includes 8 bytes that tell us that the file is in TIFF format and where in the file (what byte number / byte offset from 0) the first Image File Directory is stored.\nImage File Directories which contains image metadata, a pointer to where the image data is in the file (what byte number / byte offset from 0), and the location of the next Image File Directory if there is more than one image stored in the TIFF file. Metadata is stored as fields which comprise a TIFF tag and it’s corresponding value.\nImage Data - the values associated with each pixel in the image. A single TIFF file can store multiple images.\n\n\nGeoTIFF files include extra information (metadata) as tags which describe the coordinate reference system (CRS) of the image data (i.e. where on the Earth’s surface the image data corresponds to), spatial resolution, no data values, and various other configurations described here.\nGeoTIFF files can store multiple images (i.e. raster layers) in a single file. This makes them well suited for storing remote sensing image data where each raster layer corresponds to measured reflectance in a particular wavelength.\nWe can use the functions provided by the rasterio package to read and write raster data in Python.\nWe can use rasterio to create a file connection to raster data stored in a GeoTIFF file and use this file connection object to read the raster data into a Python data structure. Rasterio reads raster data from GeoTIFF files on disk into NumPy ndarrays in memory.\nThe GeoTIFF file week-2-s2-summer-2020.tif stores remote sensing data covering the same field that the elevation and canola yield data were collected from. The remote sensing data was captured by the European Space Agency’s Sentinel-2 satellite (10 m spatial resolution).\nWe use the with statement and context managers to open() connections to GeoTIFF files to read() raster data from them using rasterio. As we’re using a context manager to handle connections to the file we don’t need to call close() on the file connection object.\n# path the the GeoTIFF file\ns2_path = os.path.join(os.getcwd(), \"week-2\", \"week-2-s2-summer-2020.tif\")\n\n# open the GeoTIFF file and read its metadata and image data\nwith rasterio.open(s2_path) as src:\n    meta = src.meta\n    rgb = src.read([4, 3, 2])\n    red_band = src.read(4)\n    green_band = src.read(3)\n    blue_band = src.read(2)\nThe file object src is the connection to the GeoTIFF file and it has a meta property. The meta property stores metadata that describes the raster data in the GeoTIFF file. Let’s explore this metadata.\n\npprint.pprint(meta)\n\n{'count': 23,\n 'crs': CRS.from_epsg(4326),\n 'driver': 'GTiff',\n 'dtype': 'float32',\n 'height': 232,\n 'nodata': None,\n 'transform': Affine(8.983152841195215e-05, 0.0, 117.47574397627584,\n       0.0, -8.983152841195215e-05, -31.58916713453456),\n 'width': 321}\n\n\nFrom the meta object we can see the data type of the raster:\n\nprint(meta[\"dtype\"])\n\nfloat32\n\n\nWe can also see the dimensions of each raster band:\n\nprint(f\"width: {meta['width']}\") \nprint(f\"height: {meta['height']}\") \n\nwidth: 321\nheight: 232\n\n\nThe count property of the meta object is the number of bands or raster layers in the GeoTIFF file:\n\nprint(f\"number of bands: {meta['count']}\")\n\nnumber of bands: 23\n\n\nAnd, we can see the coordinate reference system of the raster data:\n\nprint(meta[\"crs\"])\n\nEPSG:4326\n\n\n\nNumPy ndarrays\nCalling the read() method of the file connection object to the GeoTIFF file reads the raster data into a NumPy ndarray object. We can specify a number as an argument to the read() method to indicate which raster bands we want to read from the GeoTIFF file. For example, read(2) will read the second band. If we specify a list of numbers we will read several bands into a multidimensional ndarray object.\nNumPy is a library used for scientific and numerical computing and is based around an N-dimensional ndarray object. An ndarray is a grid of elements of the same data type. The dimensions of a NumPy ndarray are called axes. NumPy arrays can be created from sequences of values (e.g. stored in lists, tuples, other ndarrays).\nWe can create a simple 1-dimensional ndarray using the array() function.\n\n# create a 1D ndarray\narr1d = np.array([1, 2, 3])\narr1d\n\narray([1, 2, 3])\n\n\nThe rank (or number of dimensions) of a ndarray is the number of axes.\n\n# the rank (ndim) of an ndarry is the number of axes \nprint(f\"the rank of the ndarray is {arr1d.ndim}\")\n\nthe rank of the ndarray is 1\n\n\nThe shape of an ndarray tells us the size of each axis (how many elements are arranged along that axis).\n\n# the shape of the ndarray \nprint(f\"the shape of the ndarray is {arr1d.shape}\")\n\nthe shape of the ndarray is (3,)\n\n\nA ndarray with 2-dimensions is a matrix with rows arranged on the 0 axis and columns arranged on the 1 axis.\n\n# create a 2D ndarray\narr2d = np.array([[1, 2, 3], [4, 5, 6]])\narr2d\n\narray([[1, 2, 3],\n       [4, 5, 6]])\n\n\nThe ndarray pointed to by arr2d is a 2 x 3 matrix of numeric values. We can check this.\n\nprint(f\"the rank of the ndarray is {arr2d.ndim}\")\nprint(f\"the shape of the ndarray is {arr2d.shape}\")\n\nthe rank of the ndarray is 2\nthe shape of the ndarray is (2, 3)\n\n\nndarrays can be multidimensional. They can have more than two dimensions. Remote sensing images typically comprise multiple 2-dimensional arrays with each array corresponding to a raster of reflectance measured in a particular wavelength. This 3-dimensional raster data structure can be represented as a NumPy ndarray with the bands dimension on axis 0 (each band is a raster for a given wavelength), rows (height of each raster) on axis 1, and columns (width of each raster) on axis 2.\nLet’s create a ndarray with 3-dimensions.\n\n# create a 3D ndarray\narr3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\narr3d\n\narray([[[ 1,  2,  3],\n        [ 4,  5,  6]],\n\n       [[ 7,  8,  9],\n        [10, 11, 12]]])\n\n\n\nprint(f\"the rank of the ndarray is {arr3d.ndim}\")\nprint(f\"the shape of the ndarray is {arr3d.shape}\")\n\nthe rank of the ndarray is 3\nthe shape of the ndarray is (2, 2, 3)\n\n\nThe concept of N-dimensional arrays can be extended further. For example, a 4-dimensional ndarray could store a sequence of 3-dimensional ndarrays where the fourth dimension is time and the object represents remote sensing images captured across multiple dates.\n\nRecap quiz\nExecute the following code to read in a normalised difference vegetation index (NDVI) layer computed for the same field from a GeoTIFF file and use this data to answer the following questions.\n# path to the ndvi file\ns2_ndvi_path = os.path.join(os.getcwd(), \"week-2\", \"week-2-ndvi-summer-2020.tif\")\n\n# open the GeoTIFF file and read its metadata and image data\nwith rasterio.open(s2_ndvi_path) as src:\n    meta = src.meta\n    ndvi = src.read(1)\n\n\nWhat is the name of the variable that points to the metadata for the NDVI data read from the GeoTIFF file?\n\nmeta\n\nFind out what type of object the data referenced by meta is?\n## add code here ##\n\n\nanswer\n\nprint(type(meta))\n\nFind out what type of object the data referenced by ndvi is?\n## add code here ##\n\n\nanswer\n\nprint(type(ndvi))\n\nUse the meta object to identify how many bands the raster data stored in the GeoTIFF week-2-ndvi-summer-2020.tif has?\n## add code here ##\n\n\nanswer\n\nprint(f\"There are {meta['count']} bands in the GeoTIFF file\")\n\nFind out how many raster bands have been read into the ndarray object referenced by ndvi?\n## add code here ##\n\n\nanswer\n\n\nOne band has been read into the ndarray object pointed to by ndvi. This is a rank 2 ndarray with row and columns axes and no bands axis.\n\nprint(f\"the rank of the ndvi ndarray is {ndvi.ndim}\")\nprint(f\"the shape of the ndvi ndarray is {ndvi.shape}\")\n\n\n\nDo meta[“count”] and the length of the bands axis of the ndarray object generated by a call to read() have to return the same value?\n\nNot always. In this case they should return the same value as we are reading the one and only band stored in week-2-ndvi-summer-2020.tif in an ndarray object. However, the value at meta[“count”] will tell us the number of bands in the file while the number of bands stored in the ndarray resulting from a call to read() is determined by the number passed into read().\n\n\n\n\nVisualising raster data\nWe can use the imshow() function from the Plotly Express package to render data in NumPy ndarrays as an image. The imshow() function expects a NumPy ndarray of raster values to display and a colour map (color_continuous_scale) that relates raster pixel values to a colour on the computer screen.\n\n# Plot the red band\npx.imshow(red_band, color_continuous_scale=\"Reds\")\n\n\n\n\n\n# Plot the green band\npx.imshow(green_band, color_continuous_scale=\"Greens\")\n\n\n\n\n\n# Plot the Blue band\npx.imshow(blue_band, color_continuous_scale=\"Blues\")\n\n\n\n\n\nRecap quiz\nEarlier we read NDVI data for this field into a ndarray object referenced by ndvi. Visualise this data using the imshow() function and select a suitable colour scale from the Plotly Expess built-in options. NDVI values range from -1 to 1 with higher values associated with greener vegetation.\n## add code here ##\n\n\nanswer\n\npx.imshow(ndvi, color_continuous_scale=\"viridis\")\n\n\n\nColour\nA particular colour is defined by the intensity of light in different parts of the visible spectrum (e.g. yellow is a mixture of light in red and green wavelengths).\nColour is represented by combinations (addition) of red, green, and blue light. Red, green, and blue are primary colours and combine to form white. An absence of red, green, and blue is black. Secondary colours can be formed by the addition of primary colours of varying intensities (e.g. yellow is the addition of red and green, magenta is the addition of red and blue, and cyan is the addition of green and blue).\nComputer displays consist of red, green, and blue sub-pixels, which when activated with different intensities, are perceived as different colours. The range of colours that can be displayed on a computer display is called the gamut. Colour in computer programs is represented as a three byte hexadecimal number with byte 1 corresponding to red, byte 2 corresponding to green, and byte 3 corresponding to blue. Each byte can take the range of 0 to 255 in decimal. 0 indicates the absence of a colour and 255 indicates saturation of that colour:\n\nwhite: 255 255 255\nblack: 0 0 0\nred: 255 0 0\ngreen: 0 255 00\nblue: 0 0 255\n\n\n\n\nAdditive and subtractive colour models (source: CRCSI (2017))\n\n\nComputer displays represent colour through varying the intensity of sub-pixel displays of red, green, and blue light. Variability in data values in multiband rasters can be visualised by relating data values in one band to the intensity of one of the primary colours on the computer display. Visualising a multiband raster in this way creates an additive RGB or colour composite image - it is called a composite image because each pixel is a composite of red, green, and blue light.\nAbove we rendered the red, green, and blue band reflectance from the Sentinel-2 image separately. However, if we combine these reflectance measures into a composite image (e.g. where red reflectance is represented by sub-pixel intensity of red light) we can create a true colour image as if we were looking down on the Earth’s surface with our eyes.\nThe imshow() function can take a multiband NumPy ndarray and returns an RGB image.\nAbove, we read() bands 4, 3, and 2 from the GeoTIFF file into NumPy ndarray referenced by rgb. Band 4 corresponds to red reflectance in Sentinel-2 images, band 3 corresponds to green reflectance, and band 2 corresponds to blue reflectance. We can pass rgb into the imshow() function to generate an RGB image of the field.\nWe can check that rgb has three bands by printing its shape property.\n\nprint(f\"The shape of rgb is {rgb.shape}\")\n\nThe shape of rgb is (3, 232, 321)\n\n\nIf we check the imshow() docs we can see that it expects a NumPy ndarray where the bands (or channels as they are sometimes called with images) is the final axis. NumPy has a moveaxis() function where can move the bands dimension to the last axis position before plotting.\n\n# Plot the RGB image\npx.imshow(np.moveaxis(rgb, 0, 2), contrast_rescaling=\"minmax\")\n\n\n\n\n\n\nRecap quiz\nAt the file path noted below is a GeoTIFF file storing a normalised difference water index (NDWI) layer. Write a short program to read this raster data, identify the dimensions of the raster data, and visualise the data\nFile path to NDWI data: os.path.join(os.getcwd(), \"week-2\", \"week-2-ndwi-summer-2020.tif\")\n## add code here ##\n\n\nanswer\n\ns2_ndwi_path = os.path.join(os.getcwd(), \"week-2\", \"week-2-ndwi-summer-2020.tif\")\n\nwith rasterio.open(s2_ndwi_path) as src:\n    meta = src.meta\n    ndwi = src.read(1)\n\nprint(f\"the width of the raster layer is {meta['width']}\")\nprint(f\"the height of the raster layer is {meta['height']}\")\nprint(f\"the number of bands in the raster layer is {meta['count']}\")\n\npx.imshow(ndwi, color_continuous_scale=\"YlGn\")"
  },
  {
    "objectID": "lab-2-practice-exercises.html",
    "href": "lab-2-practice-exercises.html",
    "title": "Week 2 - Practice Exercises",
    "section": "",
    "text": "This notebook contains practice exercises related to week 2’s content on working with file systems and directories and reading data from files into Python programs.\nThese exercises are based on vector data products that delineate the extent of disaster and emergency event impacts. These products are generated by the European Commission Copernicus Emergency Management Service (EMS) - Rapid Mapping Activations to aid with disaster response. The EMS Rapid Mapping Activations include vector geospatial data delineating the extent of the event impact and ancillary spatial data layers relevant to disaster response (e.g. infrastructure, land use). They also include a high-quality cartographic product depicting the event impact (in a PDF or JPEG format).\nVector data for Tropical Cyclone Yasa has been obtained and stored in the folder week-2-practice. In these exercises you will need to read this vector data from files into your Python program and check the data was read in correctly. Please refer to the Tropical Cyclone Yasa (EMSR489: Fiji, 2020) information page to find out about the disaster event and the data products."
  },
  {
    "objectID": "lab-2-practice-exercises.html#file-systems-and-directories",
    "href": "lab-2-practice-exercises.html#file-systems-and-directories",
    "title": "Week 2 - Practice Exercises",
    "section": "File systems and directories",
    "text": "File systems and directories\nCan you use the os.listdir() function to list all the files in the week-2-practice folder?\nYou will need to pass the following path into os.listdir() as an argument.\nweek_2_practice_path = os.path.join(os.getcwd(), \"week-2-practice\")\n## ADD CODE HERE ##\n\n\nanswer\n\nos.listdir(week_2_practice_path)\n\n\n\nWhat spatial data file formats are used to store data in this directory?\n\n\n\nshapefile (.shp)\n\n\nJavaScript Object Notation or JSON (.json)\n\n\nKeyhole Markup Language Zipped (.kmz)"
  },
  {
    "objectID": "lab-2-practice-exercises.html#tropical-cyclone-yasa-fiji-2020",
    "href": "lab-2-practice-exercises.html#tropical-cyclone-yasa-fiji-2020",
    "title": "Week 2 - Practice Exercises",
    "section": "Tropical Cyclone Yasa (Fiji, 2020)",
    "text": "Tropical Cyclone Yasa (Fiji, 2020)\nTropical Cyclone Yasa struck Fiji in December 2020 causing substantial flood damage. It is denoted by the EMSR code EMSR489. The below image is the cartographic map output depicting damage and key features surrounding Labasa on Vanua Levu.\n\nThe folder week-2-practice stores some of the vector data used to generate layers on this image. Can you identify the observedEvent layer in the list of files in this directory, create a path to this file, and read it into your program?\nUse the shapefile with a .shp ending for this task and read the data to a variable named obs_event_gdf.\nTip - part of the code to generate the path to the file is:\nobs_event_path = os.path.join(os.getcwd(), \"week-2-practice\", <FILENAME HERE>)\n## ADD CODE HERE ##\n\n\nanswer\n\nobs_event_path = os.path.join(os.getcwd(), \"week-2-practice\", \"EMSR489_AOI07_GRA_PRODUCT_observedEventA_r1_v1.shp\")\nobs_event_gdf = gpd.read_file(obs_event_path)\n\n# check obs event gdf is a GeoDataFrame and the data looks sensible\nprint(type(obs_event_gdf))\nobs_event_gdf.head()\n\nIf you have successfully read the observed event data into your program you should be able inspect it’s structure and information. The head of a tabular dataset should be displayed with one row per-feature which has a POLYGON geometry and several attributes.\nGeoPandas GeoDataFrame objects have an explore() method which enables quick rendering of data on a web map. We use the column argument to specify which of the GeoDataFrame column values to map to colours on the display and we use the cmap (stands for colourmap) argument to pass in a list of colours to represent different column values. Here, we use blue shades to represent flood impacts and brown to represent tree damage.\nWe use the variable m to reference the web map object that we can visualise on our display. This means we can refer to m later in our program and add more layers to the map or restyle it.\n\nm = obs_event_gdf.explore(column=\"notation\", categorical=True, cmap = [\"cyan\", \"blue\", \"brown\"])\nm\n\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\nTransport routes form a key part of emergency response, can you read in the vector data that represents transportation routes using the JSON format?\n## ADD CODE HERE ##\n\n\nanswer\n\ntransportation_data_path = os.path.join(os.getcwd(), \"week-2-practice\", \"EMSR489_AOI07_GRA_PRODUCT_transportationL_r1_v1.json\")\ntransportation_gdf = gpd.read_file(transportation_data_path)\nprint(type(transportation_gdf))\ntransportation_gdf.head()\n\n\n\nWe can add the transportation layers to web map object referenced by m. Let’s represent values in the column info with different colours on the map.\nNote, when you render the map the legend for the observed event impact layer and the transportation layer might overlap. This is an interactive map. So, you can easily drag the legend around the display to where they work best for you.\n\ntransportation_gdf.explore(column=\"info\", m=m, cmap=[\"red\", \"black\", \"grey\"])\nm\n\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "lab-3.html",
    "href": "lab-3.html",
    "title": "Introduction",
    "section": "",
    "text": "Data visualisation is the process of relating data values to elements of a figure on a computer display.\nThe Grammar of Graphics is an underlying model that describes the mapping of data values to the visual elements of a figure. It provides a consistent framework for guiding us in how to take our data values and convert them into a figure that effectively represents the data and conveys the messages and insights we seek to communicate.\nIn the Grammar of Graphics a plot comprises data and a mapping. The mapping (not cartographic here) is a formal description of how data values map onto elements of a figure. The elements of a figure are termed aesthetics and consist of:\n\nlayers - geometric elements that represent data values such as points (e.g. for scatter plots), lines (e.g. for lines of best fit), and polyons (e.g. for histograms or bar plots).\nscales - relate data values to visual display properties such as colour (e.g. a blue to red colour palette for temperature), size (e.g. larger points for larger numbers), position (e.g. location on axes), or shapes (e.g. using triangles for group A and circles for group B). Scales are used to draw axes and legends for figures.\ncoords - coordinate systems are used to map data values onto locations on the figure. On most 2D figures the x- and y-axes describe the coordinate space and on maps latitude and longitude describe the coordinate space (or you can use different coordinate reference systems).\ntheme - the background styling of the figure such as fonts for labels and background colours.\n\n\nReading the A Layered Grammar of Graphics paper by Hadley Wickham provides a detailed description of the core concepts for designing high-quality data visualisations.\n\n\nThis lab will generate interactive visualisations of crop yield data for wheat and canola collected by a harvester from a field in Western Australia and satellite data from the same field. This lab will provide an introduction to:\n\ninteractive visualisations using Plotly Express\nusing figures to represent and explore different features of a dataset\nusing colour to visualise patterns in a dataset\nvisualising spatiotemporal image datasets via animations"
  },
  {
    "objectID": "lab-3.html#setup",
    "href": "lab-3.html#setup",
    "title": "Introduction",
    "section": "Setup",
    "text": "Setup\n\nRun the labs\nYou can run the labs locally on your machine or you can use cloud environments provided by Google Colab. If you’re working with Google Colab be aware that your sessions are temporary and you’ll need to take care to save, backup, and download your work.\n  \n\n\nDownload data\nIf you need to download the data for this lab, run the following code snippet.\nimport os\n\nif \"week-3\" not in os.listdir(os.getcwd()):\n    os.system('wget \"https://github.com/data-analysis-3300-3003/data/raw/main/data/week-3.zip\"')\n    os.system('unzip \"week-3.zip\"')\n\n\nWorking in Colab\nIf you’re working in Google Colab, you’ll need to install the required packages that don’t come with the colab environment.\nif 'google.colab' in str(get_ipython()):\n    !pip install geopandas\n    !pip install pyarrow\n    !pip install mapclassify\n    !pip install rasterio\n\n\nImport modules\n# Import modules\nimport os\nimport pandas as pd\nimport geopandas as gpd\nimport plotly.express as px\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport rasterio\nimport plotly.io as pio\n\n# setup renderer\nif 'google.colab' in str(get_ipython()):\n    pio.renderers.default = \"colab\"\nelse:\n    pio.renderers.default = \"jupyterlab\""
  },
  {
    "objectID": "lab-3.html#interactive-visualisations",
    "href": "lab-3.html#interactive-visualisations",
    "title": "Introduction",
    "section": "Interactive visualisations",
    "text": "Interactive visualisations\nInteractive visualisations are important tools for exploring complex and multidimensional data. They enable users to quickly develop an understanding of a dataset’s structure and patterns by enabling them to interactively generate different views of the dataset.\nGenerally, interactive visualisations are controlled by user input from mouse events (click, drag, hover), and, in response to mouse events, change what data and information is rendered on the computer display.\nInteractive visualisations are important tools for both exploratory analysis and for communicating the results of analysis to a wider audience. For exploratory analysis the quick feedback provided by interactive visualisations allows analysts to quickly build up an understanding of the datasets they are working with, spot noise or missing data, refine and develop hypotheses and research questions, and select suitable analytical and statistical tools for further work. Interactive visualisations are useful for communication as they enable active engagement with your datasets and the message you are conveying in a user friendly and non-technical manner.\nHere, we will be using Plotly Express to develop interactive visualisations. Plotly Express is a Python module that contains functions that convert data in Python programs into interactive visualisations that can be rendered in web browser based environments.\nPlotly Express has several attractive features for developing interactive visualisations:\n\nfunctions to generate a range of figure types to explore spatial and non-spatial data (see the gallery)\nconsistent API for functions used to generate the figures (i.e. if you learn the syntax and format to generate scatter plots it can be applied to generate histograms, density plots, bar plots, violin plots, web maps, etc.)\nsimple and intuitive functions to generate the figures (i.e. produce complex interactive figures with a single line of code)\n\nLet’s read in some wheat and canola yield data collected by a harvester into a GeoPandas GeoDataFrame. The canola data corresponds to variety 43Y23 RR and the wheat data corresponds to variety ninja. We’ll demonstrate how to create interactive visualisations using Plotly Express by generating a simple widget that displays the distribution of wheat and canola yields.\n\n# Load the crop yield data\ncrop_yield_data_path = os.path.join(os.getcwd(), \"week-3\")\n\n# Get a list of crop yield data\ncrop_yield_data_files = os.listdir(crop_yield_data_path)\n\n# Combine the geojson files into one GeoDataFrame\ndfs = []\n\nfor i in crop_yield_data_files:\n    if i.endswith(\".geojson\"):\n        print(f\"Loading file {i} into a Geopandas GeoDataFrame\")\n        tmp_df = gpd.read_file(os.path.join(crop_yield_data_path, i))\n        dfs.append(tmp_df)\n\ngdf = pd.concat(dfs, axis=0)\n\nLoading file bf66-canola-yield-max-vi_sampled.geojson into a Geopandas GeoDataFrame\nLoading file bf66-wheat-yield-max-vi_sampled.geojson into a Geopandas GeoDataFrame\n\n\nNow, let’s unpick the syntax for specifying a Plotly Express visualisation. The functions to generate interactive figures are part of the plotly.express module which we’ve imported into our program as px. px.<function name>() is how we’ll access the function to generate a given figure. For example, to generate a histogram we call px.histogram() (if we wanted to generate a scatter plot we’d call px.scatter(), if we wanted to generate a line chart we’d call px.line(), if we wanted to generate a pie chart we’d call px.pie() - you get the pattern).\nNext, we need to pass data into the function that will be rendered on the computer display and specify arguments to map data values to elements on the figure. The Plotly Express documentation lists functions that can be used to generate figures and their parameters.\nParamters for the px.histogram() function inclue:\n\ndata_frame - a DataFrame object containing the data to render on the histogram.\nx - specifies the column in the DataFrame to be mapped on the x-axis of the figure.\n\ncolor - a column whose values are used to assign colours to marks (elements) on the display.\nmarginal - either violin, box, rug, or histogram that shows the distribution of the data.\nhover_data - list of column names with values that will be shown in a popup when the cursor hovers over a record on the display.\n\nUse the Zoom tool to control what data is visualised and focus the figure on where most of the data is distributed.\n\nfig = px.histogram(\n    data_frame=gdf, \n    x=\"DryYield\", \n    color=\"Variety\", \n    marginal=\"box\", \n    hover_data=[\"DryYield\", \"Elevation\", \"WetMass\"])\nfig.show()\n\n\n\n\nThere are more options that you can use to configure a histogram here.\n\nRecap quiz\nLook up the range_x paramter and consider how it could be used to remove the influence of outliers on the figure. Have a go at using it to restrict the range of values mapped to the x-axis.\n## ADD CODE HERE ##\n\n\nanswer\n\nfig = px.histogram(\n    data_frame=gdf, \n    x=\"DryYield\", \n    color=\"Variety\", \n    marginal=\"box\", \n    range_x=[0, 7],\n    hover_data=[\"DryYield\", \"Elevation\", \"WetMass\"])\nfig.show()\n\nLet’s have a go at generating a scatter plot to consolidate our understanding of how to map variables in our data to elements of a graphic. The documentation for scatter plots is here and you should notice similarities in how we set up a scatter plot to a histogram.\nLet’s use a scatter plot to see if there is a relationship beetween crop yield and elevation. We are plotting two variables here so we need to use the y parameter to specify what column in our GeoDataFrame will be mapped onto the y-axis.\nWe can use the marginal_x and marginal_y parameters to attach plots to the x- and y-axes that show the distributions of variables mapped to each axis.\nFinally, we’re going to use the opacity argument here to make the point elements on the figure semi-transparent; this will help reveal more information about the density of data values.\nBoth canola and wheat crop yield data is displayed. To see the relationship between one crop type’s yield and elevation, click on the variety in the legend.\n\nfig = px.scatter(\n    data_frame=gdf, \n    x=\"DryYield\", \n    y=\"Elevation\", \n    color=\"Variety\", \n    opacity=0.25, \n    marginal_x=\"box\", \n    marginal_y=\"violin\")\nfig.show()\n\n\n\n\n\n\nRecap quiz\nCan you limit the range of x-axis values to focus the figure on where most of the data is concentrated and remove the effect of outliers? (hint, you’ll need to remove the marginal_x argument).\n## ADD CODE HERE ##\n\n\nanswer\n\nfig = px.scatter(\n    data_frame=gdf, \n    x=\"DryYield\", \n    y=\"Elevation\", \n    color=\"Variety\", \n    range_x=[0,10],\n    opacity=0.25,\n    marginal_y=\"violin\")\nfig.show()\n\n\n\nAdding layers\nThe scatter plot we have generated above has layers of points for the scatter plot and layers of geometric elements for the box plot and violin plots. However, each of these layers are all rendered on their own sub-plot.\nThere are often times when we want to overlay layers on the same plot. A common example of this is adding a trendline to a scatter plot to help the viewer see patterns and relationships in the data. If we refer back to the documentation for scatter plots we can see there is a trendline parameter. We can use this parameter to specify the kind of trendline we’d like to draw on our scatter plot:\n\nols: ordinary least squares (or linear line of best fit)\nloess: locally weighted scatterplot smoothing line\nrolling: rolling average or rolling median line\n\nLet’s generate a scatter plot with a trendline to explore the relationship between the green normalised difference vegetation index (GNDVI, a satellite derived measure of vegetation greenness) and crop yield. Generally, higher maximum growing season GNDVI values are correlated with higher crop yields.\nIf you hover your cursor over the trendline it will show you the equation for the trendline. You will also notice that we’ve used the the range_x and range_y parameters to focus the figure on the region where most of the data is concentrated and clip the outliers from the view.\n\nfig = px.scatter(\n    data_frame=gdf, \n    x=\"gndvi\", \n    y=\"DryYield\", \n    color=\"Variety\", \n    opacity=0.05, \n    range_y=[0.1, 6], \n    range_x=[0.3, 0.9], \n    marginal_x=\"box\", \n    marginal_y=\"box\", \n    trendline=\"ols\"\n)\nfig.show()\n\n\n\n\n\nRecap quiz\n\n\nGenerally, it seems that maximum growing season GNDVI is higher for the wheat (Ninja) crop than canola (43Y23 RR). Can you think of an explanation for this?\n\nCanola canopies are characterised by yellow flowers which could reduce their greenness during the growing season.\n\n\n\n\nFacets\nSo far we have distinguished groups of data points on the same figure by using a unique colour per-group. However, this can lead to cluttered figures which obscures important variation in the data. To avoid clutter we can create faceted figures where mutliple subplots of the same type are generated, which share axes, and different subsets (groups) of the data are rendered on each subplot.\nWilke (2019) distinguish between faceted figures and compound figures. Compound figures are multiple figure types (e.g. scatter plots, histograms, maps), possibly of different datasets, combined into one figure. A key feature of a compound figure is that the subplots do not need to be arranged in a regular grid. The figures above with violin and box plots aligned on the margins of a scatter plot are examples of compound figures.\nIn contrast, facet plots consist of subplots of the same type, showing subsets of the same dataset, and are arranged on a regular grid. You might see the term trellis or lattice plots used to describe facet plots. To ensure correct interpretation of faceted figures it is important that the axes on all plots share the same range and scalings.\nLet’s create a faceted figure that shows the relationship between crop yield and the normalised difference yellowness index (NDYI) side-by-side. The NDYI is a spectral index computed from remote sensing data as a mathematical combination of green and blue reflectance values. Higher NDYI values are associated with a yellower land surface. The NDYI is often used to monitor canola flowering.\nWe can use the facet_row parameter to align subplots on separate rows or the facet_col parameter to align the subplots on separate columns. We specify a column in our GeoDataFrame to use to create the facets. The dataset is split into subsets using unique values in the specified column and each subset is rendered on a subplot. Here, we pass in the Variety column to split the data by crop type.\n\nfig = px.scatter(\n    data_frame=gdf, \n    x=\"ndyi\", \n    y=\"DryYield\", \n    facet_col=\"Variety\", \n    opacity=0.05, \n    range_y=[0.1, 5], \n    range_x=[0.1, 0.6], \n    trendline=\"ols\"\n)\nfig.show()"
  },
  {
    "objectID": "lab-3.html#selecting-the-right-figure",
    "href": "lab-3.html#selecting-the-right-figure",
    "title": "Introduction",
    "section": "Selecting the “right” figure",
    "text": "Selecting the “right” figure\nChapter 5 of Wilke (2019) provides a directory of visualisations which serves as a useful guide for selecting the correct visualisation for different types of data."
  },
  {
    "objectID": "lab-3.html#using-colour",
    "href": "lab-3.html#using-colour",
    "title": "Introduction",
    "section": "Using Colour",
    "text": "Using Colour\nA colour scale is used to map data values to colours on the display. Wilke (2019) outline three uses of colour on figures:\n\ncolour to represent data values (e.g. using red shades for low precipitation and blue shades for high precipitation).\ncolour to distinguish groups (e.g. using green for forest on a land cover map, blue for water, orange-red for desert, etc.).\ncolour to highlight (e.g. using colour to highlight particular features on your visualisation).\n\nWe can broadly characterise colour scales as being either continuous or qualitative.\n\nContinuous palettes\nContinuous colour scales can be either sequential or diverging and are typically used when using colour to represent data values (often numeric continuous variables). Continuous colour scales can be used to visualise variation in attributes of vector geospatial data on chloropleth maps and variation in attributes of raster data as surfaces.\n\nSequential palettes\nA sequential colour scale is a palette which consists of single hue such as light green to dark green or light red to dark red. Multi-hue sequential colour scales often consist of hues that imply an intuitive and increasing order to the colours such as light yellows to dark red.\nPlotly express provides a range of inbuilt sequential colour scales:\n\nfig = px.colors.sequential.swatches_continuous()\nfig.show()\n\n\n\n\nLet’s use a sequential colour scale to visualise spatial and spatio-temporal variation in greenness of the field during the canola growing season in 2020. We can start by reading in a GeoTIFF file where each band is a raster showing weekly GNDVI values generated from Sentinel-2 satellite data. The Sentinel-2 data has been cloud masked and each pixel’s time-series of GNDVI values has been smoothed using a harmonic model of time.\n# path to the GeoTIFF file\ngndvi_path = os.path.join(os.getcwd(), \"week-3\", \"gndvi_2020_bf66_fitted.tif\")\n\n# open the GeoTIFF file and read its metadata and image data\nwith rasterio.open(gndvi_path) as src:\n    meta = src.meta\n    gndvi = src.read()\n\n# move the bands to the last axis\ngndvi = np.moveaxis(gndvi, 0, 2)\nNow, we should have a multiband NumPy ndarray object. Let’s quickly check its shape.\n\nprint(f\"The array has {gndvi.shape[0]} rows\")\nprint(f\"The array has {gndvi.shape[1]} columns\")\nprint(f\"The array has {gndvi.shape[2]} bands\")\n\nThe array has 163 rows\nThe array has 280 columns\nThe array has 52 bands\n\n\nNow, let’s visualise GNDVI values for the 30th week of the year.\n\n# plot GNDVI for week of year 30\nfig = px.imshow(gndvi[:, :, 29])\nfig.update_xaxes(showticklabels=False)\nfig.update_yaxes(showticklabels=False)\nfig.show()\n\n\n\n\nWe can see that there is some spatial variation in GNDVI values within the field. However, a green colour palette might be more suitable for visualising greenness. Let’s select a different colour scale from the palettes printed above.\n\n\nRecap quiz\nChoose a suitable colour scale from the graphic above for representing greenness within the field. Pass the string indicator of this colour scale into the color_continuous_scale argument of the imshow() function.\n## ADD CODE HERE ##\n\n\nanswer\n\n# let's use a more intuitive colour palette for GNDVI\nfig = px.imshow(gndvi[:, :, 30], color_continuous_scale=\"YlGn\", range_color=[0.3, 0.7])\nfig.update_xaxes(showticklabels=False)\nfig.update_yaxes(showticklabels=False)\nfig.show()\n\nNow, let’s visualise the spatio-temporal variation in greenness through the canola growing season. This is a good use case for a faceted figure. We can represent each week as a subplot, align the subplots sequentially through time, and use the same mapping of data values to colour to make comparisons of greenness across weeks easy.\n# let's visualise change GNDVI over the growing season\nfig = px.imshow(\n    gndvi, \n    facet_col=2, \n    facet_col_wrap=4, \n    facet_col_spacing=0.04,\n    facet_row_spacing=0.04,\n    height=1200, \n    width=600,\n    color_continuous_scale=\"YlGn\", \n    range_color=[0.3, 0.7])\nfig.update_xaxes(showticklabels=False)\nfig.update_yaxes(showticklabels=False)\nfig.show()\nA nice feature of plotly express is its functionality for animating figures. Many Plotly Express functions come with an animation_frame parameter which allows you to specify a column of a DataFrame or axis of an ndarray to use to subset your data and then sequentially show each subset on your figure. Instead of making 52 separate maps of greenness in the field, let’s just create an animation that shows how the field greens up and then greens down through the canola growing season.\n# let's animate change GNDVI over the growing season\nfig = px.imshow(\n    gndvi, \n    animation_frame=2, # here we are specifying axis=2 which is the bands (weeks) dimension.\n    color_continuous_scale=\"YlGn\", \n    range_color=[0.3, 0.7],\n    height=600, \n    width=800)\nfig.update_xaxes(showticklabels=False)\nfig.update_yaxes(showticklabels=False)\nfig.show()\nCanola flowers are yellow. Fields during the flowering stage of canola growing season are characterised by yellow canopies. Let’s see this by animating the NDYI values over the canola growing season. Here we’ll use the solar colour palette which maps high data values to vivid yellow colours.\n# let's animate change in canopy yellowness over the growing season\n\n# path to the GeoTIFF file\nndyi_path = os.path.join(os.getcwd(), \"week-3\", \"ndyi_2020_bf66_fitted.tif\")\n\n# open the GeoTIFF file and read its metadata and image data\nwith rasterio.open(ndyi_path) as src:\n    meta = src.meta\n    ndyi = src.read()\n\n# move the bands to the last axis\nndyi = np.moveaxis(ndyi, 0, 2)\n\n\nRecap quiz\nCan you adapt the code used to create an animation of GNDVI values through the growing season to visualise yellowness (or canola flowering) through the growing season? Use the solar colour scale and the ndarray object referenced by ndyi.\n## ADD CODE HERE ##\n\n\nanswer\n\nfig = px.imshow(\n    ndyi, \n    animation_frame=2, \n    color_continuous_scale=\"solar\", \n    range_color=[0.1, 0.45],\n    height=600, \n    width=800)\nfig.update_xaxes(showticklabels=False)\nfig.update_yaxes(showticklabels=False)\nfig.show()\n\n\n\nDiverging palettes\nDiverging colour scales are used to represent data values deviating in two directions. Often a light colour (e.g. white) is used as the mid-point of a diverging colour scale with gradients of intensifying colour away from this mid-point. A common example of diverging colour scales are climate or weather anomalies where dry or hot years are represented with red colours and wet and cool years are represented with blue colours. Average conditions are often a pale red, pale blue, or white.\nPlotly also provides a range of diverging colour palettes we can use:\n\nfig = px.colors.diverging.swatches_continuous()\nfig.show()\n\n\n\n\nLet’s use a diverging colour palette to visualise monthly precipitation over the field since 1981. The precipitation data is obtained from the TerraClimate: Monthly Climate and Climatic Water Balance for Global Terrestrial Surfaces dataset.\nUse the pandas read_csv() function to read in the precipitation data. Inside the CSV file each row represents a month-year combination and stores a monthly precipitation total in mm.\n\n# visualise monthly precipitation using a diverging palette\nprecip_df = pd.read_csv(os.path.join(os.getcwd(), \"week-3\", \"bf66-terra-precip-monthly.csv\"))\nprecip_df[\"month\"] = precip_df[\"month\"].astype(str)\nprecip_df[\"year\"] = precip_df[\"year\"].astype(str)\nprecip_df.head()\n\n\n\n\n\n  \n    \n      \n      month\n      pr\n      year\n    \n  \n  \n    \n      0\n      1\n      6\n      1981\n    \n    \n      1\n      2\n      41\n      1981\n    \n    \n      2\n      3\n      3\n      1981\n    \n    \n      3\n      4\n      17\n      1981\n    \n    \n      4\n      5\n      81\n      1981\n    \n  \n\n\n\n\nWe can create a heatmap to visualise monthly precipitation across time and use a red to blue diverging colour palette where red colours indicate dry months and blue colours indicate wet months.\n\n# compute average rainfall to use as the mid point on a diverging colour palette\navg_pr = precip_df[\"pr\"].median()\n\nfig = px.density_heatmap(\n    precip_df,\n    x=\"year\", \n    y=\"month\", \n    z=\"pr\", \n    histfunc=\"sum\",\n    nbinsy=12,\n    color_continuous_scale=\"RdBu\",\n    color_continuous_midpoint=avg_pr\n)\nfig.show()\n\n\n\n\n\n\n\nQualitative palettes\nQualitative (or discrete) colour scales should be used to represent groups or categorical data (i.e. data where there is no logical ordering). Thus, qualitative colour scales should not represent gradients of light to dark or use colours that can be interpreted as having an implied ordering. Often, it is sensible to select colours that relate to the category (e.g. on land cover maps using green for vegetated categories, blue for water etc.)."
  },
  {
    "objectID": "lab-3-self-guided.html",
    "href": "lab-3-self-guided.html",
    "title": "Introduction",
    "section": "",
    "text": "Exploratory data analysis is an activity where you ……. explore your data. It’s often conducted towards the beginning of a data science or analysis workflow and is an interactive process to build up your familiarity with the data; identify its structure and patterns; spot noise, errors, and missing values; and begin to formulate research questions and hypotheses.\nChapter 7 of R for Data Science (Wickham and Grolemund, 2017) provides an excellant overview of techniques for exploratory data analysis. They suggest that two questions should guide your initial exploration of datasets:\n\nWhat type of variation occurs within variables?\nWhat type of covariation occurs between variables?\n\nA variable is a property or feature of interest that can be measured and a value is the state of the variable when it was measured. Columns in a DataFrame or GeoDataFrame or bands in raster often correspond to variables and cells in a table or pixels in a raster correspond to values for an observation.\n\n\nHere, you will build on the data visualisation skills from the previous lab to explore crop yield data collected by a harvester in Western Australia. You will use data visualisations and summaries to identify noise or errors in the dataset and remove or clean them. In this lab you will learn to:\n\ngenerate summary tables and descriptive statistics\nvisualise data distributions\nvisualise relationships between variables\nidentify and remove missing or noisy values"
  },
  {
    "objectID": "lab-3-self-guided.html#setup",
    "href": "lab-3-self-guided.html#setup",
    "title": "Introduction",
    "section": "Setup",
    "text": "Setup\n\nRun the labs\nYou can run the labs locally on your machine or you can use cloud environments provided by Google Colab. If you’re working with Google Colab be aware that your sessions are temporary and you’ll need to take care to save, backup, and download your work.\n  \n\n\nDownload data\nIf you need to download the data for this lab, run the following code snippet.\nimport os\n\nif \"week-3\" not in os.listdir(os.getcwd()):\n    os.system('wget \"https://github.com/data-analysis-3300-3003/data/raw/main/data/week-3.zip\"')\n    os.system('unzip \"week-3.zip\"')\n\n\nWorking in Colab\nIf you’re working in Google Colab, you’ll need to install the required packages that don’t come with the colab environment.\nif 'google.colab' in str(get_ipython()):\n    !pip install geopandas\n    !pip install pyarrow\n    !pip install mapclassify\n    !pip install rasterio\n\n\nImport modules\n# Import modules\nimport os\nimport pandas as pd\nimport geopandas as gpd\nimport plotly.express as px\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport rasterio\nimport plotly.io as pio\n\n\n# setup renderer\nif 'google.colab' in str(get_ipython()):\n    pio.renderers.default = \"colab\"\nelse:\n    pio.renderers.default = \"jupyterlab\""
  },
  {
    "objectID": "lab-3-self-guided.html#load-data",
    "href": "lab-3-self-guided.html#load-data",
    "title": "Introduction",
    "section": "Load data",
    "text": "Load data\n\n# Load the crop yield data\ncrop_yield_data_path = os.path.join(os.getcwd(), \"week-3\")\n\n# Get a list of crop yield data\ncrop_yield_data_files = os.listdir(crop_yield_data_path)\n\n# Combine the geojson files into one GeoDataFrame\ndfs = []\n\nfor i in crop_yield_data_files:\n    if i.endswith(\".geojson\"):\n        print(f\"Loading file {i} into a Geopandas GeoDataFrame\")\n        tmp_df = gpd.read_file(os.path.join(crop_yield_data_path, i))\n        dfs.append(tmp_df)\n\ngdf = pd.concat(dfs, axis=0)\n\nLoading file bf66-canola-yield-max-vi_sampled.geojson into a Geopandas GeoDataFrame\nLoading file bf66-wheat-yield-max-vi_sampled.geojson into a Geopandas GeoDataFrame"
  },
  {
    "objectID": "lab-3-self-guided.html#data-summaries",
    "href": "lab-3-self-guided.html#data-summaries",
    "title": "Introduction",
    "section": "Data summaries",
    "text": "Data summaries\nAn initial data exploration task is to produce summary statistics for the variables in our datasets. Pandas DataFrames and GeoPandas GeoDataFrames have a describe() method which generates a DataFrame of summary statistics for each variable.\n\n# Describe our DataFrame of crop yield data\ngdf.describe()\n\n\n\n\n\n  \n    \n      \n      Crop\n      Distance\n      DryYield\n      Easting\n      Elevation\n      Heading\n      Machine\n      Moisture\n      Northing\n      Swathwidth\n      WetMass\n      gndvi\n      ndyi\n      SwathWidth\n    \n  \n  \n    \n      count\n      9378.000000\n      9378.000000\n      9378.000000\n      9378.000000\n      9378.000000\n      9378.000000\n      9378.000000\n      9378.000000\n      9.378000e+03\n      4038.000000\n      9378.000000\n      8882.000000\n      8882.000000\n      5340.000000\n    \n    \n      mean\n      16.957774\n      2.455513\n      1.414895\n      546672.208986\n      268.554916\n      173.632758\n      1.795372\n      9.505673\n      6.504030e+06\n      11.781128\n      1.415163\n      0.622946\n      0.356913\n      11.805181\n    \n    \n      std\n      10.398867\n      0.462722\n      1.101763\n      566.852415\n      5.918522\n      126.139642\n      0.753388\n      1.900786\n      4.636923e+02\n      1.290750\n      1.101775\n      0.140566\n      0.083516\n      1.229728\n    \n    \n      min\n      5.000000\n      0.000000\n      0.000000\n      545394.222400\n      251.820000\n      0.000000\n      1.000000\n      0.000000\n      6.502815e+06\n      0.153000\n      0.000000\n      0.000000\n      0.000000\n      0.153000\n    \n    \n      25%\n      5.000000\n      2.113000\n      0.550000\n      546260.116550\n      265.050000\n      12.825000\n      1.000000\n      7.800000\n      6.503738e+06\n      12.000000\n      0.550000\n      0.559567\n      0.323940\n      12.000000\n    \n    \n      50%\n      26.000000\n      2.427000\n      1.102000\n      546762.423800\n      269.400000\n      180.000000\n      2.000000\n      9.400000\n      6.504071e+06\n      12.000000\n      1.102000\n      0.639549\n      0.369079\n      12.000000\n    \n    \n      75%\n      26.000000\n      2.842000\n      2.136000\n      547111.941950\n      272.650000\n      242.375000\n      2.000000\n      11.100000\n      6.504401e+06\n      12.000000\n      2.136000\n      0.717398\n      0.408013\n      12.000000\n    \n    \n      max\n      26.000000\n      3.486000\n      23.124000\n      547770.485000\n      280.060000\n      360.000000\n      3.000000\n      17.500000\n      6.504748e+06\n      12.000000\n      23.124000\n      0.836573\n      0.545766\n      12.000000\n    \n  \n\n\n\n\ndescribe() returns to us a count of the number of observations in a variable, the mean value for observations in a variable, and summary statistics describing the distribution and range of values (standard deviation, percentiles (median = 50th percentile), and min and max values).\nHowever, there are two main groups in our dataset: canola observations and wheat observations denoted by the Variety column. It will be more informative to generate summary statistcs for each group separately. We can do this using the Pandas groupby() function which splits a DataFrame into subsets based upon a grouping variable, computes statistics for each subset, and then combines the results. Here, we need to groupby() Variety to generate summary statistics for each crop type.\nWe’ll also generate these summary statistics within a context manager (denoted by a with block). This context allows us to change the default display values for a DataFrame only for this context without affecting the global defaults that apply to the rest of the notebook. This is a useful trick in case you have a particular need to control how a DataFrame is displayed (e.g. printing all rows as specified by the display.max_rows option).\n\nwith pd.option_context(\"display.max_rows\", None, \"display.float_format\", lambda x: \"%.3f\" % x):\n    display(gdf.groupby([\"Variety\"]).describe())\n\n\n\n\n\n  \n    \n      \n      Crop\n      Distance\n      ...\n      ndyi\n      SwathWidth\n    \n    \n      \n      count\n      mean\n      std\n      min\n      25%\n      50%\n      75%\n      max\n      count\n      mean\n      ...\n      75%\n      max\n      count\n      mean\n      std\n      min\n      25%\n      50%\n      75%\n      max\n    \n    \n      Variety\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      43Y23 RR\n      4038.000\n      5.000\n      0.000\n      5.000\n      5.000\n      5.000\n      5.000\n      5.000\n      4038.000\n      2.822\n      ...\n      0.370\n      0.518\n      0.000\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      Ninja\n      5340.000\n      26.000\n      0.000\n      26.000\n      26.000\n      26.000\n      26.000\n      26.000\n      5340.000\n      2.179\n      ...\n      0.423\n      0.546\n      5340.000\n      11.805\n      1.230\n      0.153\n      12.000\n      12.000\n      12.000\n      12.000\n    \n  \n\n2 rows × 112 columns\n\n\n\nThis still isn’t a very helpful layout to view the summary statistics as not all of the statistics can be displayed. Let’s transpose the summary statistics so rows become columns and vice versa using the T transpose operator.\n\nwith pd.option_context(\"display.max_rows\", None, \"display.float_format\", lambda x: \"%.3f\" % x):\n    display(gdf.loc[:, [\"Variety\", \"DryYield\", \"gndvi\", \"ndyi\"]].groupby([\"Variety\"]).describe().T)\n\n\n\n\n\n  \n    \n      \n      Variety\n      43Y23 RR\n      Ninja\n    \n  \n  \n    \n      DryYield\n      count\n      4038.000\n      5340.000\n    \n    \n      mean\n      0.590\n      2.039\n    \n    \n      std\n      0.284\n      1.080\n    \n    \n      min\n      0.000\n      0.000\n    \n    \n      25%\n      0.382\n      1.391\n    \n    \n      50%\n      0.556\n      1.990\n    \n    \n      75%\n      0.771\n      2.671\n    \n    \n      max\n      5.065\n      23.124\n    \n    \n      gndvi\n      count\n      3834.000\n      5048.000\n    \n    \n      mean\n      0.540\n      0.686\n    \n    \n      std\n      0.102\n      0.133\n    \n    \n      min\n      0.000\n      0.000\n    \n    \n      25%\n      0.527\n      0.669\n    \n    \n      50%\n      0.557\n      0.708\n    \n    \n      75%\n      0.587\n      0.745\n    \n    \n      max\n      0.683\n      0.837\n    \n    \n      ndyi\n      count\n      3834.000\n      5048.000\n    \n    \n      mean\n      0.328\n      0.379\n    \n    \n      std\n      0.076\n      0.082\n    \n    \n      min\n      0.000\n      0.000\n    \n    \n      25%\n      0.298\n      0.358\n    \n    \n      50%\n      0.333\n      0.393\n    \n    \n      75%\n      0.370\n      0.423\n    \n    \n      max\n      0.518\n      0.546"
  },
  {
    "objectID": "lab-3-self-guided.html#data-distributions",
    "href": "lab-3-self-guided.html#data-distributions",
    "title": "Introduction",
    "section": "Data distributions",
    "text": "Data distributions\nThe mean tells us the average value for a variable. However, it is susceptible to outliers and extreme values. Therefore, it is important to view the mean and the median (50th percentile) together as the median is not affected by extreme values.\nHowever, neither the mean or the median reveal the spread or distribution of values for a variable. The min and max values tell us what the range of values are for a variable. This can be useful for detecting potential measurement error and noise (e.g. is the max value for wheat yield sensible?).\nThe inter-quartile range (difference between the 75th and 25th percentile values) tells us how spread out the data is around the median and the standard deviation tells us how spread out the data is around the mean. Assuming a normal distribution, ~68% of the values are within one standard deviation of the mean.\nIt is often useful to visualise the distribution of variables. A histogram is a common visualisation for distributions. The height of the bars of a histogram correspond to the count of values that fall within the bin. The width of the bar corresponds to the bin width.\n\nRecap quiz\n\n\nWhat is a limitation of using min and max values to represent the distribition of values for a variable?\n\nThe min and max values can be affected by extreme values and don’t tell us anything about the shape or density of the distribution of data values.\n\n\n\n\n\nIf the standard deviation is small relative to the mean, what does this tell us about the spread of the data?\n\nThere is not much spread in the data away from the mean.\n\n\n\n\nfig = px.histogram(\n    data_frame=gdf, \n    x=\"DryYield\", \n    facet_col=\"Variety\", \n    hover_data=[\"DryYield\", \"Elevation\", \"WetMass\"])\nfig.show()\n\n\n\n\nThe histogram() function from Plotly Express has a nbins parameter that can be used to specify the number of bins.\n\n\nRecap quiz\nUse the Plotly Express nbins parameter of the histogram() function to change the number bins, and consequently the bin width, and explore how this affects the visualisation of the distribution.\n## add code here ##\n\n\nanswer\n\nfig = px.histogram(\n    data_frame=gdf, \n    x=\"DryYield\", \n    facet_col=\"Variety\", \n    nbins=5, ### CHANGE THIS VALUE\n    hover_data=[\"DryYield\", \"Elevation\", \"WetMass\"])\nfig.show()\n\n\n\nWhat happens if you generate a histogram with too large a bin width?\n\nYou will smooth out variation in the data and will not accurately reflect the shape of the distribution of the data.\n\n\n\n\n\nWhat happens if you generate a histogram with too small a bin width?\n\nYou might not be able to see the dominant shape of the distribution of data values as the histogram could appear “spikey” with local variability in the distribution of values emphasised."
  },
  {
    "objectID": "lab-3-self-guided.html#subsetting-pandas-dataframes",
    "href": "lab-3-self-guided.html#subsetting-pandas-dataframes",
    "title": "Introduction",
    "section": "Subsetting pandas DataFrames",
    "text": "Subsetting pandas DataFrames\nTo subset data from a pandas DataFrame we use the square brackets [] to specify the data values we’d like to extract. The [] operator can be thought of as a get item operation.\nSelection by labels\nSelection by labels refers to selecting values from a DataFrame by their label (i.e. column name).\n\nTo select a column from a DataFrame we pass the column name into [] (e.g. dry_yield = gdf[\"DryYield\"] where dry_yield is a Series object).\nTo select many columns from a DataFrame we pass a list of column names into [] (e.g. (e.g. df_yield = gdf[[\"DryYield\", \"Variety\"]] where df_yield is a DataFrame object).\n\nSelection by position\nSelection by position refers to selecting values from a DataFrame by their index position (i.e. row or column number starting at 0).\n\nTo select the \\(n^{th}\\) row pass in [n-1:n]. Remember that Python indexes from zero so the \\(n-1\\) index position is the \\(n^{th}\\) row. The slice operator : is exclusive so [n-1:n] will only select the row at n-1 (e.g. to select the \\(2^{nd}\\) row use df_row_2 = gdf[1:2]).\nTo select a slice of rows use the slice operator (e.g. to select the first 10 rows use df_10_rows = gdf[0:10]).\n\nSelection by condition\nSelection by condition selects rows that are True based on a condition (e.g. selecting all rows with a DryYield greater than 1.5 - df_yield_gt_1_5 = gdf[gdf[\"DryYield\"] > 1.5]).\nloc[] and iloc[]\nThe more robust approach to subsetting data from DataFrames is using the loc and iloc methods, which also support multi-index selection (i.e. selecting rows and columns).\n\nloc is used for selecting by labels (e.g. df_yield = gdf.loc[:, [\"DryYield\", \"Variety\"]] - note the [:, [\"DryYield\", \"Variety\"]] syntax where : means select all rows).\niloc is used for selecting by position (e.g. to select the first 10 rows use df_10_rows = gdf.iloc[0:10, :]).\nTo select the first 10 rows and columns we’d use df_10_rows_10_cols = gdf.iloc[0:10, 0:10]).\n\n\nRecap quiz\n\n\nHow many rows will the object referenced by df_temp have after calling df_temp=df.iloc[0:5, :]?\n\n5 rows at index positions 0 to 4 from the DataFrame df.\n\n\n\n\n\nHow many columns from df will the object referenced by df_temp have after calling df_temp=df.iloc[0:5, :]?\n\nAll the columns from df.\n\n\n\nUse loc and the DataFrame referenced by gdf to select all rows where DryYield is greater than 2.\n## ADD CODE HERE ##\n\n\nanswer\n\ndf_gt_2 = gdf.loc[(gdf[\"DryYield\"] > 2), :]\ndf_gt_2.head()\n\n\n\nThese are some useful resources on subsetting pandas DataFrames:\n\npandas Getting Started: How do I select specific rows and columns from a DataFrame?\nThe first few sections of the pandas docs on Indexing and selecting data\nMcKinney (2022) Python for Data Analysis - section on Indexing, selection, and filtering"
  },
  {
    "objectID": "lab-3-self-guided.html#outliers",
    "href": "lab-3-self-guided.html#outliers",
    "title": "Introduction",
    "section": "Outliers",
    "text": "Outliers\nThe majority of data values on the histograms above are concentrated on the far left of the figure. If you zoom in you will see there are a few isolated extreme or outlier yield values, which are masking the dominant pattern of the distribution. Detecting outliers is an important part of exploratory data analysis.\nNow that outliers have been detected we need to fix or remove them. A common way to detect outliers is to use a threshold based on percentile or standard deviation values. Here, we’ll say an outlier is any value that is more or less than three standard deviations from the mean.\n\n# Canola\ndf_canola = gdf.loc[gdf[\"Variety\"] == \"43Y23 RR\", :]\nprint(f\"There are {df_canola.shape[0]} canola rows BEFORE dropping outliers\")\ndf_canola = df_canola.loc[(df_canola[\"DryYield\"]-df_canola[\"DryYield\"].mean()).abs() < (3*df_canola[\"DryYield\"].std()), :]\nprint(f\"There are {df_canola.shape[0]} canola rows AFTER dropping outliers\")\n\n# Wheat\ndf_wheat = gdf.loc[gdf[\"Variety\"] == \"Ninja\", :]\nprint(f\"There are {df_wheat.shape[0]} wheat rows BEFORE dropping outliers\")\ndf_wheat = df_wheat.loc[(df_wheat[\"DryYield\"]-df_wheat[\"DryYield\"].mean()).abs() < (3*df_wheat[\"DryYield\"].std()), :]\nprint(f\"There are {df_wheat.shape[0]} wheat rows AFTER dropping outliers\")\n\nThere are 4038 canola rows BEFORE dropping outliers\nThere are 4031 canola rows AFTER dropping outliers\nThere are 5340 wheat rows BEFORE dropping outliers\nThere are 5334 wheat rows AFTER dropping outliers\n\n\n\nRecap quiz\n\n\nIs df_canola = gdf.loc[gdf[“Variety”] == “43Y23 RR”, :] an example of selection by condition or selection by position?\n\nSelection by condition. Here, we’re using a logical condition that evaluates to True for all rows where the value in the Variety column is 43Y23 RR.\n\n\n\n\n\nWhat is the abs() function being used for in the conditional selection of rows whose DryYield value is more / less than three standard deviations from the mean?\n\nabs() returns the absolute numeric value (so -2 would be returned as 2). This converts all negative deviations from the mean to positive and allows us to test for rows less than 3 standard deviations from the mean and select all rows within three standard deviations of the mean.\n\n\n\n\n\nWhat is the pandas concat() function used for?\n\nTo combine (concatenate) DataFrames along an axis. Here, we specify the 0 axis which refers to rows to stack two DataFrames on top of each other.\n\n# combine filtered dfs\ngdf_clean = pd.concat([df_canola, df_wheat], axis=0)\n\nfig = px.histogram(\n    data_frame=gdf_clean, \n    x=\"DryYield\", \n    facet_col=\"Variety\", \n    marginal=\"box\", \n    hover_data=[\"DryYield\", \"Elevation\", \"WetMass\"])\nfig.show()\n\n\n\n\nInstead of dropping rows where there are extreme crop yield values, we can also replace outlier values with a more sensible value such as the mean.\n\nmean_yield = gdf.loc[:, [\"Variety\", \"DryYield\"]].groupby([\"Variety\"]).mean()\nmean_yield\n\n\n\n\n\n  \n    \n      \n      DryYield\n    \n    \n      Variety\n      \n    \n  \n  \n    \n      43Y23 RR\n      0.589902\n    \n    \n      Ninja\n      2.038738\n    \n  \n\n\n\n\ndf_canola = gdf.loc[gdf[\"Variety\"] == \"43Y23 RR\", :]\ndf_canola.loc[(df_canola[\"DryYield\"]-df_canola[\"DryYield\"].mean()).abs() > (3*df_canola[\"DryYield\"].std()), \"DryYield\"] = mean_yield.iloc[0, 0]\n\ndf_wheat = gdf.loc[gdf[\"Variety\"] == \"Ninja\", :]\ndf_wheat.loc[(df_wheat[\"DryYield\"]-df_wheat[\"DryYield\"].mean()).abs() > (3*df_wheat[\"DryYield\"].std()), \"DryYield\"] = mean_yield.iloc[1, 0]\n\n# combine filtered dfs\ngdf_replaced = pd.concat([df_canola, df_wheat], axis=0)\n\nfig = px.histogram(\n    data_frame=gdf_replaced, \n    x=\"DryYield\", \n    facet_col=\"Variety\", \n    marginal=\"box\", \n    hover_data=[\"DryYield\", \"Elevation\", \"WetMass\"])\nfig.show()\n\n\n\n\nLooking at the wheat yield histogram we can see there are a large number of zero or close to zero values. This is another strange artefact in the distribution of our data values. Are zero crop yield values actually no crop yield from the plant or a source of measurement error or other noise? If the latter, we should remove these noisy values.\n\ndf_canola = gdf_clean.loc[gdf_clean[\"Variety\"] == \"43Y23 RR\", :]\nprint(f\"The number of canola observations with yield values of zero or less is: {(df_canola['DryYield'] <= 0).sum()}\")\ndf_wheat = gdf_clean.loc[gdf_clean[\"Variety\"] == \"Ninja\", :]\nprint(f\"The number of wheat observations with yield values of zero or less is: {(df_wheat['DryYield'] <= 0).sum()}\")\n\nThe number of canola observations with yield values of zero or less is: 13\nThe number of wheat observations with yield values of zero or less is: 140\n\n\nAbove, when setting the outlier values to their mean value, we demonstrated how can use loc on the left hand side of an expression to determine which values are set.\nHere, all rows in df_canola with a value more / less than three standard deviations from the mean are set to the mean value.\ndf_canola.loc[(df_canola[\"DryYield\"]-df_canola[\"DryYield\"].mean()).abs() > (3*df_canola[\"DryYield\"].std()), \"DryYield\"] = mean_yield.iloc[0, 0]\n\n\nRecap quiz\nWe’re going to drop zero DryYield values as these values are noisy. Can you use a selection by condition operation to subset the GeoDataFrame gdf_clean to select only rows where DryYield is greater than zero?\n## Add code here ##\n\n\nanswer\n\nprint(\"Shape of DataFrame before dropping zero yield values:\")\nprint(gdf_clean.shape)\ngdf_dropped_zero = gdf_clean.loc[gdf_clean[\"DryYield\"] > 0, :]\nprint(\"Shape of DataFrame after dropping zero yield values:\")\nprint(gdf_dropped_zero.shape)\n\n\n\nCan you generate a histogram visualising the distribution of DryYield values after dropping zero values? Use the Variety column to generate faceted subplots for each wheat and canola.\n## ADD CODE HERE ##\n\n\nanswer\n\nfig = px.histogram(\n    data_frame=gdf_dropped_zero, \n    x=\"DryYield\", \n    facet_col=\"Variety\", \n    marginal=\"box\", \n    hover_data=[\"DryYield\", \"Elevation\", \"WetMass\"])\nfig.show()\n\nAfter removing zero values the distribution of our crop yield values should look more sensible and relatively normally distributed.\n\n\n2D histograms\nWe can use 2D histograms or density heatmaps to look at the distribution of two variables together. 2D hisograms are a useful complement to scatter plots when you have a large number of observations. Here, colour is used to represent the distribution of data values as opposed to the height of rectangular bars on a histogram.\nLet’s create 2D histograms to visualise the relationship between vegetation indices and canola crop yield. Note, you’ll need to have completed the recap quiz above to generate gdf_dropped_zero.\n\nfig = px.density_heatmap(\n    data_frame=gdf_dropped_zero.loc[gdf_dropped_zero[\"Variety\"] == \"43Y23 RR\", :], \n    x=\"DryYield\", \n    y=\"gndvi\", \n    marginal_x=\"box\", \n    marginal_y=\"box\",\n    range_y=[0.4, 0.8])\nfig.show()\n\n\n\n\n\nfig = px.density_heatmap(\n    data_frame=gdf_dropped_zero.loc[gdf_dropped_zero[\"Variety\"] == \"43Y23 RR\", :], \n    x=\"DryYield\", \n    y=\"ndyi\", \n    marginal_x=\"box\", \n    marginal_y=\"box\",\n    range_y=[0.1, 0.5])\nfig.show()\n\n\n\n\n\n\nViolin plots\nOne of the limits of using histograms to visualise distributions is the size of the bins affects the distribution of data values. An alternative approach to visualising a distribution is to use a violin plot.\nViolin plots use density and box plots to visualise distributions, which look similar to violins. The density is the probability of an observation taking on a certain value and is plotted as a smooth curve. Areas where the curve is fatter indicate a higher probability that an observation will take that value. Box plots display the 25th, 50th, and 75th percentile values.\n\nfig = px.violin(\n    gdf_dropped_zero, \n    y=\"DryYield\", \n    x=\"Variety\", \n    color=\"Variety\", \n    box=True, \n    points=\"outliers\", \n    hover_data=[\"DryYield\", \"gndvi\"])\nfig.show()\n\n\n\n\n\nRecap quiz\nCan you create violin plots to visualise the GNDVI and NDYI values for each crop type?\n## ADD GNDVI VIOLIN PLOT CODE HERE ##\n\n\nanswer\n\nfig = px.violin(\n    gdf_dropped_zero, \n    y=\"gndvi\", \n    x=\"Variety\", \n    color=\"Variety\", \n    box=True, \n    points=\"outliers\", \n    hover_data=[\"DryYield\", \"gndvi\"])\nfig.show()\n\n## ADD NDYI VIOLIN PLOT CODE HERE ##\n\n\nanswer\n\nfig = px.violin(\n    gdf_dropped_zero, \n    y=\"ndyi\", \n    x=\"Variety\", \n    color=\"Variety\", \n    box=True, \n    points=\"outliers\", \n    hover_data=[\"DryYield\", \"ndyi\"])\nfig.show()"
  },
  {
    "objectID": "lab-3-practice-exercises.html",
    "href": "lab-3-practice-exercises.html",
    "title": "Week 3 - Practice Exercises",
    "section": "",
    "text": "This notebook contains exercises related to week 3’s content on generating interactive visualisations using Plotly Express. These exercises are based on this Our World in Data article: To protect the world’s wildlife we must improve crop yields – especially across Africa.\nThis article contains several visualisations, based on the paper by Williams et al. (2020), which illustrate that projected cropland expansion to meet future demands for food will result in substantial habitat loss, threats to biodiversity, and extinction. In part, this is due to growing populations in Africa where i) crop yields are low and so increasing the area under cultivation is required to generate more food, and ii) habitat for many key species is located. They also explore potential scenarios for meeting demand for food that avert the need for cropland expansion. Of the scenarios they explore, closing yield gaps in Africa looks most promising and with potential food security and economic co-benefits."
  },
  {
    "objectID": "lab-3-practice-exercises.html#population-growth",
    "href": "lab-3-practice-exercises.html#population-growth",
    "title": "Week 3 - Practice Exercises",
    "section": "Population growth",
    "text": "Population growth\nCropland expansion will result in habitat loss for many species. This cropland expansion is required to meet demand for food. One of the reasons for an increasing demand for food is population growth.\nOver the coming decades, population growth is projected to be greatest in Africa which is also the home to habitats for many key species.\nRead in the following CSV file which has annual population figures for each continent from 1800 through to 2100 (projections) and generate a line chart using Plotly Express visualising how each continents population has grown historically and is projected to grow into the future. This data is from Our World in Data with the source being Gapminder and the UN.\nYou should use the px.line() function for this task and the color argument should be set to \"Continent\".\nSee what happens when you hover your cursor over each line.\nCan you spot Africa’s projected rapid population growth through till 2100?\npop_continents = pd.read_csv(os.path.join(os.getcwd(), \"week-3-practice\", \"population_projections_1800_2100_continents.csv\"))\npop_continents.head()\n## Make visualisation here ## \n\n\nanswer\n\npx.line(\n    pop_continents,\n    x=\"Year\",\n    y=\"Population\",\n    color=\"Continent\"\n)"
  },
  {
    "objectID": "lab-3-practice-exercises.html#crop-yield-growth",
    "href": "lab-3-practice-exercises.html#crop-yield-growth",
    "title": "Week 3 - Practice Exercises",
    "section": "Crop yield growth",
    "text": "Crop yield growth\nOver the past few decades, as populations have grown so have crop yields. Crop yields are an indicator of agricultural productivity (i.e. how much food do we get from a unit area of land). Increasing the productivity of farms has reduced the need to expand the area under cultivation to meet demand from growing populations.\nRead in the following CSV file to plot the change in the average cereal crop yields (tonnes/ha) per continent since 1960 on a line chart. This data is downloaded from Our World in Data.\nYou should use the px.line() function for this task and the color argument should be set to \"Continent\".\ncrop_yields_pop_continents = pd.read_csv(os.path.join(os.getcwd(), \"week-3-practice\", \"population_yield_continents.csv\"))\ncrop_yields_pop_continents.head()\n## ADD CODE HERE ##\n\n\nanswer\n\npx.line(\n    crop_yields_pop_continents,\n    x=\"Year\",\n    y=\"Cereal_Yield_Tn/ha\",\n    color=\"Continent\"\n) \n\nYou should note the flat line for Africa indicating that crop yields have not grown over the past few decades. This is concerning as Africa is where most population growth is projected to occur. Without increases in productivity, to ensure food demand it met natural habitats will need to be brought under cultivation.\nWe can use Plotly Express’s visualisation tools to create animations that show how population growth and crop yields have changed over time.\nCan you create an animation of how the relationship between population growth and crop yields has changed for each continent since 1961?\nYou will need to use px.scatter() for this task. Set the x argument to \"Population\", y to \"Cereal_Yield_Tn/ha\", animation_frame to \"Year\", and color to \"Continent\". To make sure the axes ranges are suitable set range_x to [0, 5000000000] and range_y to [0, 6].\n## ADD CODE HERE ## \n\n\nanswer\n\npx.scatter(\n    crop_yields_pop_continents, \n    x=\"Population\", \n    y=\"Cereal_Yield_Tn/ha\", \n    size=\"Cereal_Yield_Tn/ha\",\n    color=\"Continent\",\n    animation_frame=\"Year\",\n    range_x=[0, 5000000000],\n    range_y=[0, 6]\n)\n\nCan you spot how Asia’s population grows and crop yields increase, how there is increasing crop yields but much less rapid population growth in Europe, and how Africa’s population is growing but crop yields remain low.\nPlotly Express also has a convenience function, px.chloropleth(), that we can use to make animated chloropleth maps. We can read in the following CSV file of country-level crop yields since 1961 and make an animated map of changing global crop yields from 1961 until the present day.\ncrop_yields_pop_countries = pd.read_csv(os.path.join(os.getcwd(), \"week-3-practice\", \"population_yield_countries.csv\"))\ncrop_yields_pop_countries.head()\nCan you use the px.chloropleth() function to make animate changes in crop yields at the country-level since 1961?\nTo get a good visualisation set the range_color argument to [0,8] and set the height argument to 500 (this makes the figure 500 pixels tall). Use the px.chloropleth() docs to look up what the range_color argument does.\nThe px.chloropleth() function has a locations argument, set this to \"Code\" (Code in a country code to map rows in the DataFrame to country geometries on a map). Set the color argument to \"Cereal_Yield_Tn/ha\" so each country’s fill colour represents crop yield, set the animation_frame argument to \"Year\" and set the color_continuous_scale argument to \"viridis\".\nNotice how over time the fill colour of countries in Europe, America, and Asia becomes lighter indicating increasing crop yields but Africa remains in darker purple shades.\n## ADD CODE HERE ## \n\n\nanswer\n\npx.choropleth(\n    crop_yields_pop_countries, \n    locations=\"Code\", \n    color=\"Cereal_Yield_Tn/ha\", \n    hover_name=\"Entity\", \n    animation_frame=\"Year\", \n    color_continuous_scale=\"viridis\",\n    range_color=[0,8],\n    height=500\n)"
  },
  {
    "objectID": "lab-3-practice-exercises.html#projected-change-in-cropland-area",
    "href": "lab-3-practice-exercises.html#projected-change-in-cropland-area",
    "title": "Week 3 - Practice Exercises",
    "section": "Projected change in cropland area",
    "text": "Projected change in cropland area\nWilliams et al. (2020) project the change in cropland area necessary to meet demand for food under a business as usual scenario (crop yields increasing following their historical rates of improvement and diets changing in line with projected income changes).\nRead in some of the data from the Williams et al. (2020) paper as used in Our World in Data (this data is downloaded from Our World in Data).\nThe column headers are:\n\nbau_habitat_loss_all - business as usual % change in habitat due to cropland expansion by 2050\nbau_change_pct - business as usual % change in cropland area to meet demand by 2050\nyields_change_pct - % change in cropland area to meet demand by 2050 when closing yield gaps\ndiets_change_pct - % change in cropland area to meet demand by 2050 by transitioning to healthier and lower meat diets\nwaste_change_pct - % change in cropland area to meet demand by 2050 by halving food waste\nyields_habitat_loss_all - % change in habitat loss for all species due to cropland expansion to meet demand by 2050 when closing yield gaps\nyields_habitat_loss_mammals - % change in habitat loss for mammals due to cropland expansion to meet demand by 2050 when closing yield gaps\n\nwilliams_2020_continents = pd.read_csv(os.path.join(os.getcwd(), \"week-3-practice\", \"williams_2020_continents.csv\"))\nwilliams_2020_continents.head()\nCan you make a bar plot using the px.bar() function to show percentage change in cropland area by by 2050 to meet food demand under the business as usual scenario?\nYou should set the x argument to bau_change_pct and the y argument to \"Continent\".\n## ADD CODE HERE ##\n\n\nanswer\n\npx.bar(\n    williams_2020_continents, \n    x=\"bau_change_pct\", \n    y=\"Continent\", \n    labels = {\n        \"bau_change_pct\": \"% change in cropland area by 2050 (BAU)\"\n    }\n)\n\nNote, the large increase in projected cropland expansion in Africa. The region where crop yields are lowest (i.e. where agricultural land is least productive). Let’s explore the same data on a map at the country level.\nwilliams_2020_countries = pd.read_csv(os.path.join(os.getcwd(), \"week-3-practice\", \"williams_2020_countries.csv\"))\nwilliams_2020_countries.head()\nCan you make a chloropleth map that visulises the percentage change in cropland area by 2050 to meet food demand under the business as usual scenario?\nUse the px.chloropleth() function without setting the animation_frame argument. You should set the location argument to \"Code\", color to \"bau_change_pct\", hover_name to \"Entity\", range_color to [-10,120], and height to 500.\nYou should see in bright colours the countries of Africa where cropland area is projected to increase substantially over the coming decades.\n## ADD CODE HERE ##\n\n\nanswer\n\npx.choropleth(\n    williams_2020_countries, \n    locations=\"Code\", \n    color=\"bau_change_pct\", \n    hover_name=\"Entity\",  \n    range_color=[-10,120],\n    height=500,\n    labels = {\n        \"bau_change_pct\": \"% change in cropland area by 2050 (BAU)\"\n    }\n)"
  },
  {
    "objectID": "lab-3-practice-exercises.html#projected-habitat-loss",
    "href": "lab-3-practice-exercises.html#projected-habitat-loss",
    "title": "Week 3 - Practice Exercises",
    "section": "Projected habitat loss",
    "text": "Projected habitat loss\nWe can repeat the above visualisations but swap out bau_change_pct for bau_habitat_loss_all to visualise the effect of business as usual cropland expansion on habitat loss for all species.\nCan you make a bar plot visualising the percentage change in habitat for all species under the business as usual cropland expansion scenario?\nYou should use the px.bar() function and set the argument x to \"bau_habitat_loss_all\", y to \"Continent\", and set range_x to [-11,11]. Use the pandas DataFrame williams_2020_continents for this task. Why are we setting the range_x argument to these values?\nYou should see that a large proportion of projected habitat loss is going to occur on the African contient.\n## ADD CODE HERE ##\n\n\nanswer\n\npx.bar(\n    williams_2020_continents, \n    x=\"bau_habitat_loss_all\", \n    y=\"Continent\", \n    range_x=[-11,11],\n    labels = {\n        \"bau_habitat_loss_all\": \"% change in habitat area for all species by 2050 under BAU scenario\"\n    }\n)\n\nLet’s map this data at the country level on a chloropleth map. Use the pandas DataFrame williams_2020_countries for this task. You should use the px.chloropleth() function, set the locations argument to \"Code\", set the color argument to \"bau_habitat_loss_all\", set the hover_name to \"Entity\", set the range_color to [-11, 0], and set height to 500.\nYou should see the Sub-Saharan African countries in darker purple shades indicating where most habitat loss will occur as a result of cropland expansion by 2050. There are also some countries in South America in moderate-dark purple shades where some habitat loss could occur. This is also concerning considering the important ecosystems in South America.\n## ADD CODE HERE ##\n\n\nanswer\n\npx.choropleth(\n    williams_2020_countries, \n    locations=\"Code\", \n    color=\"bau_habitat_loss_all\", \n    hover_name=\"Entity\",  \n    range_color=[-11,0],\n    height=500,\n    labels = {\n        \"bau_habitat_loss_all\": \"% change in habitat by 2050 (BAU)\"\n    }\n)"
  },
  {
    "objectID": "lab-3-practice-exercises.html#options-for-preventing-loss-of-wildlife-habitats",
    "href": "lab-3-practice-exercises.html#options-for-preventing-loss-of-wildlife-habitats",
    "title": "Week 3 - Practice Exercises",
    "section": "Options for preventing loss of wildlife habitats",
    "text": "Options for preventing loss of wildlife habitats\nThe above visualisations tell us that growing populations increase demand for food. This extra demand can be met by i) increasing area under cultivation, or ii) increasing crop yields. Much of the projected population growth is expected to occur in Africa in the coming decades. The same continent where crop yields have remained persistently low and habitat is located for many species.\nHowever, what would cropland expansion and habitat loss scenarios in 2050 look like if crop yield gaps were closed. That is, bringing crop yields up to their potential limits under optimum management. Williams et al. (2020) looked into this scenario.\nLet’s make two bar plots to visualise i) projected change in cropland area through to 2050 under a business as usual, and ii) projected change in cropland area through to 2050 under a closing yield gaps scenario. Use the williams_2020_continents DataFrame for this task. The projected change in cropland area when yield gaps are closed is the column yields_change_pct.\n## BAR PLOT: CHANGE IN CROPLAND AREA BAU ##\n\n\nanswer\n\npx.bar(\n    williams_2020_continents, \n    x=\"bau_change_pct\", \n    y=\"Continent\", \n    labels = {\n        \"bau_change_pct\": \"% change in cropland area by 2050 (BAU)\"\n    }\n)\n\n## BAR PLOT: CHANGE IN CROPLAND AREA CLOSING YIELD GAPS ##\n\n\nanswer\n\npx.bar(\n    williams_2020_continents, \n    x=\"yields_change_pct\", \n    y=\"Continent\", \n    labels = {\n        \"yields_change_pct\": \"% change in cropland area by 2050 (Close yield gaps)\"\n    }\n)\n\nThere are a few things to note when comparing these bar plots. One is that generally across all continents the change in area allocated to cropland when yield gaps close reduces. Second, that in some continents we can meet demand for food while taking land out of cultivation. Third, note the rapid drop in cropland expansion in Africa when closing yield gaps.\nLet’s viualise this with respect to change in habitat loss. Can you make a chloropleth map visualising the column \"yields_habitat_loss_all\" in the DataFrame williams_2020_countries? This will be a map showing the projected habitat loss for all species that will occur by 2050 due to cropland expansion if yield gaps are closed. Again, use the px.chloropleth() function. Set the range_color argument to [-5,5] (play around with changing this and see how this affects patterns visualised on the map). Also, set height to 500, color_continuous_scale to \"RdYlGn\", and color_continuous_midpoint to 0 (look up what the color_continuous_midpoint parameter does in the docs and think about why setting this to 0 makes sense).\n## ADD CODE HERE ##\n\n\nanswer\n\npx.choropleth(\n    williams_2020_countries, \n    locations=\"Code\", \n    color=\"yields_habitat_loss_all\", \n    hover_name=\"Entity\",  \n    range_color=[-5,5],\n    height=500,\n    color_continuous_scale=\"RdYlGn\",\n    color_continuous_midpoint=0,\n    labels = {\n        \"yields_habitat_loss_all\": \"% change in habitat by 2050 (Close yield gaps)\"\n    }\n)\n\nCompare the habitat loss due to cropland expansion (particularly over Sub-Saharan Africa and South America) under a scenario of closing yield gaps to a business as usual scenario.\nRun the following code to generate the business as usual habitat loss figure for comparison and note the different colour scales used.\npx.choropleth(\n    williams_2020_countries, \n    locations=\"Code\", \n    color=\"bau_habitat_loss_all\", \n    hover_name=\"Entity\",  \n    range_color=[-10,10],\n    height=500,\n    color_continuous_scale=\"RdYlGn\",\n    color_continuous_midpoint=0,\n    labels = {\n        \"bau_habitat_loss_all\": \"% change in habitat by 2050 (BAU)\"\n    }\n)\nWilliams et al. (2020) also looked at other options for meeting demand for food which reduce the need for cropland expansion. Among the options they looked at were changing diets to a less meat intensive diet (the EAT-Lancet diet) and halving food waste.\nLet’s make bar plots to compare the effect of closing yield gaps, adopting healthy diets, or halving food waster on cropland expansion.\nNote how there is still a large increase in cropland area in Africa under scenarios of adopting healthy diets and halving food waste. Also note how different solutions might be appropriate on different continents.\nCan you edit the below bar plots to use a consistent range of values on the x-axis to aid comparison?\npx.bar(\n    williams_2020_continents, \n    x=\"yields_change_pct\", \n    y=\"Continent\", \n    labels = {\n        \"yields_change_pct\": \"% change in cropland area by 2050 (Close yield gaps)\"\n    }\n)\npx.bar(\n    williams_2020_continents, \n    x=\"diets_change_pct\", \n    y=\"Continent\", \n    labels = {\n        \"diets_change_pct\": \"% change in cropland area by 2050 (adopt healthy diets)\"\n    }\n)\npx.bar(\n    williams_2020_continents, \n    x=\"waste_change_pct\", \n    y=\"Continent\", \n    labels = {\n        \"waste_change_pct\": \"% change in cropland area by 2050 (halve food waste)\"\n    }\n)"
  },
  {
    "objectID": "lab-3-practice-exercises.html#summary",
    "href": "lab-3-practice-exercises.html#summary",
    "title": "Week 3 - Practice Exercises",
    "section": "Summary",
    "text": "Summary\nThese exercises demonstrate how we can use data visualisations and animations to combine datasets from a range of subject areas (population, agriculture, biodiversity), explore them, and identify solutions to complex problems.\nHere, these datasets highlight the challenge of meeting food demand while protecting the habitat of many species under business-as-usual agricultural and demographic scenarios. However, visualising this data spatially illustrates how closing crop yield gaps in Africa could realise many benefits simultaneously of meeting food demand, achieving food security and development goals, and protecting habitats from conversion to cropland.\nThis exercise also demonstrates the importance of data visualisations as a communication tool (see the Our World in Data article: To protect the world’s wildlife we must improve crop yields – especially across Africa as a good example of this ). Data visualisations can be used to summarise the complexity of big datasets to tell an important story to a range of audiences.\nFinally, think about all the datasets used in these exercises: global historical and projected population time-series, global crop yield time-series, data on cropland area, habitats for species, diets, and food waste. These datasets are derived from a range of underlying data sources and models. Considerable skills in (spatial) data processing and analysis are required to generate all these underlying datasets that permit analyses such as that in Williams et al. (2020). This is where the skills you are learning in this course come in."
  },
  {
    "objectID": "lab-4.html",
    "href": "lab-4.html",
    "title": "Introduction",
    "section": "",
    "text": "Often, datasets need to go through a series of data wrangling and transformation steps before they are ready for analysis or visualisation tasks. This lab will demonstrate several data wrangling and transformation operations for raster, vector, and tabular data.\nWe will start with a subset of the AgriFieldNet Competition Dataset (Radiant Earth Foundation and IDinsight, 2022) which has been published to encourage people to develop machine learning models that classify a field’s crop type from satellite images. This dataset consists of a series of directories with each directory corresponding to a 256 x 256 pixel image footprint. Inside each directory are the following files:\n\n12 GeoTIFF files corresponding to spectral reflectance in different wavelengths from Sentinel-2 data.\n1 GeoTIFF file with non-zero pixels corresponding to a crop type label.\n1 GeoTIFF file with non-zero pixels corresponding to a field id.\n1 JSON metadata file.\n\nThis data is subset from a larger dataset covering agricultural fields in four Indian states: Odisha, Uttar Pradesh, Bihar, and Rajasthan. The field boundaries and crop type labels were captured by data collectors from IDinsight’s Data on Demand team and the satellite image preparation was undertaken by the Radiant Earth Foundation.\n\n\nOur task is to combine all the raster data in a folder into a tabular dataset that can be used for machine learning tasks to predict a field’s crop type. Specifically, we will transform a collection of GeoTiff files into a tabular dataset with columns for each field id, crop type, and field average spectral reflectance values. We will also store geometry data representing the location of each field in a geometry column.\n\nYou will learn a range of common data transformation operations to wrangle datasets into a structure suitable for analysis and visualisation.\nThis lab will focus on transformation operations applied to raster data. This lab will cover:\n\nattribute operations: subsetting rasters.\nattribute operations: band stacking to create multiband rasters.\nattribute operations: reshaping multiband rasters.\nspatial data operations: local map algebra operations to mathematically combine rasters.\n\n\n\n\nWickham and Grolemund (2017) and McKinney (2022) state that data wrangling consists of data import, data cleaning, and data transformation.\n\n\nData import was covered in week 2 with examples of how to read tabular, vector, and raster data into Python programs.\n\n\n\nData cleaning was covered in week 3 as part of the exploratory data analysis with examples of how to handle outliers and missing data.\n\n\n\nMcKinney (2022) define data transformation as the application of mathematical or statistical operations to data to generate new datasets. Data transformation can also include operations that reshape datasets or combine two or more datasets.\n\n\nDetailed notes on data transformation for spatial and non-spatial data\n\nAs we’re working with spatial and non-spatial data we can categorise data transformation operations as attribute operations, spatial operations, geometry operations, and raster-vector operations (Lovelace et al. (2022)).\nAttribute operations are applied to non-spatial (attribute data). This could be a tabular dataset without any spatial information, the attribute table of a vector dataset, or the pixel values of a raster dataset. Common attribute operations include:\n\nSelecting columns from a table based on a condition.\nSelecting (subsetting) pixels from a raster based on a condition.\nFiltering rows from a table based on a condition.\nCreating a new column of values using a function applied to existing data.\nComputing summary statistics of columns in a table or of pixel values in a raster.\nJoining datasets based on matching values in columns (keys).\n\nSpatial operations transform data using the data’s geographic information including shape and location. Vector spatial operations include:\n\nSpatial subsetting by selecting data points based on a geographic condition (e.g. selecting all fields in Western Australia).\nSpatial joins where datasets are combined based on their relationship in space.\nSpatial aggregation where summaries are produced for regions (e.g. the average crop yield for all fields in a region).\n\nSpatial operations on raster data are based on map algebra concepts and include:\n\nLocal operations which are applied on a pixel by pixel basis (e.g. converting a raster of temperature values in °F to °C).\nFocal operations which summarise or transform a raster value using the values of neihbouring pixels (e.g. computing the average value within a 3 x 3 pixel moving window).\nZonal operations which summarise or transform raster values using values inside an irregular shaped zone.\nGlobal operations which summarise the entire raster (e.g. computing the minimum value in the raster dataset).\n\nGeometry operations transform a dataset’s geographic information. Common geometry operations for vector data include:\n\nSimplification of shapes.\nComputing the centroid of polygons.\nClipping (subsetting) of geometries based on their intersection or relationship with another geometry.\n\nand geometry operations on raster data typically involve changing the spatial resolution and include:\n\nAggregation or dissagregation.\nResampling.\n\nRaster-vector operations involve both raster and vector datasets and include:\n\nCropping or masking raster data using a vector geometry.\nExtracting raster values that intersect with a vector geometry.\nRasterisation where a vector dataset is transformed to a raster layer.\nVectorisation where a raster dataset is transformed to a vector layer.\n\n\n\n\n\n\nFeature engineering is part of a machine learning workflow which involves preparing and preprocessing datasets ready for machine learning model training and evaluation. Feature engineering is one example where data wrangling operations are applied. This lab can be considered a feature engineering task where a range of raster satellite image datasets are transformed to a vector-tabular dataset which can be used to train and test a machine learning model. Often, datasets for machine learning computer vision tasks (e.g. see the datasets on Radiant Earth’s MLHub) are provided with data samples for model development spread across many sub-directories. Prior to model training you need to extract the data from these directories and assemble it in a way that it can be passed into a model. You can use this lab as a starter template for these kind of feature engineering tasks."
  },
  {
    "objectID": "lab-4.html#setup",
    "href": "lab-4.html#setup",
    "title": "Introduction",
    "section": "Setup",
    "text": "Setup\n\nRun the labs\nYou can run the labs locally on your machine or you can use cloud environments provided by Google Colab. If you’re working with Google Colab be aware that your sessions are temporary and you’ll need to take care to save, backup, and download your work.\n  \n\n\nDownload data\nIf you need to download the data for this lab, run the following code snippet.\nimport os\n\nif \"week-4\" not in os.listdir(os.getcwd()):\n    os.system('wget \"https://github.com/data-analysis-3300-3003/data/raw/main/data/week-4.zip\"')\n    os.system('unzip \"week-4.zip\"')\n\n\nWorking in Colab\nIf you’re working in Google Colab, you’ll need to install the required packages that don’t come with the colab environment.\nif 'google.colab' in str(get_ipython()):\n    !pip install geopandas\n    !pip install pyarrow\n    !pip install mapclassify\n    !pip install rasterio\n\n\nImport modules\n# Import modules\nimport os\nimport pandas as pd\nimport geopandas as gpd\nimport plotly.express as px\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport rasterio\nimport plotly.io as pio\nimport shapely.geometry\nimport pprint\n\nfrom rasterio import features\n\n# setup renderer\nif 'google.colab' in str(get_ipython()):\n    pio.renderers.default = \"colab\"\nelse:\n    pio.renderers.default = \"jupyterlab\""
  },
  {
    "objectID": "lab-4.html#data-storage",
    "href": "lab-4.html#data-storage",
    "title": "Introduction",
    "section": "Data storage",
    "text": "Data storage\nIn week 2 we showed that files are organised within a hierarchy of directories and sub-directories (or folders) in a computer system. Here, each sample (a 256 x 256 pixel image footprint) is stored in its own sub-directory. We can explore the structure of these directories and how files are arranged within them.\nFirst, let’s list the first level of sub-directories within the week-4 folder. Each of these sub-directories corresponds to a 256 x 256 pixel image.\nTo recap, we can use functions provided by the os package to help us explore directories. The os.path.join() function takes a sequence of string data representing directory names or file names and combines them into a path. The os.listdir() function lists all files or sub-directories in a directory pointed to by a path.\n\n# Load the image and labels data\ndata_path = os.path.join(os.getcwd(), \"week-4\", \"images\")\n\nimage_dirs = os.listdir(data_path)\nfor i in image_dirs:\n    if i != \".DS_Store\":\n        print(i)\n    \nif \".DS_Store\" in image_dirs:\n    image_dirs.remove(\".DS_Store\")\n\nref_agrifieldnet_competition_v1_source_0a1d5\nref_agrifieldnet_competition_v1_source_0a664\nref_agrifieldnet_competition_v1_source_0a729\nref_agrifieldnet_competition_v1_source_0a76e\nref_agrifieldnet_competition_v1_source_0aa46\nref_agrifieldnet_competition_v1_source_0afb8\nref_agrifieldnet_competition_v1_source_0b194\nref_agrifieldnet_competition_v1_source_0b1c5\nref_agrifieldnet_competition_v1_source_0b41f\nref_agrifieldnet_competition_v1_source_0b89a\n\n\nThe os.listdir() function lists files or directories at the first level of the directory passed into the function. However, often we have nested directory structures consisting of a hierarchy of sub-directories and files. The os.walk() can be used to traverse a directory tree. We can use the os.walk() function to fully reveal how the files are arranged within a sub-directory.\nWe can see that within each sub-directory corresponding to a 256 x 256 pixel image footprint there are the following files and sub-directories:\n\nFiles with the names B*.tif which are Sentinel-2 images for a particular waveband. For example, B02.tif is Sentinel-2 reflectance in the blue visible wavelength. These files will be used to generate predictor variables in a subsequent machine learning task to predict crop type.\nA field sub-directory which contains a field_ids.tif file. This file stores field ids as pixel values.\nA label sub-directory which contains a raster_labels.tif file. This file stores a numeric indicator of crop type as pixel values. These files store target labels used to train and test a machine learning model that predicts crop type from spectral reflectance data.\n\n\nfor root, dirs, files in os.walk(os.path.join(data_path, image_dirs[1]), topdown=True):\n    print(root)\n    for f in files:\n        print(f\"    {f}\")\n\n/home/jovyan/work/week-4/images/ref_agrifieldnet_competition_v1_source_0a664\n    .DS_Store\n    B01.tif\n    B02.tif\n    B03.tif\n    B04.tif\n    B05.tif\n    B06.tif\n    B07.tif\n    B08.tif\n    B09.tif\n    B11.tif\n    B12.tif\n    B8A.tif\n    stac.json\n/home/jovyan/work/week-4/images/ref_agrifieldnet_competition_v1_source_0a664/field\n    field_ids.tif\n/home/jovyan/work/week-4/images/ref_agrifieldnet_competition_v1_source_0a664/label\n    raster_labels.tif\n\n\n\nData visualisation\nLet’s quickly visualise some of this data to get an idea of its structure. First, let’s visualise the Sentinel-2 satellite image data starting with the image storing reflectance in the green visible portion of the electromagnetic spectrum.\nWe can see that the image shape is 256 x 256 pixels.\n\n# path to the green band GeoTIFF file\ns2_green_path = os.path.join(os.getcwd(), \"week-4\", \"images\", \"ref_agrifieldnet_competition_v1_source_0a664\", \"B03.tif\")\n\n# open the green band GeoTIFF file and read its image data\nwith rasterio.open(s2_green_path) as src:\n    green_band = src.read(1)\n    print(f\"the shape of the image is {green_band.shape}\")\n\n# plot the green band\npx.imshow(green_band, color_continuous_scale=\"Greens\", height=600)\n\nthe shape of the image is (256, 256)\n\n\n\n\n\nLet’s also create a true colour composite image using the red, green, and blue band images.\n\n# path to the red band GeoTIFF file\ns2_red_path = os.path.join(os.getcwd(), \"week-4\", \"images\", \"ref_agrifieldnet_competition_v1_source_0a664\", \"B04.tif\")\n\n# open the red band GeoTIFF file and read its image data\nwith rasterio.open(s2_red_path) as src:\n    red_band = src.read()\n\n# path to the green band GeoTIFF file\ns2_green_path = os.path.join(os.getcwd(), \"week-4\", \"images\", \"ref_agrifieldnet_competition_v1_source_0a664\", \"B03.tif\")\n\n# open the green band GeoTIFF file and read its image data\nwith rasterio.open(s2_green_path) as src:\n    green_band = src.read()\n    \n# path to the blue band GeoTIFF file\ns2_blue_path = os.path.join(os.getcwd(), \"week-4\", \"images\", \"ref_agrifieldnet_competition_v1_source_0a664\", \"B02.tif\")\n\n# open the blue band GeoTIFF file and read its image data\nwith rasterio.open(s2_blue_path) as src:\n    blue_band = src.read()\n    \n# make RGB image\nrgb = np.concatenate((red_band, green_band, blue_band), axis=0)\n\n# plot the rgb image\npx.imshow(np.moveaxis(rgb, 0, 2), contrast_rescaling=\"minmax\", height=600)\n\n\n\n\nNow, let’s explore the field id images. We can see that the image contains a few fields with ids assigned to them. Hover over each field and you can see its numeric id value. However, we can also see that a large portion of the image is covered by pixels with the value 0. These locations are not labelled fields and we will need to drop them from our dataset.\n\n# path to the GeoTIFF file\nfield_id_path = os.path.join(os.getcwd(), \"week-4\", \"images\", \"ref_agrifieldnet_competition_v1_source_0a664\", \"field/field_ids.tif\")\n\n# open the GeoTIFF file and read its image data\nwith rasterio.open(field_id_path) as src:\n    field_id_band = src.read(1)\n\n# plot the field id band\npx.imshow(field_id_band, color_continuous_scale=[\"#ffffff\", \"#1b9e77\", \"#d95f02\", \"#7570b3\", \"#e7298a\", \"#66a61e\", \"#e6ab02\", \"#a6761d\", \"#666666\"], height=600)\n\n\n\n\nFinally, we can look at our labels image. Each field’s pixels are assigned a numeric value that corresponds to a crop type. Based on the dataset’s documentation, this is the mapping between numeric values and crop types in the labels dataset.\n\n1 - Wheat\n2 - Mustard\n3 - Lentil\n4 - No crop/Fallow\n5 - Green pea\n6 - Sugarcane\n8 - Garlic\n9 - Maize\n13 - Gram\n14 - Coriander\n15 - Potato\n16 - Bersem\n36 - Rice\n\n\n# path to the GeoTIFF file\nlabel_path = os.path.join(os.getcwd(), \"week-4\", \"images\", image_dirs[1], \"label/raster_labels.tif\")\n\n# open the GeoTIFF file and read its metadata and image data\nwith rasterio.open(label_path) as src:\n    label_band = src.read(1)\n\n# Plot the crop label band\npx.imshow(label_band, color_continuous_scale=[\"#ffffff\", \"#1b9e77\", \"#d95f02\", \"#7570b3\", \"#e7298a\", \"#66a61e\", \"#e6ab02\", \"#a6761d\", \"#666666\"], height=600)"
  },
  {
    "objectID": "lab-4.html#raster-data-processing",
    "href": "lab-4.html#raster-data-processing",
    "title": "Introduction",
    "section": "Raster data processing",
    "text": "Raster data processing\n\nNumPy refresher\nIn week 2 we introduced NumPy ndarray objects for storing multidimensional (or N-dimensional) arrays which consist of a grid of elements of the same data type. ndarray objects are a logical data structure for representing and manipulating raster and image data in Python programs.\nThe dimensions of a NumPy ndarray are called axes. A single band raster layer would have two axes, rows (height) would be arranged along the 0th axis and columns (width) along the 1st axis. The shape of an ndarray refers to the number of elements along each axis.\n\nLet’s quickly revise these concepts by working with a raster layer with 3 rows and 3 columns.\n\ndemo_raster = np.array(\n    [[1, 2, 3],\n    [4, 5, 6],\n    [7, 8, 9]])\nprint(demo_raster)\n\n[[1 2 3]\n [4 5 6]\n [7 8 9]]\n\n\nThis ndarray object should have 2 axes corresponding to rows (0 axis) and columns (1 axis) with 3 elements along each axis.\n\nprint(f\"the shape of demo_raster is {demo_raster.shape}\")\nprint(f\"the number of elements on the 0 axis (rows) is {demo_raster.shape[0]}\")\nprint(f\"the number of elements on the 1 axis (columns) is {demo_raster.shape[1]}\")\n\nthe shape of demo_raster is (3, 3)\nthe number of elements on the 0 axis (rows) is 3\nthe number of elements on the 1 axis (columns) is 3\n\n\n\n\nSubsetting NumPy ndarrays\nThis is a form of subsetting opertation where you select values from a NumPy ndarray object based on their index locations. These operations are generally referred to as indexing and slicing when working with NumPy ndarray objects. Lovelace et al. (2022) refer to these operations on raster data as row-column subsetting.\n\nWe can extract a value from a NumPy ndarray based on its index location. For example, the first element of a 2-Dimensional ndarray is at location [0, 0] (i.e. the 0th row and 0th column).\n\nfirst_element = demo_raster[0, 0]\nprint(first_element)\n\n1\n\n\nWe can use the : symbol to specify slices of a NumPy ndarray to subset. For example, the following are three different ways of slicing the first two rows.\nNote that the slice is not inclusive of the index location after the : symbol. So, demo_raster[0:2, ] would select the first two rows of demo_raster - row 0 and row 1 (remember Python indexes from 0).\n\ntwo_rows_1 = demo_raster[0:2, ]\nprint(two_rows_1)\n\ntwo_rows_2 = demo_raster[0:2]\nprint(two_rows_2)\n\ntwo_rows_3 = demo_raster[:2]\nprint(two_rows_3)\n\n[[1 2 3]\n [4 5 6]]\n[[1 2 3]\n [4 5 6]]\n[[1 2 3]\n [4 5 6]]\n\n\nWe can use multiple slices for different axes. For example, if we wanted to subset values from a selection of rows and columns.\n\ntwo_rows_cols = demo_raster[:2, 1:]\nprint(two_rows_cols)\n\n[[2 3]\n [5 6]]\n\n\n\n\nBand stacking\nA common data wrangling and combination operation when working with raster data is band stacking. This is the process of taking two or more single band rasters and stacking them to create a multiband raster.\nWhen using NumPy ndarray objects to handle raster data, this process could involve stacking two ndarray objects with a shape of (256, 256) to create a new ndarray object with the shape (2, 256, 256). Here, axis 0 has a length of two which indicates that we’ve stacked two ndarray objects with the shape (256, 256).\nWe can use the NumPy stack() or concatenate() functions to combine a sequence of ndarrays along an axis.\nWe can write a short code snippet to start our data transformation program that will loop over Sentinel-2 bands, read the data stored in GeoTIFF files corresponding to Sentinel-2 reflectance values (bands) into an ndarray, and then use NumPy’s stack() function to stack a list of ndarrays to represent a multiband raster structure.\n\n\n\nDetailed step-by-step notes on the band stacking routine\n\nCreate an empty list which we’ll use to store ndarray objects of data read from the B*.tif GeoTIFF files. This is defined as bands = [], the [] creates an empty list:\n# empty list to append ndarray of reflectance value for each band to\nbands = []\n\n\nNow, iterate over the list of band names referenced by s2_bands and for each band read the data stored in the corresponding B*.tif file into a ndarray and append the ndarray to the bands list using the bands.append(src.read(1)) command.\n# loop over each band, read in the data from the corresponding GeoTIFF file into an ndarray\nfor b in s2_bands:\n    band_path = os.path.join(image_dir_path, b + \".tif\")\n    with rasterio.open(band_path) as src:\n        # append the ndarray storing the Sentinel-2 reflectance data for a band to a list\n        bands.append(src.read(1))\n\n\nYou will notice the use of the context manager denoted by the with block to read data from GeoTIFF files into a NumPy ndarray. This was covered in week 2, but let’s revise this quickly:\nwith rasterio.open(band_path) as src:\n\n\nCreates a file object referenced by src which points to the file at the path referenced by band_path (here a GeoTIFF file). The use of the with block as a context manager takes care of closing the connection src when we have finished reading data from the file. The file object src has a read() method which can be used to read data from the file it connects to into our Python program.\nsrc.read(1)\n\n\nFor each B*.tif file in a directory, we read it’s data into our program as:\n# loop over each band, read in the data from the corresponding GeoTIFF file into an ndarray\nfor b in s2_bands:\n    band_path = os.path.join(image_dir_path, b + \".tif\")\n    with rasterio.open(band_path) as src:\n        # append the ndarray storing the Sentinel-2 reflectance data for a band to a list\n        bands.append(src.read(1))\n\n\nOnce we have finished looping over the bands in the directory i, we can stack the ndarray objects in the list bands to form a NumPy ndarray representation of a multiband raster. We do this by passing the list of ndarray objects into the NumPy stack() function.\n# empty list to append ndarray of reflectance value for each band to\nbands = []\n    \n# loop over each band, read in the data from the corresponding GeoTIFF file into an ndarray\nfor b in s2_bands:\n    band_path = os.path.join(image_dir_path, b + \".tif\")\n    with rasterio.open(band_path) as src:\n        # append the ndarray storing the Sentinel-2 reflectance data for a band to a list\n        bands.append(src.read(1))\n\n# stack all bands in the list to create a multiband raster\nmultiband_raster = np.stack(bands)\n\n\n\nHere, we’ll keep working the GeoTIFF files in the following directory:\nimage_dir_path = os.path.join(os.getcwd(), \"week-4\", \"images\", \"ref_agrifieldnet_competition_v1_source_0a664\")\n\n# stacking bands \n\n# Sentinel-2 band names \ns2_bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n\n# empty list to append ndarray of reflectance value for each band to\nbands = []\n    \n# loop over each band, read in the data from the corresponding GeoTIFF file into an ndarray\nfor b in s2_bands:\n    print(f\"reading {b}.tif\")\n    band_path = os.path.join(image_dir_path, b + \".tif\")\n    with rasterio.open(band_path) as src:\n        # append the ndarray storing the Sentinel-2 reflectance data for a band to a list\n        bands.append(src.read(1))\n\n# stack all bands in the list to create a multiband raster\nmultiband_raster = np.stack(bands)\n    \n\nreading B01.tif\nreading B02.tif\nreading B03.tif\nreading B04.tif\nreading B05.tif\nreading B06.tif\nreading B07.tif\nreading B08.tif\nreading B8A.tif\nreading B09.tif\nreading B11.tif\nreading B12.tif\n\n\nLet’s inspect the output of the band stacking workflow. multiband_raster should be a ndarray objects of rank 3 with three axes (bands, rows, columns).\n\nprint(f\"the shape of the bands is {multiband_raster.shape} with rank {len(multiband_raster.shape)}\")\n\nthe shape of the bands is (12, 256, 256) with rank 3\n\n\n\n\nMap algebra\nFollowing Lovelace et al. (2022), we refer to map algebra as operations that transform raster pixel values via statistical or mathematical operations which can involve combining pixel values from different raster layers or using neighbouring raster values.\nLocal map algebra operations operate on a pixel by pixel basis; the mathematical operation is applied independently to each pixel without reference to neighbouring pixel values. For example, addition, subtraction, multiplication, and logical operations can all be applied on a pixel by pixel basis.\nA commonly used local operation when working with remote sensing data is computing spectral indices. Spectral indices are pixel by pixel mathematical combinations of spectral reflectance in different wavelengths that are used to monitor vegetation or land surface conditions. Read Zeng et al. (2022) for a review of vegetation indices.\nThe normalised difference vegetation index (NDVI) is used for tracking vegetation condition and representing the greenness of vegetation in a remote sensing image.\nAs we’re processing these remote sensing images to generate characteristics of fields that can be used to predict crop type, we will also compute each field’s NDVI value as it could contain useful information to discriminate between crop types.\nThe NDVI is computed as:\n\\(NDVI=\\frac{NIR-red}{NIR+red}\\)\nThus, the NDVI is computed via division, subtraction, and addition operations computed on a pixel by pixel basis using raster data corresponding to red and near infrared reflectance.\nNumPy provides tools for fast mathematical operations on ndarray objects. If ndarray objects have the same shape, a mathematical combination of two or more ndarray objects will be computed on an element by element (i.e. pixel by pixel) basis without needing to write for loops to iterate over ndarray elements. This feature of NumPy is called vectorisation and makes NumPy a useful tool for processing and analysing large amounts of image data.\nFor example, if we wanted to add two NumPy ndarray objects together on a pixelwise basis we could do this using for loops in Python:\n\n# slow array addition using for loops\na = np.array(\n    [[1, 2],\n     [3, 4]])\n\nb = np.array(\n    [[1, 2],\n     [3, 4]])   \n\nresult = np.zeros((2, 2))\n\nfor r in range(0, 2):\n    print(f\"processing row {r}\")\n    for c in range(0, 2):\n        print(f\"processing column {c}\")\n        \n        result[r, c] = a[r, c] + b[r, c]\n\nprint(result)     \n\nprocessing row 0\nprocessing column 0\nprocessing column 1\nprocessing row 1\nprocessing column 0\nprocessing column 1\n[[2. 4.]\n [6. 8.]]\n\n\nHowever, this approach will be slow if we are working with large raster datasets in NumPy ndarrays. It is also quite verbose, we need to write two for loops just to perform element-wise addition of two arrays. These element-wise operations can be computed in isolation. In other words adding the elements in pixel location 0, 0 does not depend on the result of adding elements in pixel location 0, 1. This means that element-wise operations can be performed in parallel, which is termed vectorised computation in NumPy, and you can use NumPy’s element-wise operations to perform mathematical operations on ndarrays in parallel.\nThis has two advantages: speed (particularly when working with large or many images) and cleaner code. The NumPy element-wise approach to adding the ndarrays a and b above is:\n\n# vectorised addition using for loops\na = np.array(\n    [[1, 2],\n     [3, 4]])\n\nb = np.array(\n    [[1, 2],\n     [3, 4]])  \n\nresult = a + b\n\nprint(result)\n\n[[2 4]\n [6 8]]\n\n\nNow we’re ready to use NumPy’s element wise operations to compute the NDVI. multiband_raster is an ndarray objects with each band storing reflectance in different wavelengths.\nRed reflectance is stored in band 4 of Sentinel-2 images. Thus, red reflectance would be located at index position 3 (the fourth element as we start indexing at 0) on axis 0.\nNear infrared reflectance is stored in band 8 of Sentinel-2 images. By the same logic near infrared reflectance is located at index position 7 on axis 0.\n\n# compute NDVI\n\n# get the red band - cast to float\nred = multiband_raster[3, :, :].astype(\"float64\")\n\n# get the nir band - cast to float\nnir = multiband_raster[7, :, :].astype(\"float64\")\n\n# compute the ndvi\nndvi = (nir-red)/(nir+red)\n\nprint(f\"the shape of the ndvi image is {ndvi.shape}\")\n\nthe shape of the ndvi image is (256, 256)\n\n\nNDVI values fall between -1 and 1 with values closer to 1 indicating greener vegetation and values less than 0 indicating an absence of vegetation. Let’s visualise the NDVI band and check the values fall within this range.\n\n# visualise the ndvi image\npx.imshow(ndvi, color_continuous_scale=\"viridis\", contrast_rescaling=\"minmax\", height=600)\n\n\n\n\nYou will have noticed that prior to computing the NDVI values we converted the red and near infrared ndarray objects to float64 type. This is because NDVI values represent variation in vegetation conditions using numbers with digits before and after the decimal point (a NDVI value of 0.8 would indicate green vegetation and a NDVI value of -0.2 would indicate an absence of green vegetation and possibly water cover). Thus, it is more appropriate to use floating point numbers to store NDVI values.\nIf you check the data type (dtype) of the values of the multiband ndarray objects storing reflectance data you will see that they are of type uint8. This means they are unsigned integers - they cannot represent negative values. However, NDVI values can be negative. Therefore, we should convert these values to a data type that can store negative and positive (i.e. signed) numbers.\nWe use the NumPy method astype() to cast an ndarray to a new dtype. You can read more about NumPy data types here.\n\nprint(f\"The dtype of the red band is {multiband_raster[3, :, :].dtype}\")\n\nThe dtype of the red band is uint8\n\n\nNow we have demonstrated how to compute NDVI values from NumPy ndarray objects, we can edit our existing routine that created rank 3 ndarray objects stacking by raster layers to also include an NDVI band.\n\n# stacking bands \n\n# Sentinel-2 band names \ns2_bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n\n# empty list to append ndarray of reflectance value for each band to\nbands = []\n    \n# loop over each band, read in the data from the corresponding GeoTIFF file into an ndarray\nfor b in s2_bands:\n    print(f\"reading {b}.tif\")\n    band_path = os.path.join(image_dir_path, b + \".tif\")\n    with rasterio.open(band_path) as src:\n        # append the ndarray storing the Sentinel-2 reflectance data for a band to a list\n        bands.append(src.read(1))\n\n# stack all bands in the list to create a multiband raster\nmultiband_raster = np.stack(bands)\n    \n# make NDVI band\nred = multiband_raster[3,:,:].astype(\"float64\")\nnir = multiband_raster[7,:,:].astype(\"float64\")\nndvi = (nir-red)/(nir+red)\nndvi = np.expand_dims(ndvi, axis=0) # add a bands axis\nmultiband_raster = np.concatenate((multiband_raster, ndvi), axis=0) # stack the ndvi band\n\nreading B01.tif\nreading B02.tif\nreading B03.tif\nreading B04.tif\nreading B05.tif\nreading B06.tif\nreading B07.tif\nreading B08.tif\nreading B8A.tif\nreading B09.tif\nreading B11.tif\nreading B12.tif\n\n\nLet’s visualise the NDVI band in multiband_raster to check it looks sensible. Also, note how we can use the index value -1 for the last element along an axis. The NDVI band was stacked at the end of the 0 axis of the ndarray so the NDVI raster is the last slice of the ndarray on the 0 axis.\n\nprint(f\"the shape of the first ndarray in stacked_bands is {multiband_raster.shape}\")\nprint(f\"the data type of the ndarray is {multiband_raster.dtype}\")\n\nndvi = multiband_raster[-1, :,  :]\n\n# visualise the ndvi image\npx.imshow(ndvi, color_continuous_scale=\"viridis\", contrast_rescaling=\"minmax\", height=600)\n\nthe shape of the first ndarray in stacked_bands is (13, 256, 256)\nthe data type of the ndarray is float64\n\n\n\n\n\n\n\nLabels and field id bands\nSo, far we have built a routine that processes the Sentinel-2 images using operations applied to raster data. These will form our predictor variables (features) that can be used to train a machine learning model that classifies crop type in subsequent tasks. Now we need to get the crop type labels that our model will learn to predict (classify) from the Sentinel-2 remote sensing data.\nWe can extend our program to do this. After we generate and stack the NDVI band we can read in the field id and crop type labels data and append them to the ndarray object too.\nLook for the following code in the routine below to see how this is done:\n### HERE WE ARE STACKING THE FIELD ID BAND \nfield_id_path = os.path.join(image_dir_path, \"field/field_ids.tif\")\nwith rasterio.open(field_id_path) as src:\n    field_ids = src.read().astype(\"float64\")\n    field_ids[field_ids == 0] = np.nan\n    multiband_raster = np.concatenate((bands, field_ids), axis=0)\nA few things to note:\n\nthe GeoTIFF files storing the field ids (field_ids.tif) and crop type labels (raster_labels.tif) are stored in sub-directories within each directory. This means we need to create a path that points to these files within their sub-directories.\npixels in the field_ids.tif raster with a value of 0 do not correspond to crop type labels. These pixels are not of interest to us here so we can set them to np.nan. Later we will drop all np.nan values so our dataset only reflects locations with crop type labels.\n\n\n# stacking bands \n\n# Sentinel-2 band names \ns2_bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n\n# empty list to append ndarray of reflectance value for each band to\nbands = []\n    \n# loop over each band, read in the data from the corresponding GeoTIFF file into an ndarray\nfor b in s2_bands:\n    print(f\"reading {b}.tif\")\n    band_path = os.path.join(image_dir_path, b + \".tif\")\n    with rasterio.open(band_path) as src:\n        # append the ndarray storing the Sentinel-2 reflectance data for a band to a list\n        bands.append(src.read(1))\n\n# stack all bands in the list to create a multiband raster\nmultiband_raster = np.stack(bands)\n    \n# make NDVI band\nred = multiband_raster[3,:,:].astype(\"float64\")\nnir = multiband_raster[7,:,:].astype(\"float64\")\nndvi = (nir-red)/(nir+red)\nndvi = np.expand_dims(ndvi, axis=0) # add a bands axis\nmultiband_raster = np.concatenate((multiband_raster, ndvi), axis=0) # stack the ndvi band\n    \n### HERE WE ARE STACKING THE FIELD ID BAND \nfield_id_path = os.path.join(image_dir_path, \"field/field_ids.tif\")\nwith rasterio.open(field_id_path) as src:\n    field_ids = src.read().astype(\"float64\")\n    field_ids[field_ids == 0] = np.nan\n    multiband_raster = np.concatenate((bands, field_ids), axis=0)\n\nreading B01.tif\nreading B02.tif\nreading B03.tif\nreading B04.tif\nreading B05.tif\nreading B06.tif\nreading B07.tif\nreading B08.tif\nreading B8A.tif\nreading B09.tif\nreading B11.tif\nreading B12.tif\n\n\n\nRecap quiz\nCan you extend the below routine to read in crop type labels associated with each 256 x 256 pixel image footprint and append this data to the ndarray object bands. You should follow a similar logic that was used for reading and appending the field id band above. There is a sub-directory label which stores a GeoTIFF file of crop type labels raster_labels.tif. Edit the code snippet below.\n\n# stacking bands \n\n# Sentinel-2 band names \ns2_bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n\n# empty list to append ndarray of reflectance value for each band to\nbands = []\n    \n# loop over each band, read in the data from the corresponding GeoTIFF file into an ndarray\nfor b in s2_bands:\n    print(f\"reading {b}.tif\")\n    band_path = os.path.join(image_dir_path, b + \".tif\")\n    with rasterio.open(band_path) as src:\n        # append the ndarray storing the Sentinel-2 reflectance data for a band to a list\n        bands.append(src.read(1))\n\n# stack all bands in the list to create a multiband raster\nmultiband_raster = np.stack(bands)\n    \n# make NDVI band\nred = multiband_raster[3,:,:].astype(\"float64\")\nnir = multiband_raster[7,:,:].astype(\"float64\")\nndvi = (nir-red)/(nir+red)\nndvi = np.expand_dims(ndvi, axis=0) # add a bands axis\nmultiband_raster = np.concatenate((multiband_raster, ndvi), axis=0) # stack the ndvi band\n    \n### HERE WE ARE STACKING THE FIELD ID BAND \nfield_id_path = os.path.join(image_dir_path, \"field/field_ids.tif\")\nwith rasterio.open(field_id_path) as src:\n    field_ids = src.read().astype(\"float64\")\n    field_ids[field_ids == 0] = np.nan\n    multiband_raster = np.concatenate((multiband_raster, field_ids), axis=0)\n    \n## HERE WE ARE STACKING THE CROP TYPE LABELS BAND \n\n## ADD CODE HERE \n\nreading B01.tif\nreading B02.tif\nreading B03.tif\nreading B04.tif\nreading B05.tif\nreading B06.tif\nreading B07.tif\nreading B08.tif\nreading B8A.tif\nreading B09.tif\nreading B11.tif\nreading B12.tif\n\n\n\n\nanswer\n\n# stacking bands \n\n# Sentinel-2 band names \ns2_bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n\n# empty list to append ndarray of reflectance value for each band to\nbands = []\n    \n# loop over each band, read in the data from the corresponding GeoTIFF file into an ndarray\nfor b in s2_bands:\n    print(f\"reading {b}.tif\")\n    band_path = os.path.join(image_dir_path, b + \".tif\")\n    with rasterio.open(band_path) as src:\n        # append the ndarray storing the Sentinel-2 reflectance data for a band to a list\n        bands.append(src.read(1))\n\n# stack all bands in the list to create a multiband raster\nmultiband_raster = np.stack(bands)\n    \n# make NDVI band\nred = multiband_raster[3,:,:].astype(\"float64\")\nnir = multiband_raster[7,:,:].astype(\"float64\")\nndvi = (nir-red)/(nir+red)\nndvi = np.expand_dims(ndvi, axis=0) # add a bands axis\nmultiband_raster = np.concatenate((multiband_raster, ndvi), axis=0) # stack the ndvi band\n    \n### HERE WE ARE STACKING THE FIELD ID BAND \nfield_id_path = os.path.join(image_dir_path, \"field/field_ids.tif\")\nwith rasterio.open(field_id_path) as src:\n    field_ids = src.read().astype(\"float64\")\n    field_ids[field_ids == 0] = np.nan\n    multiband_raster = np.concatenate((multiband_raster, field_ids), axis=0)\n    \n## HERE WE ARE STACKING THE CROP TYPE LABELS BAND \nlabels_path = os.path.join(image_dir_path, \"label/raster_labels.tif\")\nwith rasterio.open(labels_path) as src:\n    multiband_raster = np.concatenate((multiband_raster, src.read()), axis=0)\n\n\n\n\nReshaping raster data\nFor each 256 x 256 pixel Sentinel-2 image footprint, we have have created a multiband raster with each band storing reflectance in different wavelengths, computed an NDVI band and appended that to the stack of raster bands, and also stacked bands representing crop type labels for each pixel and a field id indicating which field a pixel belongs to. We have an ndarray object of rank 3 with axis 0 for bands, axis 1 for rows, and axis 2 for columns.\nOur goal is to create a tabular dataset where each column represents a variable (e.g. crop type, spectral reflectance, or field id) and each row represents a field. This tabular format is what is required for many machine learning tasks.\nThe next stage in our data transformation routine is to reshape the data from an image-style structure (i.e. where variables are stored along the bands or 0 axis) to a tabular style format where variables are stored along the columns axis. A tabular style dataset can be represented as a rank 2 ndarray (axis 0 for rows and axis 1 for columns). Therefore, we need a reshaping operation that will transform a rank 3 ndarray object to a rank 2 ndarray object and arrange variables along the 1 axis.\n\nAn ndarray object has a reshape() method. This method takes in a tuple of integers that describe the shape of the new ndarray. For example, let’s demonstrate reshaping a 3 x 3 ndarray to a 9 x 1 ndarray.\n\na = np.array([[1, 2, 3], \n             [1, 2, 3],\n             [1, 2, 3]])\n\na_reshaped = a.reshape((9, 1))\nprint(a_reshaped)\n\n[[1]\n [2]\n [3]\n [1]\n [2]\n [3]\n [1]\n [2]\n [3]]\n\n\nThe transpose is another common operation used for reshaping array-like objects. The transpose operation flips the rows and columns of an array. The transpose of a 5 x 4 array is a 4 x 5 array. NumPy ndarray objects have a transpose property T which returns the transpose of the array. We can demonstrate a few examples of viewing the transpose of an ndarray so you can build up an intuition of how it works.\n\na = np.array([[1, 2, 3, 4], \n             [1, 2, 3, 4],\n             [1, 2, 3, 4]])\n\na_transposed = a.T\nprint(\"Note how the 1 valued elements are now aligned along the columns or 1 axis\")\nprint(a_transposed)\n\nNote how the 1 valued elements are now aligned along the columns or 1 axis\n[[1 1 1]\n [2 2 2]\n [3 3 3]\n [4 4 4]]\n\n\n\nb = np.array([[3, 3, 3], \n             [4, 4, 4],\n             [5, 5, 5]])\n\nb_transposed = b.T\nprint(\"Note how the 3 valued elements are now aligned along the rows or 0 axis\")\nprint(b_transposed)\n\nNote how the 3 valued elements are now aligned along the rows or 0 axis\n[[3 4 5]\n [3 4 5]\n [3 4 5]]\n\n\nWe’ll need to reshape the ndarray object from rank 3 with shape (bands, rows, cols) to a rank 2 array with shape (bands, (rows * cols)). Instead of arranging the elements for each variable (i.e. reflectance values in different wavelengths, crop type, field id) in an image-style format (like a rank 2 array), the reshape operation will transform the ndarray so bands remain on the 0-axis but become rows and the the data values will be arranged along the 1 axis (columns).\nLet’s demonstrate this with the the ndarray in multiband_raster.\n\nprint(f\"the shape of multiband raster is {multiband_raster.shape}\")\n\nrows = multiband_raster.shape[1]\ncols = multiband_raster.shape[2]\nn_bands = multiband_raster.shape[0]\nmultiband_reshaped = multiband_raster.reshape(n_bands, rows*cols)\nprint(f\"the shape of the reshaped raster is {multiband_reshaped.shape}\")\n\nthe shape of multiband raster is (15, 256, 256)\nthe shape of the reshaped raster is (15, 65536)\n\n\nNow the we have reshaped the multiband raster to a tabular format, but the variables are arranged down the 0 axis (rows) and we want them arranged as columns. We can use a transpose operation to flip our now reshaped rank 2 ndarray to the desired tabular format structure.\n\ntabular_array = multiband_reshaped.reshape(n_bands, rows*cols).T\nprint(f\"the shape of the transposed array is {tabular_array.shape}\")\n\nthe shape of the transposed array is (65536, 15)\n\n\nNow we know how to transform our rank 3 ndarray objects representing multiband rasters to an ndarray representing a tabular format, we can extend our routine to perform the reshaping operations after the band stacking operations.\n\n# stacking bands \n\n# Sentinel-2 band names \ns2_bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n\n# empty list to append ndarray of reflectance value for each band to\nbands = []\n    \n# loop over each band, read in the data from the corresponding GeoTIFF file into an ndarray\nfor b in s2_bands:\n    print(f\"reading {b}.tif\")\n    band_path = os.path.join(image_dir_path, b + \".tif\")\n    with rasterio.open(band_path) as src:\n        # append the ndarray storing the Sentinel-2 reflectance data for a band to a list\n        bands.append(src.read(1))\n\n# stack all bands in the list to create a multiband raster\nmultiband_raster = np.stack(bands)\n    \n# make NDVI band\nred = multiband_raster[3,:,:].astype(\"float64\")\nnir = multiband_raster[7,:,:].astype(\"float64\")\nndvi = (nir-red)/(nir+red)\nndvi = np.expand_dims(ndvi, axis=0) # add a bands axis\nmultiband_raster = np.concatenate((multiband_raster, ndvi), axis=0) # stack the ndvi band\n    \n### HERE WE ARE STACKING THE FIELD ID BAND \nfield_id_path = os.path.join(image_dir_path, \"field/field_ids.tif\")\nwith rasterio.open(field_id_path) as src:\n    field_ids = src.read().astype(\"float64\")\n    field_ids[field_ids == 0] = np.nan\n    multiband_raster = np.concatenate((multiband_raster, field_ids), axis=0)\n    \n## HERE WE ARE STACKING THE CROP TYPE LABELS BAND \nlabels_path = os.path.join(image_dir_path, \"label/raster_labels.tif\")\nwith rasterio.open(labels_path) as src:\n    multiband_raster = np.concatenate((multiband_raster, src.read()), axis=0)\n\n# reshape multiband raster to tabular format\nrows = multiband_raster.shape[1]\ncols = multiband_raster.shape[2]\nn_bands = multiband_raster.shape[0]\nreshaped = multiband_raster.reshape(n_bands, rows*cols)\ntabular = reshaped.T\n\nreading B01.tif\nreading B02.tif\nreading B03.tif\nreading B04.tif\nreading B05.tif\nreading B06.tif\nreading B07.tif\nreading B08.tif\nreading B8A.tif\nreading B09.tif\nreading B11.tif\nreading B12.tif\n\n\n\nprint(f\"the shape of the ndarray representing the data in a tabular format is {tabular.shape}\")\n\nthe shape of the ndarray representing the data in a tabular format is (65536, 15)"
  },
  {
    "objectID": "lab-4-self-guided.html",
    "href": "lab-4-self-guided.html",
    "title": "Introduction",
    "section": "",
    "text": "Often, datasets need to go through a series of data wrangling and transformation steps before they are ready for analysis or visualisation tasks. This lab will demonstrate several data wrangling and transformation operations for raster, vector, and tabular data.\nWe will start with a subset of the AgriFieldNet Competition Dataset (Radiant Earth Foundation and IDinsight, 2022) which has been published to encourage people to develop machine learning models that classify a field’s crop type from satellite images. This dataset consists of a series of directories with each directory corresponding to a 256 x 256 pixel image footprint. Inside each directory are the following files:\n\n12 GeoTIFF files corresponding to spectral reflectance in different wavelengths from Sentinel-2 data.\n1 GeoTIFF file with non-zero pixels corresponding to a crop type label.\n1 GeoTIFF file with non-zero pixels corresponding to a field id.\n1 JSON metadata file.\n\nThis data is subset from a larger dataset covering agricultural fields in four Indian states: Odisha, Uttar Pradesh, Bihar, and Rajasthan. The field boundaries and crop type labels were captured by data collectors from IDinsight’s Data on Demand team and the satellite image preparation was undertaken by the Radiant Earth Foundation.\n\n\nOur task is to combine all the raster data in a folder into a tabular dataset that can be used for machine learning tasks to predict a field’s crop type. Specifically, we will transform a collection of GeoTiff files into a tabular dataset with columns for each field id, crop type, and field average spectral reflectance values. We will also store geometry data representing the location of each field in a geometry column.\n\nYou will learn a range of common data transformation operations to wrangle datasets into a structure suitable for analysis and visualisation.\nThis lab will focus on transformation operations applied to tabular and vector data. This lab will cover:\n\nattribute operations: data cleaning refresher (from week 3).\nattribute operations: subsetting DataFrames based on conditions.\nattribute operations: appending (concatenating) rows to tabular DataFrame objects.\nattribute operations: group-by and summarise operations of tabular DataFrame objects.\nattribute operations: key-based relational joins between two tables.\nraster-vector operations: vectorising raster data.\ngeometry operations: computing polygon geometry centroids.\nattribute operations: key-based relational joins between two tables.\nspatial data operations: spatial joins of two GeoDataFrame objects."
  },
  {
    "objectID": "lab-4-self-guided.html#setup",
    "href": "lab-4-self-guided.html#setup",
    "title": "Introduction",
    "section": "Setup",
    "text": "Setup\n\nRun the labs\nYou can run the labs locally on your machine or you can use cloud environments provided by Google Colab. If you’re working with Google Colab be aware that your sessions are temporary and you’ll need to take care to save, backup, and download your work.\n  \n\n\nDownload data\nIf you need to download the data for this lab, run the following code snippet.\nimport os\n\nif \"week-4\" not in os.listdir(os.getcwd()):\n    os.system('wget \"https://github.com/data-analysis-3300-3003/data/raw/main/data/week-4.zip\"')\n    os.system('unzip \"week-4.zip\"')\n\n\nWorking in Colab\nIf you’re working in Google Colab, you’ll need to install the required packages that don’t come with the colab environment.\nif 'google.colab' in str(get_ipython()):\n    !pip install geopandas\n    !pip install pyarrow\n    !pip install mapclassify\n    !pip install rasterio\n\n\nImport modules\n# Import modules\nimport os\nimport pandas as pd\nimport geopandas as gpd\nimport plotly.express as px\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport rasterio\nimport plotly.io as pio\nimport shapely.geometry\nimport pprint\n\nfrom rasterio import features\n\n# setup renderer\nif 'google.colab' in str(get_ipython()):\n    pio.renderers.default = \"colab\"\nelse:\n    pio.renderers.default = \"jupyterlab\"\n\n\nPreliminary processing\nThis weeks self-guided lab will pick up from lab-4 where we’d created a program to:\n\nread GeoTIFF files into NumPy ndarray objects\nstack the ndarray objects to create a multiband raster representation of the data\nreshape the multiband ndarray objects to a tabular-like structure\n\nIn this lab we will extend this program by converting the ndarray representation of a table to DataFrame object which we will further process with a range of tabular attribute and vector operations.\n\n# path to data\nimage_dir_path = os.path.join(os.getcwd(), \"week-4\", \"images\", \"ref_agrifieldnet_competition_v1_source_0a664\")\n\n# stacking bands \n\n# Sentinel-2 band names \ns2_bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n\n# empty list to append ndarray of reflectance value for each band to\nbands = []\n    \n# loop over each band, read in the data from the corresponding GeoTIFF file into an ndarray\nfor b in s2_bands:\n    print(f\"reading {b}.tif\")\n    band_path = os.path.join(image_dir_path, b + \".tif\")\n    with rasterio.open(band_path) as src:\n        # append the ndarray storing the Sentinel-2 reflectance data for a band to a list\n        bands.append(src.read(1))\n\n# stack all bands in the list to create a multiband raster\nmultiband_raster = np.stack(bands)\n    \n# make NDVI band\nred = multiband_raster[3,:,:].astype(\"float64\")\nnir = multiband_raster[7,:,:].astype(\"float64\")\nndvi = (nir-red)/(nir+red)\nndvi = np.expand_dims(ndvi, axis=0) # add a bands axis\nmultiband_raster = np.concatenate((multiband_raster, ndvi), axis=0) # stack the ndvi band\n    \n### HERE WE ARE STACKING THE FIELD ID BAND \nfield_id_path = os.path.join(image_dir_path, \"field/field_ids.tif\")\nwith rasterio.open(field_id_path) as src:\n    field_ids = src.read().astype(\"float64\")\n    field_ids[field_ids == 0] = np.nan\n    multiband_raster = np.concatenate((multiband_raster, field_ids), axis=0)\n    \n## HERE WE ARE STACKING THE CROP TYPE LABELS BAND \nlabels_path = os.path.join(image_dir_path, \"label/raster_labels.tif\")\nwith rasterio.open(labels_path) as src:\n    multiband_raster = np.concatenate((multiband_raster, src.read()), axis=0)\n\n# reshape multiband raster to tabular format\nrows = multiband_raster.shape[1]\ncols = multiband_raster.shape[2]\nn_bands = multiband_raster.shape[0]\nreshaped = multiband_raster.reshape(n_bands, rows*cols)\ntabular = reshaped.T\n\nreading B01.tif\nreading B02.tif\nreading B03.tif\nreading B04.tif\nreading B05.tif\nreading B06.tif\nreading B07.tif\nreading B08.tif\nreading B8A.tif\nreading B09.tif\nreading B11.tif\nreading B12.tif"
  },
  {
    "objectID": "lab-4-self-guided.html#attribute-data-operations",
    "href": "lab-4-self-guided.html#attribute-data-operations",
    "title": "Introduction",
    "section": "Attribute data operations",
    "text": "Attribute data operations\n\nPandas DataFrame and data cleaning\nAs our data is now in a tabular structure it makes sense to convert it from a NumPy ndarray object to Pandas a DataFrame object. Pandas DataFrame objects, and the pandas package more generally, are based on NumPy but have been tailored for working with tabular datasets. For example, a NumPy ndarray stores data of the same type in an array-like structure (e.g. all elements are integers). A pandas DataFrame can store different type data in different columns (e.g. column 0 is string, column 1 is floating point, etc.), but the values within each column are the same type and each column is typically a PandasArray which is based on a NumPy ndarray.\nColumns in a pandas DataFrame are called Series and a Series can be objects in your program independent of a DataFrame. A Series is an array-like sequence of values stored in a PandasArray which wraps a NumPy ndarray, and a DataFrame creates a tabular structure by combining one or more Series.\nOperations on Pandas DataFrames also borrow from NumPy’s style such as avoiding for-loops; however, they also provide several features and functions geared towards working with tabular datasets. A selection of these features include:\n\nindexing using column names\nrelational database style operations including key-based joins, conditional filtering and selection of data, and group-by and summarise\nsupport for working with time-series\nmore tools for handling missing data\n\nThus, Pandas DataFrame objects are useful for many attribute data transorfmation operations.\nTo convert a NumPy ndarray to a Pandas DataFrame we pass the array into the DataFrame’s constructor function helpfully named DataFrame(). The constructor function expects the NumPy ndarray and a list of column labels as arguments.\nLet’s quickly recap our data structures after we have performed several raster transformation operations on the GeoTIFF files. We have an ndarray object, tabular, which is a 2-Dimensional NumPy ndarray representing 256 x 256 pixel images in a tabular structure with pixels aligned down the rows (0-axis) and bands aligned along the columns (1-axis).\n\nprint(f\"tabular is of type {type(tabular)}\")\nprint(f\"tabular is an ndarray with shape {tabular.shape}\")\n\ntabular is of type <class 'numpy.ndarray'>\ntabular is an ndarray with shape (65536, 15)\n\n\n\n# convert ndarray to Pandas DataFrame\ns2_bands = ['B01', 'B02', 'B03', 'B04','B05', 'B06', 'B07', 'B08','B8A', 'B09', 'B11', 'B12']\n\n# create a DataFrame object from the first element in tables\ntmp_df = pd.DataFrame(tabular, columns=s2_bands + [\"ndvi\", \"field_id\", \"labels\"])\ntmp_df.head()\n\n\n\n\n\n  \n    \n      \n      B01\n      B02\n      B03\n      B04\n      B05\n      B06\n      B07\n      B08\n      B8A\n      B09\n      B11\n      B12\n      ndvi\n      field_id\n      labels\n    \n  \n  \n    \n      0\n      43.0\n      37.0\n      36.0\n      32.0\n      36.0\n      61.0\n      74.0\n      67.0\n      80.0\n      13.0\n      56.0\n      31.0\n      0.353535\n      NaN\n      0.0\n    \n    \n      1\n      43.0\n      37.0\n      36.0\n      32.0\n      36.0\n      61.0\n      74.0\n      68.0\n      80.0\n      13.0\n      56.0\n      31.0\n      0.360000\n      NaN\n      0.0\n    \n    \n      2\n      43.0\n      38.0\n      37.0\n      33.0\n      37.0\n      62.0\n      75.0\n      70.0\n      82.0\n      13.0\n      59.0\n      35.0\n      0.359223\n      NaN\n      0.0\n    \n    \n      3\n      43.0\n      37.0\n      37.0\n      34.0\n      37.0\n      62.0\n      75.0\n      70.0\n      82.0\n      13.0\n      59.0\n      35.0\n      0.346154\n      NaN\n      0.0\n    \n    \n      4\n      43.0\n      38.0\n      38.0\n      35.0\n      39.0\n      64.0\n      76.0\n      70.0\n      83.0\n      13.0\n      65.0\n      40.0\n      0.333333\n      NaN\n      0.0\n    \n  \n\n\n\n\nLooking at the DataFrame we can clearly see some NaN values in the field_id column. As each row in this DataFrame represents a pixel in the image, rows with NaN values in the field_id column are pixels which don’t have a crop type label. Therefore, we can drop them using the dropna() method - this will drop all rows from the DataFrame where there is a NaN value.\nLet’s inspect some metadata for the DataFrame we have created.\n\ntmp_df.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 65536 entries, 0 to 65535\nData columns (total 15 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   B01       65536 non-null  float64\n 1   B02       65536 non-null  float64\n 2   B03       65536 non-null  float64\n 3   B04       65536 non-null  float64\n 4   B05       65536 non-null  float64\n 5   B06       65536 non-null  float64\n 6   B07       65536 non-null  float64\n 7   B08       65536 non-null  float64\n 8   B8A       65536 non-null  float64\n 9   B09       65536 non-null  float64\n 10  B11       65536 non-null  float64\n 11  B12       65536 non-null  float64\n 12  ndvi      65536 non-null  float64\n 13  field_id  455 non-null    float64\n 14  labels    65536 non-null  float64\ndtypes: float64(15)\nmemory usage: 7.5 MB\n\n\nThe DataFrame’s info() method returns a summary of the column’s data types, count of non-null data, and the memory usage for the object. We can see that the field_id and labels columns are float64; however, these columns are storing categorical data so integer numbers would be a more appropriate type. Therefore, we can use the astype() method to convert these columns to integer type.\n\nRecap quiz\nCan you use the dropna() and astype() methods to i) drop all rows with NaN values, and ii) convert the field_id and labels columns to int32 type? Use the pandas docs for example uses of the dropna() and astype() methods.\n## ADD CODE HERE ##\n\n\nanswer\n\ntmp_df = tmp_df.dropna()\ntmp_df = tmp_df.astype({\"field_id\": \"int32\", \"labels\": \"int32\"})\n# Check the cast to integer type has worked. \n# Also, note the reduced memory usage after dropping all the nan rows\ntmp_df.info()\n\n\n\n\nGrouped summaries\nAnother common attribute operation when working with tabular data is performing grouped aggregations and summaries. For example, often we want to compute the mean, median, min, max, or sum of data values within groups in our dataset. This could be to generate summary tables for reporting purposes or an intermediate step in a data transformation workflow.\nOur goal for this data transformation workflow is to generate average spectral reflectance values in different wavelengths from Sentinel-2 images for each field with a crop type label. So far we have created a table where each row represents one pixel in a 256 x 256 image footprint and we have many pixels per field. We need to compute the average reflectance values for each field. This is a group-by and summarise operation - grouping by field and summarising using the mean.\nA group-by and summarise operation can be conceptualised as a sequence of split-apply-combine steps McKinney (2022):\n\nSplit your dataset into groups.\nApply a function to values in each group as a summary.\nCombine the results of applying the function to each group.\n\nFor our dataset we need to group-by field_id and labels (crop type column) and compute the mean of spectral reflectance values within each group.\nPandas DataFrames have a groupby() method that can take in a list of one or more column names. Calling this method returns a GroupBy object that creates groups from your dataset for each of the unique values of the grouping columns and can be used to apply summary operations to each group.\n\n# create a group using field id and crop type\ntmp_df_groups = tmp_df.groupby([\"field_id\", \"labels\"])\nprint(tmp_df_groups)\n\n<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f6bc8f335e0>\n\n\nFinally, we need to apply our summary operations to each group. We can do this by calling a function on the GroupBy object. A useful function for data exploration tasks is calling size() which tells us the number of observations in each group.\n\n# size of groups\ntmp_df_groups.size()\n\nfield_id  labels\n80        6          59\n81        1          70\n771       6          27\n772       6           7\n1009      4           6\n1054      2          43\n1316      6         175\n1481      2          51\n1482      4          17\ndtype: int64\n\n\nBy calling size() on the GroupBy object we can see that we have a group with a field_id of 81 and a crop type label of 1 (wheat). There are 70 observations in this group.\nIf we want to compute the mean of the spectral reflectance values within each group we can call mean() instead of size().\n\n# mean spectral reflectance values per group\ntmp_df_groups.mean()\n\n\n\n\n\n  \n    \n      \n      \n      B01\n      B02\n      B03\n      B04\n      B05\n      B06\n      B07\n      B08\n      B8A\n      B09\n      B11\n      B12\n      ndvi\n    \n    \n      field_id\n      labels\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      80\n      6\n      42.186441\n      37.389831\n      35.881356\n      32.949153\n      37.322034\n      58.847458\n      69.711864\n      64.728814\n      76.474576\n      12.000000\n      60.101695\n      35.830508\n      0.325059\n    \n    \n      81\n      1\n      43.000000\n      39.671429\n      38.771429\n      40.771429\n      43.242857\n      56.771429\n      65.700000\n      61.185714\n      72.800000\n      12.000000\n      72.971429\n      49.371429\n      0.200899\n    \n    \n      771\n      6\n      43.000000\n      38.555556\n      37.074074\n      36.777778\n      40.444444\n      56.518519\n      66.259259\n      61.518519\n      72.888889\n      12.074074\n      67.111111\n      43.296296\n      0.251846\n    \n    \n      772\n      6\n      42.000000\n      37.142857\n      35.428571\n      32.142857\n      36.714286\n      60.142857\n      72.285714\n      66.285714\n      79.142857\n      12.000000\n      58.285714\n      33.142857\n      0.346986\n    \n    \n      1009\n      4\n      43.500000\n      39.833333\n      39.000000\n      40.000000\n      43.666667\n      59.833333\n      69.833333\n      64.500000\n      76.500000\n      12.166667\n      73.166667\n      50.000000\n      0.234912\n    \n    \n      1054\n      2\n      42.000000\n      36.883721\n      35.139535\n      31.720930\n      36.953488\n      59.674419\n      71.023256\n      66.116279\n      78.093023\n      12.255814\n      59.767442\n      34.581395\n      0.351325\n    \n    \n      1316\n      6\n      42.417143\n      37.691429\n      36.451429\n      34.285714\n      38.994286\n      60.651429\n      71.891429\n      66.817143\n      79.074286\n      12.840000\n      65.982857\n      40.862857\n      0.321599\n    \n    \n      1481\n      2\n      43.666667\n      39.000000\n      37.686275\n      38.549020\n      41.941176\n      54.960784\n      63.568627\n      59.274510\n      70.627451\n      12.000000\n      72.137255\n      48.196078\n      0.211922\n    \n    \n      1482\n      4\n      42.000000\n      37.176471\n      35.176471\n      32.411765\n      36.882353\n      56.705882\n      66.176471\n      60.647059\n      72.235294\n      12.000000\n      54.764706\n      32.470588\n      0.302352\n    \n  \n\n\n\n\nWe’re now in a position to update our data transformation routine to include converting the ndarray object in a tabular-like structure to Pandas DataFrames, data cleaning to drop NaN pixels, and computing the mean spectral reflectance values for each field_id and crop type label combination.\n\n# path to data\nimage_dir_path = os.path.join(os.getcwd(), \"week-4\", \"images\", \"ref_agrifieldnet_competition_v1_source_0a664\")\n\n# stacking bands \n\n# Sentinel-2 band names \ns2_bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n\n# empty list to append ndarray of reflectance value for each band to\nbands = []\n    \n# loop over each band, read in the data from the corresponding GeoTIFF file into an ndarray\nfor b in s2_bands:\n    print(f\"reading {b}.tif\")\n    band_path = os.path.join(image_dir_path, b + \".tif\")\n    with rasterio.open(band_path) as src:\n        # append the ndarray storing the Sentinel-2 reflectance data for a band to a list\n        bands.append(src.read(1))\n\n# stack all bands in the list to create a multiband raster\nmultiband_raster = np.stack(bands)\n    \n# make NDVI band\nred = multiband_raster[3,:,:].astype(\"float64\")\nnir = multiband_raster[7,:,:].astype(\"float64\")\nndvi = (nir-red)/(nir+red)\nndvi = np.expand_dims(ndvi, axis=0) # add a bands axis\nmultiband_raster = np.concatenate((multiband_raster, ndvi), axis=0) # stack the ndvi band\n    \n### HERE WE ARE STACKING THE FIELD ID BAND \nfield_id_path = os.path.join(image_dir_path, \"field/field_ids.tif\")\nwith rasterio.open(field_id_path) as src:\n    field_ids = src.read().astype(\"float64\")\n    field_ids[field_ids == 0] = np.nan\n    multiband_raster = np.concatenate((multiband_raster, field_ids), axis=0)\n    \n## HERE WE ARE STACKING THE CROP TYPE LABELS BAND \nlabels_path = os.path.join(image_dir_path, \"label/raster_labels.tif\")\nwith rasterio.open(labels_path) as src:\n    multiband_raster = np.concatenate((multiband_raster, src.read()), axis=0)\n\n# reshape multiband raster to tabular format\nrows = multiband_raster.shape[1]\ncols = multiband_raster.shape[2]\nn_bands = multiband_raster.shape[0]\nreshaped = multiband_raster.reshape(n_bands, rows*cols)\ntabular = reshaped.T\n    \n### HERE WE CONVERT TO DATAFRAMES AND DROP NAN VALUES\ntmp_df = pd.DataFrame(tabular, columns=s2_bands + [\"ndvi\", \"field_id\", \"labels\"])\ndfs = tmp_df.dropna()\n    \ndfs = dfs.astype({\"field_id\": \"int32\", \"labels\": \"int32\"})\ndfs = dfs.groupby([\"field_id\", \"labels\"]).mean().reset_index()\n\nreading B01.tif\nreading B02.tif\nreading B03.tif\nreading B04.tif\nreading B05.tif\nreading B06.tif\nreading B07.tif\nreading B08.tif\nreading B8A.tif\nreading B09.tif\nreading B11.tif\nreading B12.tif\n\n\nLet’s quickly inspect the output. We should have one row per field_id and crop type label group. The DataFrame storing the results of this routine are referenced by the variable dfs.\n\ndfs\n\n\n\n\n\n  \n    \n      \n      field_id\n      labels\n      B01\n      B02\n      B03\n      B04\n      B05\n      B06\n      B07\n      B08\n      B8A\n      B09\n      B11\n      B12\n      ndvi\n    \n  \n  \n    \n      0\n      80\n      6\n      42.186441\n      37.389831\n      35.881356\n      32.949153\n      37.322034\n      58.847458\n      69.711864\n      64.728814\n      76.474576\n      12.000000\n      60.101695\n      35.830508\n      0.325059\n    \n    \n      1\n      81\n      1\n      43.000000\n      39.671429\n      38.771429\n      40.771429\n      43.242857\n      56.771429\n      65.700000\n      61.185714\n      72.800000\n      12.000000\n      72.971429\n      49.371429\n      0.200899\n    \n    \n      2\n      771\n      6\n      43.000000\n      38.555556\n      37.074074\n      36.777778\n      40.444444\n      56.518519\n      66.259259\n      61.518519\n      72.888889\n      12.074074\n      67.111111\n      43.296296\n      0.251846\n    \n    \n      3\n      772\n      6\n      42.000000\n      37.142857\n      35.428571\n      32.142857\n      36.714286\n      60.142857\n      72.285714\n      66.285714\n      79.142857\n      12.000000\n      58.285714\n      33.142857\n      0.346986\n    \n    \n      4\n      1009\n      4\n      43.500000\n      39.833333\n      39.000000\n      40.000000\n      43.666667\n      59.833333\n      69.833333\n      64.500000\n      76.500000\n      12.166667\n      73.166667\n      50.000000\n      0.234912\n    \n    \n      5\n      1054\n      2\n      42.000000\n      36.883721\n      35.139535\n      31.720930\n      36.953488\n      59.674419\n      71.023256\n      66.116279\n      78.093023\n      12.255814\n      59.767442\n      34.581395\n      0.351325\n    \n    \n      6\n      1316\n      6\n      42.417143\n      37.691429\n      36.451429\n      34.285714\n      38.994286\n      60.651429\n      71.891429\n      66.817143\n      79.074286\n      12.840000\n      65.982857\n      40.862857\n      0.321599\n    \n    \n      7\n      1481\n      2\n      43.666667\n      39.000000\n      37.686275\n      38.549020\n      41.941176\n      54.960784\n      63.568627\n      59.274510\n      70.627451\n      12.000000\n      72.137255\n      48.196078\n      0.211922\n    \n    \n      8\n      1482\n      4\n      42.000000\n      37.176471\n      35.176471\n      32.411765\n      36.882353\n      56.705882\n      66.176471\n      60.647059\n      72.235294\n      12.000000\n      54.764706\n      32.470588\n      0.302352"
  },
  {
    "objectID": "lab-4-self-guided.html#raster-vector-operations-and-vector-operations",
    "href": "lab-4-self-guided.html#raster-vector-operations-and-vector-operations",
    "title": "Introduction",
    "section": "Raster-vector operations and vector operations",
    "text": "Raster-vector operations and vector operations\nWe’re almost at the stage where we’ve processed a number of GeoTIFF files stored across many directories into a tabular dataset in a DataFrame object ready for machine learning. However, there are two more columns we need to create and append to the DataFrame. The first is a geometry column recording the centroid of each field. This allows us to keep a record of each field’s geographic location. We’ll also use this centroid to identify the district (an administrative boundary below the State-level in India) each field is located in.\nTo compute the centroid for each field we need to perform some raster-vector operations where each raster dataset is converted to a vector dataset. This is called vectorisation and can be achieved using rasterio’s shapes() function which returns the shape and value of connected regions in a raster dataset. Pixels belonging the same field in a raster layer should be connected (i.e. their edges touch) and they should have the same value (field id). Thus, applying the shapes() function to the raster layer of field ids should return vector polygons for each field outline.\nTo do this we’ll need to use the field_ids.tif file. Let’s quickly inspect this files again.\n\nfield_id_path = os.path.join(image_dir_path, \"field/field_ids.tif\")\nwith rasterio.open(field_id_path) as src:\n    print(f\"Printing metadata for field_ids.tif\")\n    pprint.pprint(src.meta)\n    print(\"\")\n\nPrinting metadata for field_ids.tif\n{'count': 1,\n 'crs': CRS.from_epsg(32644),\n 'driver': 'GTiff',\n 'dtype': 'uint16',\n 'height': 256,\n 'nodata': 0.0,\n 'transform': Affine(10.0, 0.0, 622880.0,\n       0.0, -10.0, 3010560.0),\n 'width': 256}\n\n\n\nWe have printed a dictionary object of metadata for the field_ids.tif file.\nLet’s look at what the shapes() function returns for field_ids.tif.\nThe shapes() function takes in a NumPy ndarray of raster values (generated by src.read() which reads the raster values from the GeoTIFF file into a NumPy ndarray in memory) and returns a generator object which generates a tuple for each shape in the raster data. The first element of the tuple is a dictionary object of coordinates and the type of geometry (e.g. point, line, polygon). The second element of the tuple is the attribute value that corresponds to the geometry. We can convert the generator into a list of tuples.\n\n\nfield_id_path = os.path.join(image_dir_path, \"field/field_ids.tif\")\nwith rasterio.open(field_id_path) as src:\n    # shapes is a generator\n    shapes = features.shapes(src.read(), transform=src.transform)\n\n    # list of geometry and shape value\n    field_shapes = list(shapes)\n    \n    # pretty print the first two elements of field_shapes\n    pprint.pprint(field_shapes[0:2])\n\n[({'coordinates': [[(625350.0, 3010380.0),\n                    (625370.0, 3010380.0),\n                    (625370.0, 3010370.0),\n                    (625390.0, 3010370.0),\n                    (625390.0, 3010360.0),\n                    (625410.0, 3010360.0),\n                    (625410.0, 3010350.0),\n                    (625430.0, 3010350.0),\n                    (625430.0, 3010320.0),\n                    (625420.0, 3010320.0),\n                    (625420.0, 3010300.0),\n                    (625410.0, 3010300.0),\n                    (625410.0, 3010280.0),\n                    (625400.0, 3010280.0),\n                    (625400.0, 3010270.0),\n                    (625390.0, 3010270.0),\n                    (625390.0, 3010250.0),\n                    (625380.0, 3010250.0),\n                    (625380.0, 3010230.0),\n                    (625370.0, 3010230.0),\n                    (625370.0, 3010220.0),\n                    (625360.0, 3010220.0),\n                    (625360.0, 3010200.0),\n                    (625350.0, 3010200.0),\n                    (625350.0, 3010180.0),\n                    (625310.0, 3010180.0),\n                    (625310.0, 3010190.0),\n                    (625290.0, 3010190.0),\n                    (625290.0, 3010200.0),\n                    (625270.0, 3010200.0),\n                    (625270.0, 3010240.0),\n                    (625280.0, 3010240.0),\n                    (625280.0, 3010250.0),\n                    (625290.0, 3010250.0),\n                    (625290.0, 3010270.0),\n                    (625300.0, 3010270.0),\n                    (625300.0, 3010290.0),\n                    (625310.0, 3010290.0),\n                    (625310.0, 3010310.0),\n                    (625320.0, 3010310.0),\n                    (625320.0, 3010330.0),\n                    (625330.0, 3010330.0),\n                    (625330.0, 3010350.0),\n                    (625340.0, 3010350.0),\n                    (625340.0, 3010360.0),\n                    (625350.0, 3010360.0),\n                    (625350.0, 3010380.0)]],\n   'type': 'Polygon'},\n  1316.0),\n ({'coordinates': [[(625430.0, 3010120.0),\n                    (625440.0, 3010120.0),\n                    (625440.0, 3010070.0),\n                    (625430.0, 3010070.0),\n                    (625430.0, 3010080.0),\n                    (625420.0, 3010080.0),\n                    (625420.0, 3010100.0),\n                    (625430.0, 3010100.0),\n                    (625430.0, 3010120.0)]],\n   'type': 'Polygon'},\n  772.0)]\n\n\nAt this stage, we’ve converted our raster data to a list of numbers representing coordinates for the shape. We now need to turn this list of coordinates into a geometry object. In Python, geometries are represented as Shapely Geometry objects. The geometry column in a GeoPandas GeoDataFrame is a Series of Shapely Geometry objects.\nTo create a Shapely Geometry object we extract the list of coordinates and pass them into the shapely.geometry.shape() function.\nPrinting geom should return a list of Shapely Geometry objects.\n\nfield_id_path = os.path.join(image_dir_path, \"field/field_ids.tif\")\nwith rasterio.open(field_id_path) as src:\n    # shapes is a generator\n    shapes = features.shapes(src.read(), transform=src.transform)\n\n    # list of geometry and shape value\n    field_shapes = list(shapes)\n\n    # create a list of Shapely Geometry objects\n    geom = []\n    for s in field_shapes:\n        geom.append(shapely.geometry.shape(s[0]))\n\n    print(geom)\n\n[<shapely.geometry.polygon.Polygon object at 0x7f6fc5216b60>, <shapely.geometry.polygon.Polygon object at 0x7f6fc5217e50>, <shapely.geometry.polygon.Polygon object at 0x7f6fc5216920>, <shapely.geometry.polygon.Polygon object at 0x7f6fc5217280>, <shapely.geometry.polygon.Polygon object at 0x7f6fc52178e0>, <shapely.geometry.polygon.Polygon object at 0x7f6f56b5cb50>, <shapely.geometry.polygon.Polygon object at 0x7f6f56b5f820>, <shapely.geometry.polygon.Polygon object at 0x7f6f56b5e830>, <shapely.geometry.polygon.Polygon object at 0x7f6f56b5f520>, <shapely.geometry.polygon.Polygon object at 0x7f6f56b5c100>]\n\n\nWe can also plot an element of geom to show it is a Shapely Geometry object.\n\ngeom[0]\n\n\n\n\n\ngeom[1]\n\n\n\n\n\nRecap quiz\n\n\nWhat object are we creating with []?\n\nAn empty list object.\n\n\n\n\n\nWhat type of object is geom and what elements does it store?\n\nIt is a list object which is storing a list of Shapely Geometry objects.\n\nNext, we compute the centroid for the polygon shape of the field. Computing a centroid is a geometry operation where the shape’s geometry is converted from a polygon to a point feature. To efficiently compute the centroid for the shapes returned by shapes() we can convert the list of Geometry objects to a GeoSeries and then use the GeoSeries centroid attribute to return a GeoSeries of centroids.\nInspecting this GeoSeries should reveal a sequence of point Geometry objects have been computed. This GeoSeries object is now referenced by geom.\n\nfield_id_path = os.path.join(image_dir_path, \"field/field_ids.tif\")\nwith rasterio.open(field_id_path) as src:\n    # shapes is a generator\n    shapes = features.shapes(src.read(), transform=src.transform)\n\n    # list of geometry and shape value\n    field_shapes = list(shapes)\n\n    # create a list of Shapely Geometry objects\n    geom = []\n    for s in field_shapes:\n        geom.append(shapely.geometry.shape(s[0]))\n\n    # compute centroids\n    geom = gpd.GeoSeries(geom, crs=src.crs).centroid\n\n    print(geom)\n\n0    POINT (625348.886 3010277.629)\n1    POINT (625432.143 3010093.571)\n2    POINT (624427.353 3010055.588)\n3    POINT (624406.860 3010018.721)\n4    POINT (623445.678 3009850.593)\n5    POINT (625380.000 3009830.000)\n6    POINT (623763.857 3009644.143)\n7    POINT (623465.980 3009577.157)\n8    POINT (625155.370 3009447.222)\n9    POINT (624157.525 3009275.277)\ndtype: geometry\n\n\nNow we have computed the centroid for each field, we can convert the points to a common coordinate reference system (EPSG:4326) using GeoPandas to_crs() method. We convert the points to a new coordinate system, EPSG:4326 which uses latitude and longitude values, to be able to perform vector operations using two vector datasets in future tasks (it is important that vector datasets have the same coordinate reference system to get correct and intended results).\nfield_id_path = os.path.join(image_dir_path, \"field/field_ids.tif\")\nwith rasterio.open(field_id_path) as src:\n    # shapes is a generator\n    shapes = features.shapes(src.read(), transform=src.transform)\n\n    # list of geometry and shape value\n    field_shapes = list(shapes)\n\n    # create a list of Shapely Geometry objects\n    geom = []\n    for s in field_shapes:\n        geom.append(shapely.geometry.shape(s[0]))\n\n    # compute centroids\n    geom = gpd.GeoSeries(geom, crs=src.crs).centroid\n\n    # reproject to EPSG 4326\n    geom = geom.to_crs(\"EPSG:4326\")\nIf we look at the object returned by the features.shapes(), it’s a tuple with coordinates for connected raster pixels with the same value in the first element and the second element is the value of those raster pixels.\n({'coordinates': [[(625350.0, 3010380.0),\n                    (625370.0, 3010380.0),\n                    (625370.0, 3010370.0),\n                    (625390.0, 3010370.0),\n                    (625390.0, 3010360.0),\n                    (625410.0, 3010360.0),\n                    (625410.0, 3010350.0),\n                    (625430.0, 3010350.0),\n                    (625430.0, 3010320.0),\n                    (625420.0, 3010320.0),\n                    (625420.0, 3010300.0),\n                    (625410.0, 3010300.0),\n                    (625410.0, 3010280.0),\n                    (625400.0, 3010280.0),\n                    (625400.0, 3010270.0),\n                    (625390.0, 3010270.0),\n                    (625390.0, 3010250.0),\n                    (625380.0, 3010250.0),\n                    (625380.0, 3010230.0),\n                    (625370.0, 3010230.0),\n                    (625370.0, 3010220.0),\n                    (625360.0, 3010220.0),\n                    (625360.0, 3010200.0),\n                    (625350.0, 3010200.0),\n                    (625350.0, 3010180.0),\n                    (625310.0, 3010180.0),\n                    (625310.0, 3010190.0),\n                    (625290.0, 3010190.0),\n                    (625290.0, 3010200.0),\n                    (625270.0, 3010200.0),\n                    (625270.0, 3010240.0),\n                    (625280.0, 3010240.0),\n                    (625280.0, 3010250.0),\n                    (625290.0, 3010250.0),\n                    (625290.0, 3010270.0),\n                    (625300.0, 3010270.0),\n                    (625300.0, 3010290.0),\n                    (625310.0, 3010290.0),\n                    (625310.0, 3010310.0),\n                    (625320.0, 3010310.0),\n                    (625320.0, 3010330.0),\n                    (625330.0, 3010330.0),\n                    (625330.0, 3010350.0),\n                    (625340.0, 3010350.0),\n                    (625340.0, 3010360.0),\n                    (625350.0, 3010360.0),\n                    (625350.0, 3010380.0)]],\n   'type': 'Polygon'},\n  1316.0)\n\n\nRecap quiz\nThis is a challenging quiz question, have a go at each of the steps and follow the pointers to previous code snippets or docs before reviewing the answer.\n1. We need create another Series of field ids using the value of raster pixels corresponding to the coordinates in a tuple. We can do this by looping over field_shapes (the list of tuples) and accessing the element at index position one in the tuple. Have a look at how we looped over field_shapes and accessed the coordinates at index position 0 in s and appended the object to the list geom. Use this logic as a template for how you could access the value in index position 1 and append it to a list.\n2. Once you have created this Series, you should set its type to int32 using the astype() method. These are the docs for astype().\n3. Then we need to combine the Series of field ids with the GeoSeries of field centroids in a GeoDataFrame. You can do this using the GeoDataFrame() constructor function: field_id_df = gpd.GeoDataFrame({'field_id': field_ids, 'geometry': geom}) (field_ids is a Series of field id values and geom is a GeoSeries of points.\n4. Finally, we need to drop rows in the GeoDataFrame with 0 values in the field_id column as these shapes don’t have a crop type label. You can use the loc[] method for this and refer back to the Subsetting pandas DataFrames section from the self-guided lab in week 3.\nfield_id_path = os.path.join(image_dir_path, \"field/field_ids.tif\")\nwith rasterio.open(field_id_path) as src:\n    # shapes is a generator\n    shapes = features.shapes(src.read(), transform=src.transform)\n\n    # list of geometry and shape value\n    field_shapes = list(shapes)\n\n    # create a list of Shapely Geometry objects\n    geom = []\n    for s in field_shapes:\n        geom.append(shapely.geometry.shape(s[0]))\n\n    # compute centroids\n    geom = gpd.GeoSeries(geom, crs=src.crs).centroid\n\n    # reproject to EPSG 4326\n    geom = geom.to_crs(\"EPSG:4326\")\n        \n    ## ADD CODE HERE ##\n\n\nanswer\n\nfield_id_path = os.path.join(image_dir_path, \"field/field_ids.tif\")\nwith rasterio.open(field_id_path) as src:\n    # shapes is a generator\n    shapes = features.shapes(src.read(), transform=src.transform)\n\n    # list of geometry and shape value\n    field_shapes = list(shapes)\n\n    # create a list of Shapely Geometry objects\n    geom = []\n    for s in field_shapes:\n        geom.append(shapely.geometry.shape(s[0]))\n\n    # compute centroids\n    geom = gpd.GeoSeries(geom, crs=src.crs).centroid\n\n    # reproject to EPSG 4326\n    geom = geom.to_crs(\"EPSG:4326\")\n\n    # create a Series of field ids\n    field_ids = []\n    for f in field_shapes:\n        field_ids.append(f[1])\n\n    field_ids = pd.Series(field_ids).astype(\"int32\")\n\n    # Combine the Series and GeoSeries into a DataFrame\n    field_id_df = gpd.GeoDataFrame({'field_id': field_ids, 'geometry': geom})\n\n    # drop shapes with value 0\n    field_id_df = field_id_df.loc[field_id_df[\"field_id\"] > 0, :]\n\n    print(field_id_df)\n\nIf you’ve successfully completed the recap quiz, you should have a variable field_id_df that references a GeoDataFrame with a column of field_id values and a geometry column of field centroids.\n\nfield_id_df\n\n\n\n\n\n  \n    \n      \n      field_id\n      geometry\n    \n  \n  \n    \n      0\n      1316\n      POINT (82.26570 27.20954)\n    \n    \n      1\n      772\n      POINT (82.26652 27.20787)\n    \n    \n      2\n      1482\n      POINT (82.25637 27.20762)\n    \n    \n      3\n      1054\n      POINT (82.25616 27.20729)\n    \n    \n      4\n      80\n      POINT (82.24644 27.20586)\n    \n    \n      5\n      1009\n      POINT (82.26597 27.20550)\n    \n    \n      6\n      81\n      POINT (82.24963 27.20397)\n    \n    \n      7\n      1481\n      POINT (82.24662 27.20339)\n    \n    \n      8\n      771\n      POINT (82.26366 27.20207)"
  },
  {
    "objectID": "lab-4-self-guided.html#joins",
    "href": "lab-4-self-guided.html#joins",
    "title": "Introduction",
    "section": "Joins",
    "text": "Joins\n\nKey-based joins\nWe now have two separate data objects in our Python program. We have a DataFrame storing average spectral reflectance values for each field, field id, and crop type label attributes (this is referenced by the variable dfs). We also have a GeoDataFrame storing the field id attribute and the field centroid as a point Geometry (this is referenced by the variable field_id_df).\nWhen two tables have a matching column(s) we can use join operations to combine them. Rows in both tables are matched using common values in the matching column(s) and the joined table has columns from both tables.\nJoining tables is a common operation in relational databases using SQL and the same operations can be implemented in Pandas using merge() functions.\nSome important concepts for join operations:\n\nThe columns with values used to match rows are called keys.\none-to-one joins are where there is exactly one match between rows in the two tables being joined.\nmany-to-one joins are where a row in one table can match one or more rows in another table.\nleft joins keep all rows in the left table and only matching rows in the right table.\ninner joins keep only matching rows in the left and right tables.\n\nThe Pandas merge() docs and McKinney (2022) provide useful explanations for how join operations work.\n\nLet’s use consider these concepts in the context of joining our DataFrame dfs storing average spectral reflectance values and crop type labels and our GeoDataFrame field_id_df which stores the field centroids.\nThe matching column in both tables is field_id. This the joining key.\nWe are joining the two tables on field_id which should be unique to each field. Therefore, we are implementing a one-to-one join.\nAs we’re using the field centroids for subsequent operations, we only want to keep fields that have a centroid value. Therefore, we’ll use an inner join.\nPandas merge() function expects the following arguments:\n\nleft - left table in the join.\nright - right table in the join.\nhow - whether to use a left or inner join.\nleft_on - columns in left table to use as keys.\nright_on - columns in the right table to use as keys.\n\n\nRecap quiz\nCan you use the merge() function to perform an inner join using the field_id column combining dfs and field_id_df? If the join is successful you should see a geometry column appended to the columns in dfs. Assign the result of this merge() to the variable joined_df.\n## ADD CODE HERE ##\n\n\nanswer\n\njoined_df = pd.merge(left=dfs, right=field_id_df, how=\"inner\", left_on=[\"field_id\"], right_on=[\"field_id\"])\n# display on the first few rows\njoined_df.head()\n\n\n# convert joined_df to GeoDataFrame\njoined_df = gpd.GeoDataFrame(joined_df, geometry=joined_df.geometry, crs=\"EPSG:4326\")\ntype(joined_df)\n\ngeopandas.geodataframe.GeoDataFrame\n\n\n\n\n\nSpatial Joins\nSpatial join operations join the attributes of two vector layers based on their relationship in space. For example, if we have a GeoDataFrame storing field boundaries (polygon geometries) and field attributes and another GeoDataFrame storing shire boundaries (polygon geometries) and a shire name as an attribute, we can join the the two tables based on the largest intersection (overlap) between field boundaries and shire boundaries. If the field boundaries GeoDataFrame was the left table in the spatial join, for each row (or geometry feature) the shire name from the shire with largest intersection would be joined to that table in a new column.\nGeoPandas provides an sjoin() function that can be used for spatial joins of two GeoDataFrames. The sjoin() function expects the following as arguments:\n\nleft_df - left GeoDataFrame in the spatial join.\nright_df - right GeoDataFrame in the spatial join - columns from the right_df will be joined to left_df.\nhow - whether to use a left, inner, or right join.\npredicate - a binary predicate that defines the spatial relationship between features in right_df and left_df.\n\nBinary predicates that can be used are:\n\nintersects\ncontains\ncrosses\nwithin\ntouches\noverlaps\n\nIntersects is the default predicate for spatial joins in GeoPandas.\n\nTo complete our data transformation routine we need to add a column to joined_df that stores the District that the field is located in. We can do this using a spatial join based on the intersect of the field’s centroid (point geometry) and the shape of the District (polygon geometry).\nBut, we need to read in District geometries for India obtained from geoBoundaries.\n\nindia_districts = gpd.read_file(os.path.join(os.getcwd(), \"week-4\", \"india-adm\", \"geoBoundaries-IND-ADM2_simplified.topojson\"))\nindia_districts.head()\n\n\n\n\n\n  \n    \n      \n      id\n      OBJECTID\n      shapeName\n      Level\n      Shape_Length\n      Shape_Area\n      shapeID\n      shapeGroup\n      shapeType\n      geometry\n    \n  \n  \n    \n      0\n      None\n      1\n      Ashoknagar\n      ADM2\n      3.925451\n      0.421664\n      IND-ADM2-76128533B24212364\n      IND\n      ADM2\n      POLYGON ((78.17492 24.84254, 78.19372 24.83812...\n    \n    \n      1\n      None\n      2\n      Raisen\n      ADM2\n      7.526803\n      0.748785\n      IND-ADM2-76128533B65758206\n      IND\n      ADM2\n      POLYGON ((77.38164 23.07007, 77.38918 23.07290...\n    \n    \n      2\n      None\n      3\n      Chhindwara\n      ADM2\n      7.724320\n      1.033143\n      IND-ADM2-76128533B77651862\n      IND\n      ADM2\n      POLYGON ((79.23985 22.79130, 79.24010 22.78983...\n    \n    \n      3\n      None\n      4\n      Betul\n      ADM2\n      6.736091\n      0.875211\n      IND-ADM2-76128533B14961718\n      IND\n      ADM2\n      POLYGON ((78.27227 22.39968, 78.27821 22.39640...\n    \n    \n      4\n      None\n      5\n      Hoshangabad\n      ADM2\n      5.467521\n      0.586915\n      IND-ADM2-76128533B94465219\n      IND\n      ADM2\n      POLYGON ((78.03032 22.79956, 78.03799 22.79956...\n    \n  \n\n\n\n\nLet’s quickly tidy up the India Districts GeoDataFrame to keep only the District name and geometry columns.\n\nindia_districts = india_districts.loc[:, [\"shapeName\", \"geometry\"]]\nindia_districts.columns = [\"district\", \"geometry\"]\nindia_districts = india_districts.set_crs(\"EPSG:4326\")\nindia_districts.head()\n\n\n\n\n\n  \n    \n      \n      district\n      geometry\n    \n  \n  \n    \n      0\n      Ashoknagar\n      POLYGON ((78.17492 24.84254, 78.19372 24.83812...\n    \n    \n      1\n      Raisen\n      POLYGON ((77.38164 23.07007, 77.38918 23.07290...\n    \n    \n      2\n      Chhindwara\n      POLYGON ((79.23985 22.79130, 79.24010 22.78983...\n    \n    \n      3\n      Betul\n      POLYGON ((78.27227 22.39968, 78.27821 22.39640...\n    \n    \n      4\n      Hoshangabad\n      POLYGON ((78.03032 22.79956, 78.03799 22.79956...\n    \n  \n\n\n\n\n\nindia_districts.plot(column=\"district\")\n\n<AxesSubplot: >\n\n\n\n\n\nThat looks like India. Let’s implement our final data transformation step and perform a spatial join to add a District column to joined_df.\n\nRecap quiz\nUse the GeoPandas docs to implement a spatial join with the sjoin() function that joins india_districts (as right_df) to joined_df (as left_df) using an inner join and intersects predicate. Assign the result to the variable joined_df_district.\n## ADD CODE HERE ##\n\n\nanswer\n\n# spatial join\njoined_df_district = gpd.sjoin(\n    left_df=joined_df, \n    right_df=india_districts, \n    how=\"inner\", \n    predicate=\"intersects\"\n)\njoined_df_district.head()\n\n\n\n\nSave file\nFinally, let’s write our processed data ready for training and testing a machine learning model to file.\n\nRecap quiz\nCan you save the data referenced by joined_df_district to a GeoJSON file on disk? Save the data with the filename processed_data.geojson at the path created by os.path.join(os.getcwd(), \"week-4\", \"processed_data.geojson\").\n## ADD CODE HERE ##\n\n\nanswer\n\n# save file\nout_path = os.path.join(os.getcwd(), \"week-4\", \"processed_data.geojson\")\njoined_df_district.to_file(out_path)"
  },
  {
    "objectID": "lab-4-practice-exercises.html",
    "href": "lab-4-practice-exercises.html",
    "title": "Week 4 Practice Exercises",
    "section": "",
    "text": "This notebook contains a range of practice exercises that demonstrate how data transformation and geoprocessing operations can be sequenced to complete a task. Here, we have a vector dataset of polygon geometries which correspond to areas in Fiji impacted by Tropical Cyclone Yasa. These geometries were digitised by the European Commission Copernicus Emergency Management Service (EMS) - Rapid Mapping Activations.\nWe also have a post tropical cyclone event NDVI image derived from Sentinel-2 data. We wish to i) compute the average NDVI value of pixels inside each polygon and ii) generate a sample of polygons where there was no observed disaster impact and compute the average NDVI values for these no-impact polygons.\nThe exercise of computing the average NDVI values for all pixels that intersect a polygon geometry is a raster-vector operation called zonal statistics. We will be using the Python package rasterstats which we installed above for computing zonal statistics.\nHowever, before we get to the stage where we can compute the zonal statistics we need to pre-process our polygon geometries. This involves reprojecting the geometries to match the coordinate reference system of the raster data. Then we need to perform a range of geometry operations to generate a sample of no-impact polygons. Geometry operations involve manipulating the shape of geometric objects.\nGeometry operations that manipulate shapes include computing the centroids of polygons (transforming a polygon object to a point), buffering a geometry (increasing the size of a geometry), computing the intersection between two geometries (reducing the area, length, or size of a geometry based on its relationship with another geometry), combining two geometries by computing their union. It is important to be able to look up different geometry operations in the GeoPandas documentation. Geometry operations are important parts of data transformation and geoprocessing workflows where raw or input spatial data is converted into a format for subsequent tasks such as statistical analysis, machine learning, or data visualisation."
  },
  {
    "objectID": "lab-4-practice-exercises.html#setup",
    "href": "lab-4-practice-exercises.html#setup",
    "title": "Week 4 Practice Exercises",
    "section": "Setup",
    "text": "Setup\nYou can run the labs locally on your machine or you can use cloud environments provided by Google Colab. If you’re working with Google Colab be aware that your sessions are temporary and you’ll need to take care to save, backup, and download your work.\n  \n\nDownload data\nimport os\n\nif \"week-4-practice\" not in os.listdir(os.getcwd()):\n    os.system('wget \"https://www.dropbox.com/s/muygsjbu13i2vvp/week-4-practice.zip\"')\n    os.system('unzip \"week-4-practice.zip\"')\n\n\nWorking in Colab\nIf you’re working in Google Colab, you’ll need to install the required packages that don’t come with the colab environment.\nif 'google.colab' in str(get_ipython()):\n    !pip install geopandas\n    !pip install pyarrow\n    !pip install mapclassify\n    !pip install rasterio\n    !pip install planetary-computer\n    !pip install pystac-client\n\n\nInstall rasterstats\n\n!pip install rasterstats\n\nRequirement already satisfied: rasterstats in /opt/conda/lib/python3.10/site-packages (0.18.0)\nRequirement already satisfied: affine<3.0 in /opt/conda/lib/python3.10/site-packages (from rasterstats) (2.4.0)\nRequirement already satisfied: click>7.1 in /opt/conda/lib/python3.10/site-packages (from rasterstats) (8.1.3)\nRequirement already satisfied: rasterio>=1.0 in /opt/conda/lib/python3.10/site-packages (from rasterstats) (1.3.4)\nRequirement already satisfied: simplejson in /opt/conda/lib/python3.10/site-packages (from rasterstats) (3.18.3)\nRequirement already satisfied: shapely in /opt/conda/lib/python3.10/site-packages (from rasterstats) (1.8.5.post1)\nRequirement already satisfied: cligj>=0.4 in /opt/conda/lib/python3.10/site-packages (from rasterstats) (0.7.2)\nRequirement already satisfied: fiona<1.9 in /opt/conda/lib/python3.10/site-packages (from rasterstats) (1.8.22)\nRequirement already satisfied: numpy>=1.9 in /opt/conda/lib/python3.10/site-packages (from rasterstats) (1.23.5)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from fiona<1.9->rasterstats) (2022.12.7)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from fiona<1.9->rasterstats) (65.6.3)\nRequirement already satisfied: attrs>=17 in /opt/conda/lib/python3.10/site-packages (from fiona<1.9->rasterstats) (22.2.0)\nRequirement already satisfied: six>=1.7 in /opt/conda/lib/python3.10/site-packages (from fiona<1.9->rasterstats) (1.16.0)\nRequirement already satisfied: click-plugins>=1.0 in /opt/conda/lib/python3.10/site-packages (from fiona<1.9->rasterstats) (1.1.1)\nRequirement already satisfied: munch in /opt/conda/lib/python3.10/site-packages (from fiona<1.9->rasterstats) (2.5.0)\nRequirement already satisfied: snuggs>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from rasterio>=1.0->rasterstats) (1.4.7)\nRequirement already satisfied: pyparsing>=2.1.6 in /opt/conda/lib/python3.10/site-packages (from snuggs>=1.4.1->rasterio>=1.0->rasterstats) (3.0.9)\n\n\n\n\nImport modules\nimport rasterio \nimport pandas as pd\nimport geopandas as gpd\nimport numpy as np\nimport os\nimport pprint \nimport pystac_client\nimport planetary_computer as pc\nimport plotly.express as px\nimport plotly.io as pio\nimport rasterio\nfrom rasterio import windows\nfrom rasterio import features\nfrom rasterio import warp\nfrom skimage import io\n\nfrom pystac.extensions.eo import EOExtension as eo\n\n# setup renderer\nif 'google.colab' in str(get_ipython()):\n    pio.renderers.default = \"colab\"\nelse:\n    pio.renderers.default = \"jupyterlab\"\nfrom rasterstats import zonal_stats"
  },
  {
    "objectID": "lab-4-practice-exercises.html#geometry-operations",
    "href": "lab-4-practice-exercises.html#geometry-operations",
    "title": "Week 4 Practice Exercises",
    "section": "Geometry operations",
    "text": "Geometry operations\nLet’s load the vector polygon data that delineates the observed disaster impact following Tropical Cyclone Yasa and visualise it to see it’s structure.\n\nobs_event_path = os.path.join(os.getcwd(), \"week-4-practice\", \"EMSR489_AOI07_GRA_PRODUCT_observedEventA_r1_v1.shp\")\nobs_event_gdf = gpd.read_file(obs_event_path)\nobs_event_gdf.explore()\n\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\nobs_event_gdf.head()\n\n\n\n\n\n  \n    \n      \n      event_type\n      obj_desc\n      det_method\n      notation\n      dmg_src_id\n      area\n      geometry\n    \n  \n  \n    \n      0\n      5-Flood\n      Coastal flood\n      Photo-interpretation\n      Flooded area\n      2\n      0.116880\n      POLYGON ((179.32164 -16.45597, 179.32160 -16.4...\n    \n    \n      1\n      5-Flood\n      Coastal flood\n      Photo-interpretation\n      Flooded area\n      2\n      0.117763\n      POLYGON ((179.31929 -16.45974, 179.31927 -16.4...\n    \n    \n      2\n      5-Flood\n      Coastal flood\n      Photo-interpretation\n      Flooded area\n      2\n      0.089316\n      POLYGON ((179.31975 -16.46000, 179.31970 -16.4...\n    \n    \n      3\n      5-Flood\n      Coastal flood\n      Photo-interpretation\n      Flooded area\n      2\n      0.197164\n      POLYGON ((179.31988 -16.46047, 179.31985 -16.4...\n    \n    \n      4\n      5-Flood\n      Coastal flood\n      Photo-interpretation\n      Flooded area\n      2\n      0.268161\n      POLYGON ((179.32041 -16.46056, 179.32035 -16.4...\n    \n  \n\n\n\n\nWe’re going to be using these geometries in a zonal statistics operation. This is a raster-vector operation where we compute summary statistics for all raster pixels that intersect with a polygon geometry. Here, we’ll use a Sentinel-2 NDVI image captured just after Tropical Cyclone Yasa impacted this region. However, this satellite image has the projection system EPSG:32760.\nCan you use the GeoPandas GeoDataFrame method to_crs() to convert obs_event_gdf to EPSG:32760? Assign the variable name obs_event_gdf_32760 to the reprojected GeoDataFrame.\nThe GeoPandas docs for reprojection are here if you want to look up how to do this.\n## ADD CODE HERE ##\n\n\nanswer\n\nobs_event_gdf_32760 = obs_event_gdf.to_crs(\"EPSG:32760\")\n\n\n\n\n\nWhy do we need the polygon geometries and raster data to be in the same projection system for zonal statistics operations?\n\nTo ensure the polygon geometries are intersected with raster pixels that correspond to the same location on the Earth’s land surface.\n\n\n\nOur task is to compute summary statistics for each of the polygon geometries that delineate an area impacted by the tropical cyclone event. However, for comparison, we’d also like to generate some sample polygons of areas without a visible impact. We can do this through a sequence of geoprocessing operations that manipulate geometry objects.\nThe first step is to combine our GeoDataFrame of many polygon objects into a single multipolygon object. We can do this using the unary_union property of a GeoSeries (i.e. the geometry column in a GeoDataFrame). The unary_union computes the union of many polygon objects. The is a geometry aggregation operation, combining many geometry objects into one.\nBelow is a quick visualisation of a multipolygon object. We can use multipolygon objects in a number of ways in our programs. For example, we could use multipolygon objects to conveniently represent a country consisting of many islands as a single feature. However, here we’ll use them as they help simplify some of the geometry operations we wish to perform in subsequent tasks.\n\nimport shapely\nshapely.geometry.MultiPolygon([\n    shapely.geometry.Polygon([(0.8,0.8), (0.9,1.0), (1.0,0.9), (0.9,0.9), (0.8,0.8)]), \n    shapely.geometry.Polygon([(0.0,0.1), (0.2,0.4), (0.4,0.3), (0.0,0.0), (0.0,0.1)])\n])\n\n\n\n\nIf we print the multipolygon object, you can see the geometries are represented as a nested collection of polygons.\n\nprint(\n    shapely.geometry.MultiPolygon([\n        shapely.geometry.Polygon([(0.8,0.8), (0.9,1.0), (1.0,0.9), (0.9,0.9), (0.8,0.8)]), \n        shapely.geometry.Polygon([(0.0,0.1), (0.2,0.4), (0.4,0.3), (0.0,0.0), (0.0,0.1)])\n    ])\n)\n\nMULTIPOLYGON (((0.8 0.8, 0.9 1, 1 0.9, 0.9 0.9, 0.8 0.8)), ((0 0.1, 0.2 0.4, 0.4 0.3, 0 0, 0 0.1)))\n\n\nLet’s quickly inspect the structure of our GeoDataFrame with each polygon geometry on its own row.\n\nobs_event_gdf_32760.head()\n\n\n\n\n\n  \n    \n      \n      event_type\n      obj_desc\n      det_method\n      notation\n      dmg_src_id\n      area\n      geometry\n    \n  \n  \n    \n      0\n      5-Flood\n      Coastal flood\n      Photo-interpretation\n      Flooded area\n      2\n      0.116880\n      POLYGON ((747882.541 8179203.830, 747878.308 8...\n    \n    \n      1\n      5-Flood\n      Coastal flood\n      Photo-interpretation\n      Flooded area\n      2\n      0.117763\n      POLYGON ((747626.133 8178789.386, 747623.751 8...\n    \n    \n      2\n      5-Flood\n      Coastal flood\n      Photo-interpretation\n      Flooded area\n      2\n      0.089316\n      POLYGON ((747674.948 8178759.223, 747669.789 8...\n    \n    \n      3\n      5-Flood\n      Coastal flood\n      Photo-interpretation\n      Flooded area\n      2\n      0.197164\n      POLYGON ((747688.839 8178707.629, 747685.664 8...\n    \n    \n      4\n      5-Flood\n      Coastal flood\n      Photo-interpretation\n      Flooded area\n      2\n      0.268161\n      POLYGON ((747745.195 8178697.311, 747738.845 8...\n    \n  \n\n\n\n\nNow, let’s compute the unary_union of the geometry column. It should return to us a GeoSeries with one element (a multipolygon object that has aggregated all the polygons in our GeoDataFrame into a single feature).\n\nobs_event_gdf_union = gpd.GeoSeries(obs_event_gdf_32760[\"geometry\"].unary_union).set_crs(\"EPSG:32760\")\nobs_event_gdf_union\n\n0    MULTIPOLYGON (((747853.543 8178546.895, 747859...\ndtype: geometry\n\n\nNow we have combined our polygons into a single multipolygon object, we can use the buffer operation to expand the geometries by a specified distance to cover areas outside the locations impacted by Tropical Cyclone Yasa.\nCan you apply a 100 m buffer to the multipolygon object referenced by obs_event_gdf_union and reference it with the variable name obs_event_gdf_buffer?\n## ADD CODE HERE ##\n\n\nanswer\n\nobs_event_gdf_buffer = obs_event_gdf_union.buffer(100)\n\n\n\nNext, we’ll need to set the CRS for the buffered geometries back to EPSG:32760. In the map below, areas where disaster impact following the tropical cyclone was observed are coloured red and adjacent areas where not disaster impact was observed are coloured blue.\n\nobs_event_gdf_buffer = obs_event_gdf_buffer.set_crs(\"EPSG:32760\")\nm = obs_event_gdf_buffer.explore()\nobs_event_gdf_32760.explore(m=m, color=\"red\")\n\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\nWe want to use this data as sample polygons where there was no disaster impact. Therefore, we need to remove the interior areas of the polygons which correspond to the locations where disaster impact on the land surface was recorded (these are the red polygons on the map above). We can do this using the GeoPandas difference() method; this returns to us geometries of all the locations in one geometry that are not in another geometry.\n\nCan you use the difference() method of the GeoDataFrame obs_event_gdf_buffer to remove locations where a disaster event impact was recorded (represented in the GeoDataFrame obs_event_gdf_union)?\nAssign the result to the variable name obs_event_no_impact.\n## ADD CODE HERE ##\n\n\nanswer\n\nobs_event_no_impact = obs_event_gdf_buffer.difference(obs_event_gdf_union)\n\n\n\nLet’s check the result looks sensible.\n\nobs_event_no_impact.explore()\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\nWhy did we compute the buffer and difference operations on a multipolygon (created via the unary_union) instead of using a GeoDataFrame of many polygon geometries?\n\nIf we computed the buffer operation on many separate polygons, we’d be returned many larger buffered polygons which would be overlapping in places. This, in itself, is not necessarily an issue. But, we use the buffered polygons in a difference() operation to remove interior areas where disaster impacts occurred. The difference() operation works on a row-by-row basis (i.e. the geometry in row 1 of GeoDataFrame A is compared to the geometry of row 1 in GeoDataFrame B - the geometry in row 1 of GeoDataFrame A is NOT compared to the geometry of row 2 in GeoDataFrame B). This is problematic if the disaster impact area of represented by the geometry in row 2 in GeoDataFrame B overlaps with the geometry in row 1 of GeoDataFrame A. In this case we would not be able to fully remove areas where disaster impact was recorded. However, by comparing two multipolygon objects on a row-by-row basis (there is just one row in GeoDataFrame A and B) we can ensure all areas where disaster impact was recorded are removed.\n\nNow, let’s convert the GeoSeries multipolygon object into a GeoSeries of many individual polygon objects using the explode method. This operation takes each of the polygons that comprise the composite multipolygon feature and returns them as a GeoSeries of separate polygon features.\n\n\nWhy have we used the explode method to split a multipolygon representation of areas not impacted by the disaster event into separate polygons?\n\nWe will use these polygons to capture the NDVI signal of areas not impacted by Tropical Cyclone Yasa. If we compute the mean NDVI value for all pixels that intersect with the multipolygon object we’ll get a single value for the entire region of interest. This single mean NDVI value might mask lots of spatial variation in the NDVI signal of not impacted areas; computing the NDVI value for many smaller polygons can provide information on variation in the NDVI values of not impacted areas across the scene. Also, if we have many geometries representing not impacted areas which we can compute mean NDVI values for, we can compare these NDVI values with the mean NDVI of nearby polygons where there was a disaster impact. This might give us a more accurate indication of the impact of the Tropical Cyclone on vegetation cover as we’re more likely to be comparing similar land covers or exposure to cyclone event.\n\n\nobs_event_no_impact\n\n0    MULTIPOLYGON (((755506.240 8181026.807, 755501...\ndtype: geometry\n\n\n\nobs_event_no_impact = obs_event_no_impact.explode(ignore_index=True)\nobs_event_no_impact\n\n0     POLYGON ((755506.240 8181026.807, 755501.171 8...\n1     POLYGON ((755051.258 8181594.507, 755049.445 8...\n2     POLYGON ((753480.667 8181490.978, 753479.999 8...\n3     POLYGON ((753367.195 8182994.416, 753376.130 8...\n4     POLYGON ((753613.613 8182533.814, 753611.018 8...\n5     POLYGON ((753289.101 8180423.611, 753296.224 8...\n6     POLYGON ((753463.427 8182276.244, 753460.801 8...\n7     POLYGON ((753137.410 8181383.454, 753141.253 8...\n8     POLYGON ((752985.150 8183917.505, 752976.195 8...\n9     POLYGON ((753125.718 8180358.689, 753135.367 8...\n10    POLYGON ((752345.024 8181298.596, 752334.705 8...\n11    POLYGON ((752335.368 8182099.952, 752344.277 8...\n12    POLYGON ((752137.763 8183893.892, 752131.481 8...\n13    POLYGON ((751827.995 8180825.032, 751827.430 8...\n14    POLYGON ((750009.854 8180620.064, 750009.057 8...\n15    POLYGON ((749401.708 8182513.764, 749399.327 8...\n16    POLYGON ((750564.409 8181308.106, 750556.356 8...\n17    POLYGON ((749696.598 8180896.132, 749690.178 8...\n18    POLYGON ((749625.376 8180238.871, 749625.540 8...\n19    POLYGON ((749537.201 8179530.259, 749538.811 8...\n20    POLYGON ((749320.180 8181272.053, 749319.849 8...\n21    POLYGON ((749341.774 8181995.004, 749345.743 8...\n22    POLYGON ((749113.147 8180440.903, 749104.504 8...\n23    POLYGON ((749291.317 8180080.297, 749293.406 8...\n24    POLYGON ((749181.323 8179513.807, 749179.941 8...\n25    POLYGON ((749082.134 8180881.527, 749077.184 8...\n26    POLYGON ((749146.550 8182701.924, 749145.359 8...\n27    POLYGON ((748940.859 8181362.440, 748944.035 8...\n28    POLYGON ((746237.927 8181663.791, 746234.077 8...\n29    POLYGON ((748015.547 8179802.092, 748013.857 8...\n30    POLYGON ((748717.874 8180227.628, 748718.303 8...\n31    POLYGON ((748293.456 8178644.194, 748294.692 8...\n32    POLYGON ((748652.653 8180850.530, 748662.656 8...\n33    POLYGON ((747636.336 8180918.198, 747628.161 8...\n34    POLYGON ((747421.062 8179177.721, 747422.771 8...\n35    POLYGON ((747833.198 8179346.504, 747842.510 8...\n36    POLYGON ((747248.685 8179560.028, 747250.523 8...\n37    POLYGON ((747298.769 8182200.459, 747303.004 8...\n38    POLYGON ((747306.912 8180394.610, 747314.663 8...\n39    POLYGON ((747027.611 8181091.017, 747026.552 8...\n40    POLYGON ((746974.111 8182028.863, 746971.325 8...\ndtype: geometry\n\n\nFinally, let’s do some GeoDataFrame subsetting and concatenation to combine polygons corresponding to disaster event impact with the no impact polygons.\nFirst, let’s make the obs_event_no_impact GeoSeries a GeoDataFrame with an obj_desc column to match the observed disaster event impact GeoDataFrame.\n\nobs_event_no_impact_id = pd.DataFrame({\"obj_desc\": [\"no impact\" for x in range(0,35)]})\nobs_event_no_impact = gpd.GeoDataFrame(obs_event_no_impact_id, geometry=obs_event_no_impact, crs=\"EPSG:32760\")\nobs_event_no_impact.head()\n\n\n\n\n\n  \n    \n      \n      obj_desc\n      geometry\n    \n  \n  \n    \n      0\n      no impact\n      POLYGON ((755506.240 8181026.807, 755501.171 8...\n    \n    \n      1\n      no impact\n      POLYGON ((755051.258 8181594.507, 755049.445 8...\n    \n    \n      2\n      no impact\n      POLYGON ((753480.667 8181490.978, 753479.999 8...\n    \n    \n      3\n      no impact\n      POLYGON ((753367.195 8182994.416, 753376.130 8...\n    \n    \n      4\n      no impact\n      POLYGON ((753613.613 8182533.814, 753611.018 8...\n    \n  \n\n\n\n\nNext, let’s just get the obj_desc and the geometry columns from obs_event_gdf_32760 and concatenate the two GeoDataFrames (i.e. stack them on top of each other row wise).\n\n\nWhy are we subsetting out the the obj_desc and geometry columns?\n\nWe are subsetting these two columns to match the columns in the obs_event_no_impact GeoDataFrame. This allows us to stack the DataFrames on top of each other row wise with the columns matching up.\n\n\nobs_event_gdf_32760 = obs_event_gdf_32760.loc[:, [\"obj_desc\", \"geometry\"]]\nsample_polygons = pd.concat([obs_event_gdf_32760, obs_event_no_impact], axis=0)\nsample_polygons\n\n\n\n\n\n  \n    \n      \n      obj_desc\n      geometry\n    \n  \n  \n    \n      0\n      Coastal flood\n      POLYGON ((747882.541 8179203.830, 747878.308 8...\n    \n    \n      1\n      Coastal flood\n      POLYGON ((747626.133 8178789.386, 747623.751 8...\n    \n    \n      2\n      Coastal flood\n      POLYGON ((747674.948 8178759.223, 747669.789 8...\n    \n    \n      3\n      Coastal flood\n      POLYGON ((747688.839 8178707.629, 747685.664 8...\n    \n    \n      4\n      Coastal flood\n      POLYGON ((747745.195 8178697.311, 747738.845 8...\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      30\n      no impact\n      POLYGON ((748717.874 8180227.628, 748718.303 8...\n    \n    \n      31\n      no impact\n      POLYGON ((748293.456 8178644.194, 748294.692 8...\n    \n    \n      32\n      no impact\n      POLYGON ((748652.653 8180850.530, 748662.656 8...\n    \n    \n      33\n      no impact\n      POLYGON ((747636.336 8180918.198, 747628.161 8...\n    \n    \n      34\n      no impact\n      POLYGON ((747421.062 8179177.721, 747422.771 8...\n    \n  \n\n269 rows × 2 columns"
  },
  {
    "objectID": "lab-4-practice-exercises.html#zonal-stats",
    "href": "lab-4-practice-exercises.html#zonal-stats",
    "title": "Week 4 Practice Exercises",
    "section": "Zonal stats",
    "text": "Zonal stats\nWe now have 269 sample polygons of locations affected by Tropical Cyclone Yasa and those without visible impacts. We want to compute the average NDVI values across all pixels that intersect each polygon. This is a zonal statistics operation.\nWe can use the zonal_stats() function from the rasterstats package to perform zonal statistics in Python.\nThe zonal_stats() function takes in vector data of geometries that zonal statistics are computed for as its first argument (or a file path to a vector file), the path to a raster dataset (i.e. a GeoTIFF file) as its second argument, and optionally a list of statistics to compute to the stats argument. You can find the full list of parameters for the zonal_stats() function in the package documentation.\nCan you look up what the all_touched parameter of the zonal_stats() function is used to specify in the rasterstats docs?\nWe have a GeoTIFF file of NDVI values computed from a Sentinel-2 image captured just after Tropical Cyclone Yasa at the file path os.path.join(os.getcwd(), \"week-4-practice\", \"ndvi_post_yasa_int16.tif\").\nLet’s use it to compute the average NDVI value for each of the polygons in the GeoDataFrame sample_polygons. zonal_stats returns to us a dictionary object for each polygon with the summary statistic label as a key and the computed statistic as the value.\n\nndvi_zonal_stats = zonal_stats(sample_polygons, os.path.join(os.getcwd(), \"week-4-practice\", \"ndvi_post_yasa_int16.tif\"), stats=[\"mean\"], all_touched=True)\npprint.pprint(f\"print the mean NDVI for the first 10 polygons: {ndvi_zonal_stats[0:10]}\")\n\n(\"print the mean NDVI for the first 10 polygons: [{'mean': 306.2857142857143}, \"\n \"{'mean': 191.8181818181818}, {'mean': 168.0}, {'mean': 169.0222222222222}, \"\n \"{'mean': 135.5}, {'mean': 104.50632911392405}, {'mean': 50.66304347826087}, \"\n \"{'mean': 112.70967741935483}, {'mean': -174.8}, {'mean': \"\n '199.44444444444446}]')\n\n\nWe can convert the list of dictionary objects into a DataFrame using the DataFrame constructor function.\n\nzonal_stats_df = pd.DataFrame(ndvi_zonal_stats)\nzonal_stats_df.head()\n\n\n\n\n\n  \n    \n      \n      mean\n    \n  \n  \n    \n      0\n      306.285714\n    \n    \n      1\n      191.818182\n    \n    \n      2\n      168.000000\n    \n    \n      3\n      169.022222\n    \n    \n      4\n      135.500000\n    \n  \n\n\n\n\nThe NDVI data is in integer format and has been scaled by 1000 (it is cheaper to store integer data than floating point data). However, NDVI values should be between -1 and 1. Let’s fix this by dividing the NDVI values by 1000.\n\nzonal_stats_df[\"mean\"] = zonal_stats_df[\"mean\"] / 1000\nzonal_stats_df.head()\n\n\n\n\n\n  \n    \n      \n      mean\n    \n  \n  \n    \n      0\n      0.306286\n    \n    \n      1\n      0.191818\n    \n    \n      2\n      0.168000\n    \n    \n      3\n      0.169022\n    \n    \n      4\n      0.135500\n    \n  \n\n\n\n\nFinally, we can add the column of mean NDVI values for each polygon back to our GeoDataFrame. This means we can display our polygons and map the fill colour of each polygon to its mean NDVI value.\n\nsample_polygons[\"ndvi\"] = zonal_stats_df.loc[:, [\"mean\"]]\nsample_polygons.head()\n\n\n\n\n\n  \n    \n      \n      obj_desc\n      geometry\n      ndvi\n    \n  \n  \n    \n      0\n      Coastal flood\n      POLYGON ((747882.541 8179203.830, 747878.308 8...\n      0.306286\n    \n    \n      1\n      Coastal flood\n      POLYGON ((747626.133 8178789.386, 747623.751 8...\n      0.191818\n    \n    \n      2\n      Coastal flood\n      POLYGON ((747674.948 8178759.223, 747669.789 8...\n      0.168000\n    \n    \n      3\n      Coastal flood\n      POLYGON ((747688.839 8178707.629, 747685.664 8...\n      0.169022\n    \n    \n      4\n      Coastal flood\n      POLYGON ((747745.195 8178697.311, 747738.845 8...\n      0.135500\n    \n  \n\n\n\n\n\nsample_polygons.explore(column=\"ndvi\")\n\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\nCan you identify some limitations of this approach to generating a sample of areas not impacted by Tropical Cyclone Yasa?\n\n\n\nWe used the areas directly adjacent to observed impact as our no impact sample. If there is error in how the disaster impact was delineated, it is likely that a disaster impact signal might leak into zones we’ve labelled as not impacted. A better strategy might be to use sample locations a specified distance from an observed impact.\n\n\nThere could be differences in NDVI across land covers. If there are different land covers in the impacted area and not impacted area, we could be assigning a difference in NDVI due to land cover differences to disaster impact.\n\n\nWe could use difference NDVI images. Comparing the change in NDVI before and after disaster event in areas where a disaster impact was observed to areas where it was not.\n\n\n\n\n\n\n\nWhat data transformation and geoprocessing operations could you deploy if you just wanted to focus on the disaster impacts to croplands?\n\nYou could obtain a land cover map with a cropland class and mask all pixels that are not classified as cropland before computing zonal stats (i.e. set their values NaN)."
  },
  {
    "objectID": "lab-5.html",
    "href": "lab-5.html",
    "title": "Introduction",
    "section": "",
    "text": "This lab will provide an introduction to key machine learning concepts and also demonstrate how you can use Scikit-learn to implement machine learning workflows in Python.\nMachine learning is the process of learning from data to make predictions. Supervised machine learning models are trained to predict an outcome based on input data (predictors or features). The model is trained to minimise the error in predictions using a training set where both the outcome labels and input data are known. If the outcome is categorical (e.g. land cover type, cloud / no-cloud) then it is a classification machine learning task and if the outcome is numeric (e.g. crop yield, temperature) then it is a regression machine learning task.\nThere are also unsupervised machine learning tasks where there are no known outcomes prior to model training. Unsupervised machine learning models typically cluster datasets with similar data points assigned to the same cluster or group.\nPlease watch this introduction to machine learning video from Climate Change AI:"
  },
  {
    "objectID": "lab-5.html#setup",
    "href": "lab-5.html#setup",
    "title": "Introduction",
    "section": "Setup",
    "text": "Setup\n\nRun the labs\nYou can run the labs locally on your machine or you can use cloud environments provided by Google Colab. If you’re working with Google Colab be aware that your sessions are temporary and you’ll need to take care to save, backup, and download your work.\n  \n\n\nDownload data\nIf you need to download the date for this lab, run the following code snippet.\nimport os\n\nif \"week-5\" not in os.listdir(os.getcwd()):\n    os.system('wget \"https://github.com/data-analysis-3300-3003/data/raw/main/data/week-5.zip\"')\n    os.system('unzip \"week-5.zip\"')\n\n\nWorking in Colab\nIf you’re working in Google Colab, you’ll need to install the required packages that don’t come with the colab environment.\nif 'google.colab' in str(get_ipython()):\n    !pip install geopandas\n    !pip install pyarrow\n    !pip install mapclassify\n    !pip install rasterio\n\n\nImport modules\nimport pandas as pd\nimport geopandas as gpd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.io as pio\nimport rasterio\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.model_selection import GroupShuffleSplit\nfrom sklearn.inspection import permutation_importance\nfrom sklearn import tree\n\n# setup renderer\nif 'google.colab' in str(get_ipython()):\n    pio.renderers.default = \"colab\"\nelse:\n    pio.renderers.default = \"jupyterlab\"\n\nrng = np.random.RandomState(0)"
  },
  {
    "objectID": "lab-5.html#load-data",
    "href": "lab-5.html#load-data",
    "title": "Introduction",
    "section": "Load data",
    "text": "Load data\ndata_path = os.path.join(os.getcwd(), 'week-5', 'agrifieldnet_processed_adm4.geojson')\ngdf = gpd.read_file(data_path)"
  },
  {
    "objectID": "lab-5.html#data-pre-processing",
    "href": "lab-5.html#data-pre-processing",
    "title": "Introduction",
    "section": "Data pre-processing",
    "text": "Data pre-processing\nOften, after sourcing data, the first task in a machine learning workflow is data preprocessing - transforming the raw data into a format ready for model training or making predictions. These tasks are often referred to as feature engineering - the process of engineering or creating features or predictor variables.\nIn week 4, we implemented data preprocessing tasks to generate a dataset ready for machine learning. These included:\n\ncombining red and near infrared reflectance to compute the normalised difference vegetation index (NDVI)\nconverting image format data to tabular format data\ngrouping and summarising pixel-level data to a field-level dataset\n\nWe transformed the red and near infrared reflectance into NDVI values as the NDVI captures information about vegetation condition and it might help discriminate between different crop types.\nWe converted image format data to tabular format data as the machine learning algorithms that we’ll train in this lab expect tabular-like data as inputs.\nLet’s inspect the data. We can see it is a GeoDataFrame with columns corresponding to the field_id, labels (crop type identifier), spectral reflectance in several wavebands (B*) and ndvi, the village where the field is located in India, and geometry POINT object for the field centroid.\n\nprint(f\"The data is of type: {type(gdf)}\")\ngdf.head()\n\nThe data is of type: <class 'geopandas.geodataframe.GeoDataFrame'>\n\n\n\n\n\n\n  \n    \n      \n      field_id\n      labels\n      B01\n      B02\n      B03\n      B04\n      B05\n      B06\n      B07\n      B08\n      B8A\n      B09\n      B11\n      B12\n      ndvi\n      index_right\n      village\n      geometry\n    \n  \n  \n    \n      0\n      1\n      1\n      45.000000\n      42.444444\n      42.722222\n      48.000000\n      49.666667\n      58.000000\n      65.222222\n      60.277778\n      71.944444\n      12.000000\n      80.277778\n      61.333333\n      0.113383\n      6174\n      Utraula\n      POINT (82.31564 27.23659)\n    \n    \n      1\n      2\n      1\n      45.000000\n      42.000000\n      42.166667\n      47.666667\n      49.250000\n      59.916667\n      69.000000\n      63.916667\n      76.333333\n      12.833333\n      79.916667\n      56.750000\n      0.145935\n      6174\n      Utraula\n      POINT (82.31906 27.23882)\n    \n    \n      2\n      3\n      1\n      45.000000\n      42.687500\n      43.500000\n      49.187500\n      51.437500\n      62.875000\n      71.625000\n      66.625000\n      79.312500\n      13.000000\n      82.125000\n      58.062500\n      0.151548\n      6174\n      Utraula\n      POINT (82.32850 27.23514)\n    \n    \n      3\n      88\n      4\n      44.850000\n      42.725000\n      43.900000\n      50.300000\n      52.025000\n      61.750000\n      69.725000\n      65.000000\n      76.737500\n      12.300000\n      82.550000\n      58.787500\n      0.128102\n      6174\n      Utraula\n      POINT (82.40434 27.27498)\n    \n    \n      4\n      89\n      6\n      43.636364\n      38.872727\n      38.000000\n      38.781818\n      42.090909\n      56.345455\n      65.236364\n      61.800000\n      72.127273\n      12.000000\n      68.018182\n      45.981818\n      0.229402\n      6174\n      Utraula\n      POINT (82.40566 27.27154)\n    \n  \n\n\n\n\nBased on the dataset’s documentation the below is the mapping between numeric values and crop types in the labels dataset.\n\n1 - Wheat\n2 - Mustard\n3 - Lentil\n4 - No crop/Fallow\n5 - Green pea\n6 - Sugarcane\n8 - Garlic\n9 - Maize\n13 - Gram\n14 - Coriander\n15 - Potato\n16 - Bersem\n36 - Rice\n\nLet’s explore how many examples we have of different crop types. We can see that our dataset is dominated by wheat, mustard, and no crop / fallow labels.\n\n# make labels categorical for bar plot\nclass_mappings = {\n    \"1\": \"Wheat\",\n    \"2\": \"Mustard\",\n    \"3\": \"Lentil\",\n    \"4\": \"Fallow\",\n    \"5\": \"Green pea\",\n    \"6\": \"Sugarcane\",\n    \"8\": \"Garlic\",\n    \"9\": \"Maize\",\n    \"13\": \"Gram\",\n    \"14\": \"Coriander\",\n    \"15\": \"Potato\",\n    \"16\": \"Bersem\",\n    \"36\": \"Rice\"\n}\n\ngdf[\"labels_cat\"] = gdf[\"labels\"].astype(\"str\")\ngdf.replace({\"labels_cat\": class_mappings}, inplace=True)\n\ngdf.groupby(\"labels_cat\").count().loc[:, \"field_id\"]\n\nlabels_cat\nBersem         16\nCoriander      14\nFallow       1745\nGarlic         49\nGram           65\nGreen pea      31\nLentil        111\nMaize         307\nMustard      1060\nPotato         43\nRice          131\nSugarcane     174\nWheat        2200\nName: field_id, dtype: int64\n\n\nWe can also explore the spatial distribution of the data.\n\ngdf.explore(\"labels\", tiles=\"CartoDB dark_matter\", cmap=\"tab20\", categorical=True)\n\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\nThere are some final preprocessing steps required before we are ready to train a model to classify a field’s crop type.\nScikit-learn models expect the input data and outcomes to be array-like. Generally, this is in the form of NumPy ndarray objects.\nWe want the input data (features or predictors) to be in a separate object to the outcomes (labels). Therefore, we’ll subset the GeoDataFrame object and store just the predictor variables in an array-like object X and the outcomes in an object y.\nNumeric Pandas Series or DataFrame objects are array-like and so we can directly subset columns from the GeoDataFrame to create input and output objects.\nX generally has the shape (n_samples, n_features) where each sample is aligned along the rows dimension (or 0-axis in a rank 2 NumPy ndarray) and the features (or predictors) are aligned along the columns dimension (or 1-axis in a rank 2 NumPy ndarray).\nX = gdf.drop([\"field_id\", \"labels\", \"labels_cat\", \"index_right\", \"village\", \"geometry\"], axis=1)\ny = gdf.loc[:, \"labels\"]\n\nX.head()\n\n\n\n\n\n  \n    \n      \n      B01\n      B02\n      B03\n      B04\n      B05\n      B06\n      B07\n      B08\n      B8A\n      B09\n      B11\n      B12\n      ndvi\n    \n  \n  \n    \n      0\n      45.000000\n      42.444444\n      42.722222\n      48.000000\n      49.666667\n      58.000000\n      65.222222\n      60.277778\n      71.944444\n      12.000000\n      80.277778\n      61.333333\n      0.113383\n    \n    \n      1\n      45.000000\n      42.000000\n      42.166667\n      47.666667\n      49.250000\n      59.916667\n      69.000000\n      63.916667\n      76.333333\n      12.833333\n      79.916667\n      56.750000\n      0.145935\n    \n    \n      2\n      45.000000\n      42.687500\n      43.500000\n      49.187500\n      51.437500\n      62.875000\n      71.625000\n      66.625000\n      79.312500\n      13.000000\n      82.125000\n      58.062500\n      0.151548\n    \n    \n      3\n      44.850000\n      42.725000\n      43.900000\n      50.300000\n      52.025000\n      61.750000\n      69.725000\n      65.000000\n      76.737500\n      12.300000\n      82.550000\n      58.787500\n      0.128102\n    \n    \n      4\n      43.636364\n      38.872727\n      38.000000\n      38.781818\n      42.090909\n      56.345455\n      65.236364\n      61.800000\n      72.127273\n      12.000000\n      68.018182\n      45.981818\n      0.229402\n    \n  \n\n\n\n\nFor classification tasks the values in y should be integer and for regression tasks the values in y should be floating point. As crop type is a categorical variable values in y should be of integer data type.\n\ny.head()\n\n0    1\n1    1\n2    1\n3    4\n4    6\nName: labels, dtype: int64\n\n\n\nTrain-test splits\nFor supervised machine learning tasks we need to create training and test datasets.\nThe model is trained using the training set which consists of matched features and outcomes.\nThe model is then evaluated using the test set. A prediction is made using features in the test set and the prediction is compared with known outcomes for those features. This provides an indication of the model’s performance. It is important that the test set is independent from the training set - an important part of machine learning model development is preventing information from the test set leaking into the training set.\nScikit-learn provides a useful train_test_split() function which expects X and y array-like objects as inputs and will return 4 array-like objects (X_train, X_test, y_train, y_test).\nWe can provide further arguments to train_test_split():\n\ntest_size determines the proportion of the input data that is allocated to the test set\nrandom_state is a seed that ensures the same random split of the data occurs each time the code is executed. This is important for reproduciblity of results.\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=rng, test_size=0.3)\n\nprint(f\"the size of the training features object is {X_train.shape}\") \nprint(f\"the size of the test features object is {X_test.shape}\")\nprint(f\"the size of the training outcomes object is {y_train.shape}\")\nprint(f\"the size of the test features object is {y_test.shape}\")\n\nthe size of the training features object is (4162, 13)\nthe size of the test features object is (1784, 13)\nthe size of the training outcomes object is (4162,)\nthe size of the test features object is (1784,)"
  },
  {
    "objectID": "lab-5.html#model-training",
    "href": "lab-5.html#model-training",
    "title": "Introduction",
    "section": "Model training",
    "text": "Model training\nScikit-learn provides a range of machine learning algorithms that can be trained for different tasks (e.g. classification, regression, text, images, clustering etc.).\nIn Scikit-learn terminology each of these algorithms is called an estimator - the docs have a useful interactive guide to help you select the right estimator for your machine learning task.\nEach estimator object has a fit() method. The fit method expects the training data as arguments (X_train and y_train) and when called learns rules that minimise the error in predicting the outcome labels in y_train. This is the learning part of the machine learning workflow.\nHere, we will demonstrate how to train a tree-based machine learning model: a random forests classifier.\nFirst, we create an estimator object for the model. Then, we use the estimator’s fit() method to train the model.\n\nRandom forests classifiers\nRandom forests models are an ensemble and tree-based model. They’re a tree-based model as they consist of an ensemble of decision tree classifiers.\nPlease read through this Google Machine Learning Guide on decision trees and random forests.\n\n\nDetailed notes on tree-based models\n\nDecision tree classifiers are trained to learn rules that classify outcome labels based on input features by recursively splitting the feature space. The algorithm starts by finding the value of a feature that splits the dataset into two groups which minimise the “impurity” of outcome labels in each group. Then, that process is repeated by splitting each of the two groups, again to minimise the “impurity” of outcome labels. This process repeats until a stopping criterion is reached. The Gini index is the default metric to measure class impurity in each internal node of the tree.\nThe class label associated with each of the terminal nodes of the tree is based on the most commonly occurring class.\nIndividual decision tree classifiers are relatively quick to train, can learn non-linear and interactive relationships between input features and outcome labels, and are easy to visualise and interpret.\nHowever, there are limits to decision tree classifiers. They are often not the most accurate classifiers. They also have high variance; if you train a decision tree classifier on two different samples it will likely learn different relationships and generate different predictions. Large decision trees can also overfit the training data; they can learn to fully represent the structure of the training set but will not generalise well to new and unseen data.\nRandom forests models mitigate the limitations of a single decision tree classifier by:\nbagging: training a number (ensemble) of decision trees based on bootstrap samples of the training datasets. The average prediction from many decision tree models reduces the variance in predictions.\nsampling features at each split: when training each of the decision trees in the ensemble, a random selection of features are searched for each split within the tree. This prevents a small number of features from dominating the model, enables the model to learn using all the input features, and reduces overfitting. If there are p features, then often the m √p are considered at each split.\nmajority vote: for classification tasks, the final predicted value from a random forest model is the most common prediction of the outcome label across all trees in the ensemble.\n\n\n\nLet’s create a random forest model estimator object using the RandomForestClassifier() function. We’ll set the n_estimators parameter to 20 here; this means the random forest will consist of an ensemble of 20 decision tree classifiers. The random_state parameter ensures we learn the same model each time we train it on the same data; this is important for reproducible results.\n\n# create and train a random forests model\nrf = RandomForestClassifier(n_estimators=20, random_state=rng)\nrf.fit(X_train, y_train.astype(int))\n\nRandomForestClassifier(n_estimators=20,\n                       random_state=RandomState(MT19937) at 0x7F86571B5D40)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestClassifierRandomForestClassifier(n_estimators=20,\n                       random_state=RandomState(MT19937) at 0x7F86571B5D40)"
  },
  {
    "objectID": "lab-5.html#model-evaluation",
    "href": "lab-5.html#model-evaluation",
    "title": "Introduction",
    "section": "Model evaluation",
    "text": "Model evaluation\nAfter training a model, we need to evaluate it to assess its performance. This evaluation allows us to compare different models and get an indication of how well the model will perform when it is used on new data.\nIt is important that the test data used to evaluate a model is independent of the training data; this is to ensure an unbiased estimate of model performance.\nThere are a range of model evaluation metrics for classification tasks:\n\naccuracy: the proportion of correctly classified examples.\nrecall: the ratio of true positives to true positives and false negatives - the ability of the classifier to capture all positive cases. \\(recall = \\frac{tp}{tp+fn}\\).\nprecision: the ratio of true positives to true positives and false positives - the classifiers ability not to label something as positive when it is not. \\(precision = \\frac{tp}{tp+fp}\\).\nf1-score: the f1-score combines the recall and precision scores and takes on the range 0 to 1. \\(F1 = 2\\cdot\\frac{precision\\cdot{recall}}{precision+recall}\\)\n\nScitkit-learn provides a classification_report() which can be used to generate performance metrics for each class and the model as a whole.\nThe classification_report() expects known outcome labels and predicted outcome labels. To generate the predicted labels, we can use the predict() method of the estimator object and pass in input test data.\n\ny_pred = rf.predict(X_test)\n\nprint(classification_report(y_test, y_pred))\n\n              precision    recall  f1-score   support\n\n           1       0.66      0.81      0.73       658\n           2       0.47      0.43      0.45       310\n           3       0.50      0.09      0.15        34\n           4       0.81      0.80      0.80       535\n           5       0.60      0.30      0.40        10\n           6       0.50      0.34      0.40        53\n           8       0.00      0.00      0.00        12\n           9       0.79      0.76      0.77        98\n          13       0.62      0.23      0.33        22\n          14       0.00      0.00      0.00         2\n          15       0.67      0.25      0.36         8\n          16       0.00      0.00      0.00         4\n          36       0.44      0.11      0.17        38\n\n    accuracy                           0.68      1784\n   macro avg       0.47      0.32      0.35      1784\nweighted avg       0.66      0.68      0.66      1784\n\n\n\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n\n\nFrom the classification report, we can ascertain the following:\n\nthe model’s overall accuracy is 0.68 - 68% of the examples in the test set were classified correctly.\nthe model’s performance is better for class labels 1 (wheat), 4 (fallow), and 9 (maize).\nthe performance metric scores for the other classes is lower.\nthe model’s performance is best for classes with the most observations in the training dataset.\nwe’re getting a warning indicating to us that the precision and f1-score are being set to zero in labels with no predicted samples.\n\nWe can also plot a confusion matrix to see if there are patterns of confusion between classes.\n\nlabels = [\"Wheat\", \n          \"Mustard\", \n          \"Lentil\", \n          \"Fallow\", \n          \"Green Pea\",\n          \"Sugarcane\",\n          \"Garlic\",\n          \"Maize\",\n          \"Gram\",\n          \"Coriander\",\n          \"Potato\",\n          \"Bersem\",\n          \"Rice\"]\ncm = confusion_matrix(y_test, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\ndisp.plot(text_kw={\"fontsize\":10}, xticks_rotation=\"vertical\")\nplt.show()\n\n\n\n\nFrom the confusion matrix, we can see:\n\nthere is confusion between the mustard and wheat classes.\nthere is confusion between rice and fallow.\na large number of minitory classes as misclassified as wheat or mustard (majority classes).\nthere were no successful classifications of coriander, garlic, or bersem.\n\n\nRecap quiz\nEarlier, we discussed that random forests models should be more accurate than a single decision tree classifier. Can you train a decision tree classifier to test if this the case?\nThe documentation for the decision tree classifier is here.\nUse X_train, y_train, X_test, and y_test for this task\n## add code here ##\n\n\nanswer\n\n# import the tree module from scikit-learn\nfrom sklearn import tree\n\n# create a decision tree classifier object\nclf = tree.DecisionTreeClassifier(random_state=0)\n\n# train the model\nclf.fit(X_train, y_train)\n\n# test model\ny_pred_tree = clf.predict(X_test)\nprint(classification_report(y_test, y_pred_tree))"
  },
  {
    "objectID": "lab-5.html#class-imbalance",
    "href": "lab-5.html#class-imbalance",
    "title": "Introduction",
    "section": "Class imbalance",
    "text": "Class imbalance\nOur training and test datasets are clearly imbalanced across the outcome class labels. The majoring of samples are of wheat (1), mustard (2), or fallow (4) classes.\nWe can see the imbalance in our dataset using a bar plot.\n\npx.histogram(gdf, x=\"labels_cat\")\n\n\n\n\n\nprint(\"the number of samples by class in our overall dataset (pre-split) are:\")\ngdf.groupby('labels_cat').count().loc[:, \"field_id\"]\n\nthe number of samples by class in our overall dataset (pre-split) are:\n\n\nlabels_cat\nBersem         16\nCoriander      14\nFallow       1745\nGarlic         49\nGram           65\nGreen pea      31\nLentil        111\nMaize         307\nMustard      1060\nPotato         43\nRice          131\nSugarcane     174\nWheat        2200\nName: field_id, dtype: int64\n\n\n\nRecap quiz\n\n\nHow could imbalanced data affect model performance?\n\n\n\nThe model will not see enough examples of minority classes to learn rules to discriminate them from the input data\n\n\nThe model will learn it can achieve good overall accuracy by just predicting majority classes\n\n\n\n\n\n\n\nWhat could we do to fix the class imbalance problem?\n\n\n\nUndersample the majority classes\n\n\nOversample the minority classes\n\n\nGet more data\n\n\nPool the minority classes to reduce the total number of classes"
  },
  {
    "objectID": "lab-5.html#data-leakage",
    "href": "lab-5.html#data-leakage",
    "title": "Introduction",
    "section": "Data leakage",
    "text": "Data leakage\nData leakage occurs when information in the test set leaks into the training dataset. This means the test set is not truly independent and does not provide an unbiased assessment of the model’s performance on new data.\nSpatial correlation occurs when observations close to each other are more similar or disimilar than observations further away. This is encapsulated by Tobler’s first law of Geography: “Everything is related to everything else. But near things are more related than distant things.”\nGeospatial data is often spatially correlated. This means that data points close to each other are not statistically independent. A random training and test split of spatially correlated data can result in the test dataset not being independent of the training dataset. This is because some of the data in the test set is correlated with data in the training set. Spatial correlation is causing data leakage and the evaluation of model performance using this test set will be biased.\n\nRecap quiz\n\n\nHow could you generate training and test splits which are not spatially correlated?\n\nFirst, you could explore the spatial correlation in your dataset using techniques such as Moran’s I and Local Moran’s I statistics.\nIf you believe that your samples are not likely to be correlated across administrative boundaries such as villages, counties, states etc. you could randomly split your data at the administrative boundary-level as opposed to the sample-level. That is, instead of taking a random hold-out sample of data points for the test set you would take a random sample of administrative units as the test set and all data points inside those units would be your test set.\nAn alternative strategy if there are no useful administrative boundaries could be to spatially cluster your samples using their coordinates so proximal data points are allocated to the same cluster and randomly hold-out some clusters as the test set.\n\n\n\nLet’s use the village column in our dataset gdf as a group to guide generation of train and test sets. We’ll ensure that no samples from the same village are in both the training and test sets.\n\n\nWhat is our assumption when using villages as the grouping variable?\n\nWe are assuming that data points in neighbouring villages are not spatially correlated, and, therefore, there is no data leakage from the the test set to the training set. Is this a safe assumption? Do you think villages next to each other will have different agricultural contexts?\n\nX_sp = gdf.drop([\"field_id\", \"labels\", \"labels_cat\", \"index_right\", \"village\", \"geometry\"], axis=1)\ny_sp = gdf.loc[:, \"labels\"]\ngroups = gdf.loc[:, \"village\"]\nscikit-learn has a GroupShuffleSplit object that has a split() method that can be used to generate splits of the dataset.\nFirst, we need to create an instance of the GroupShuffleSplit object specifying the number of different splits of the dataset that we want to create using the n_splits argument. We also use the train_size argument to define how much of the data should be allocated to the training and test sets.\nHere, we only want to create one split of our dataset at the village level so we set n_splits=1.\nThen, we call the split() method of gss, our GroupShuffleSplit object, passing in the features (X_sp), outcome labels (y_sp), and the groups (groups). This returns to us a train_index and test_index specifying the index locations of samples allocated to the training and test set. Passing in groups ensures that no samples from the same group (village) are in both the training and test sets.\nWe then use the index locations in train_index and test_index to subset X_sp and y_sp for model training and testing.\n\ngss = GroupShuffleSplit(n_splits=1, train_size=.8, random_state=0)\n\nfor i, (train_index, test_index) in enumerate(gss.split(X_sp, y_sp, groups)):\n    print(f\"processing split {i}\")\n    X_train_sp = X_sp.iloc[train_index, :]\n    X_test_sp = X_sp.iloc[test_index, :]\n    y_train_sp = y_sp.iloc[train_index]\n    y_test_sp = y_sp.iloc[test_index]\n    print(f\"the size of the training features object is {X_train.shape}\") \n    print(f\"the size of the test features object is {X_test.shape}\")\n    print(f\"the size of the training outcomes object is {y_train.shape}\")\n    print(f\"the size of the test features object is {y_test.shape}\")\n\nprocessing split 0\nthe size of the training features object is (4162, 13)\nthe size of the test features object is (1784, 13)\nthe size of the training outcomes object is (4162,)\nthe size of the test features object is (1784,)\n\n\nNow we’re ready to train and test our model.\n\n\nRecap quiz\n\n\nRelative to our model which did not account for spatial correlation when splitting training and test data, do you think this model’s performance will improve?\n\nWe could assume that this model’s performance will be worse than the naive with spatial correlation between training and test sets as we have tried to block leakage of information from test set into the training set.\n\n\n\nLet’s train the model and test its performance.\n\n# create and train a random forests model\nrf_sp = RandomForestClassifier(n_estimators=20, random_state=rng)\nrf_sp.fit(X_train_sp, y_train_sp.astype(int))\n\nRandomForestClassifier(n_estimators=20,\n                       random_state=RandomState(MT19937) at 0x7F86571B5D40)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestClassifierRandomForestClassifier(n_estimators=20,\n                       random_state=RandomState(MT19937) at 0x7F86571B5D40)\n\n\n\ny_pred_sp = rf.predict(X_test_sp)\n\nprint(classification_report(y_test_sp, y_pred_sp))\n\n              precision    recall  f1-score   support\n\n           1       0.89      0.95      0.92       673\n           2       0.83      0.85      0.84       261\n           3       0.90      0.59      0.72        32\n           4       0.94      0.91      0.92       518\n           5       1.00      0.70      0.82        10\n           6       0.88      0.77      0.82        39\n           8       1.00      1.00      1.00         4\n           9       0.91      0.93      0.92       111\n          13       0.81      0.62      0.70        21\n          14       1.00      1.00      1.00         1\n          15       0.80      0.80      0.80         5\n          16       1.00      0.75      0.86         8\n          36       1.00      0.67      0.81        46\n\n    accuracy                           0.90      1729\n   macro avg       0.92      0.81      0.86      1729\nweighted avg       0.90      0.90      0.89      1729"
  },
  {
    "objectID": "lab-5-self-guided.html",
    "href": "lab-5-self-guided.html",
    "title": "Introduction",
    "section": "",
    "text": "Machine learning is the process of learning from data to make predictions. Supervised machine learning models are trained to predict an outcome based on input data (predictors or features). The model is trained to minimise the error in predictions using a training set where both the outcome labels and input data are known.\nA key part of the machine learning model development workflow is evaluating model performance. This should provide an assessment of how well a model will perform in making predictions on new or unseen data. Machine learning models are data hungry, the more examples the model sees during training the better it will be able to learn mappings that relate input features to outcome labels. However, we also want to test our model on a dataset that is representative of conditions the model might encounter “in-the-wild”; this results in setting aside a chunk of our ground truth dataset that cannot be used for model training. Thus, our model is not trained using all available ground truth data.\nOne strategy that is deployed to maximise data available for model training and to provide an assessment of model performance is cross-validation.\nPreviously, we demonstrated a workflow to develop a machine learning model for a classification task: predicting a field’s crop type. In this lab we will develop a machine learning model for a regression task (predicting a continuous number) and evaluate the model using k-fold cross-validation."
  },
  {
    "objectID": "lab-5-self-guided.html#cross-validation",
    "href": "lab-5-self-guided.html#cross-validation",
    "title": "Introduction",
    "section": "Cross-validation",
    "text": "Cross-validation\nBefore we explore our ground truth dataset for model development, let’s quickly introduce cross-validation. Previously, we evaluated the model’s performance by removing a random sample of the data prior to model training to use as a test set.\n\nRecap quiz\n\n\nWhy is it important for the test dataset to be randomly sampled from the ground truth data?\n\nWe want the test dataset to be representative and unbiased to provide as realistic assessment of the model’s performance on new data as possible.\n\n\n\n\n\nWhat is a potential limitation of using a single hold-out randomly sampled test set for evaluating model performance?\n\nWith a randomly sampled test set, each time the machine learning model development workflow is repeated new training and test sets would be generated and the model will have different performance scores. Using a single test set means, that by chance, the model could have an overly optimistic or pessimistic assessment of its performance.\nFurther, by withholding a test set we reduce the amount of data available to train the model. A smaller training dataset can reduce the model’s performance. Thus, as we’re removing data to form the test set we’d expect the model’s error to be larger than if we’d trained the model on the entire dataset.\n\n\n\nIn k-fold cross-validation there is not a single test set. Instead, the ground truth dataset is randomly split into \\(k\\) folds. For example, if \\(k=5\\) the ground truth dataset would be randomly split into 5 groups. Then, in turn, each fold is held out as a test set and the model is trained using data from the remaining four folds. Each fold takes a turn at being the test set. The model performance can be summarised using the average of the performance metrics generated using each fold. This means the model’s performance is less susceptible to being influenced by a chance split of the ground truth data into training and test splits. It also means we can use the whole dataset to train the model and evaluate its performance.\n\n\nMAPS 2016 Data\nThe dataset we’re using is the data from Lobell et al. (2019). Their analysis compared different approaches to estimating smallholder maize crop yields in Uganda: farmer reported yields, subplot crop cut samples, full plot crop cut samples, and satellite-based crop yield esimates.\nBoosting agricultural productivity in smallholder landscapes is important for improving a range of livelihood outcomes including food security and poverty alleviation. Accurate data on smallholder farmer crop production is a key ingredient to guiding development initiatives, government policies / programs, agricultural management and input use, and monitoring progress towards several Sustainable Development Goals.\nTraditionally, agricultural productivity in smallholder landscapes has been measured using farmer reported crop yields via surveys after harvests. These estimates are subject to considerable error impacting the quality of the data.\nMore accurate measures of crop yield include physically harvesting a sub plot or full plot - crop cutting. However, crop cutting is more costly, time consuming, and requires liaising with farmers to generate large datasets of yield measurements.\nLobell et al. (2019) explore the potential for using satellite data to measure crop yields in smallholder fields to address i) the issue of error in farmer reported yields, and ii) the cost of crop cutting.\nWe’re going to use the replication data from their paper and see if we can develop a machine learning model to accurately predict smallholder maize crop yield using satellite data as inputs. As this dataset only has a few hundred data points, we’ll use all the data to train the model and test its performance using cross-validation."
  },
  {
    "objectID": "lab-5-self-guided.html#setup",
    "href": "lab-5-self-guided.html#setup",
    "title": "Introduction",
    "section": "Setup",
    "text": "Setup\n\nRun the labs\nYou can run the labs locally on your machine or you can use cloud environments provided by Google Colab. If you’re working with Google Colab be aware that your sessions are temporary and you’ll need to take care to save, backup, and download your work.\n  \n\n\nDownload data\nIf you need to download the date for this lab, run the following code snippet.\nimport os\n\nif \"week-5\" not in os.listdir(os.getcwd()):\n    os.system('wget \"https://github.com/data-analysis-3300-3003/data/raw/main/data/week-5.zip\"')\n    os.system('unzip \"week-5.zip\"')\n\n\nWorking in Colab\nIf you’re working in Google Colab, you’ll need to install the required packages that don’t come with the colab environment.\nif 'google.colab' in str(get_ipython()):\n    !pip install geopandas\n    !pip install pyarrow\n    !pip install mapclassify\n    !pip install rasterio\n\n\nImport modules\nimport pandas as pd\nimport geopandas as gpd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.io as pio\nimport rasterio\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.model_selection import GroupShuffleSplit\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.inspection import permutation_importance\nfrom sklearn import tree\n\n# setup renderer\nif 'google.colab' in str(get_ipython()):\n    pio.renderers.default = \"colab\"\nelse:\n    pio.renderers.default = \"jupyterlab\"\n\nrng = np.random.RandomState(0)"
  },
  {
    "objectID": "lab-5-self-guided.html#load-data",
    "href": "lab-5-self-guided.html#load-data",
    "title": "Introduction",
    "section": "Load data",
    "text": "Load data\n\ndf = pd.read_csv(os.path.join(os.getcwd(), \"week-5\", \"lobell_2019_maize.csv\"))\nprint(f\"the shape of the DataFrame is {df.shape}\")\ndf.head()\n\nthe shape of the DataFrame is (463, 16)\n\n\n\n\n\n\n  \n    \n      \n      cc_yield\n      gcvi_doy_151\n      gcvi_doy_171\n      ndvi_doy_151\n      ndvi_doy_171\n      mtci_doy_151\n      mtci_doy_171\n      slope_sr\n      soiltype_sr\n      soilqual_sr\n      intercrop_legume\n      intercrop_cassava\n      crop_rotation\n      plot_area_GPS\n      tot_maize_area_ha\n      purestand\n    \n  \n  \n    \n      0\n      0.074381\n      1601.090909\n      1957.909091\n      470.818182\n      592.000000\n      4990.727273\n      5163.636364\n      FLAT\n      LOAM\n      GOOD\n      1.0\n      1.0\n      1\n      0.098254\n      0.052609\n      0\n    \n    \n      1\n      0.188531\n      1670.774194\n      1889.129032\n      500.387097\n      602.838710\n      4665.322581\n      4317.838710\n      MODERATE SLOPE\n      LOAM\n      POOR\n      0.0\n      1.0\n      0\n      0.312110\n      0.416826\n      0\n    \n    \n      2\n      1.848827\n      2394.454545\n      2321.090909\n      644.000000\n      665.545455\n      6014.818182\n      5643.272727\n      FLAT\n      LOAM\n      GOOD\n      NaN\n      NaN\n      0\n      0.114050\n      0.133546\n      1\n    \n    \n      3\n      2.175352\n      2130.333333\n      2082.666667\n      620.000000\n      651.000000\n      4708.000000\n      4502.000000\n      SLIGHT SLOPE\n      OTHER (SPECIFY)\n      GOOD\n      NaN\n      NaN\n      0\n      0.133263\n      0.101171\n      1\n    \n    \n      4\n      0.090876\n      2661.375000\n      1993.437500\n      662.093750\n      618.437500\n      5494.000000\n      4010.187500\n      FLAT\n      LOAM\n      GOOD\n      1.0\n      0.0\n      0\n      0.326660\n      0.404686\n      0"
  },
  {
    "objectID": "lab-5-self-guided.html#explore-data",
    "href": "lab-5-self-guided.html#explore-data",
    "title": "Introduction",
    "section": "Explore data",
    "text": "Explore data\nThere data that we have read into df includes a range of variables related to crop yield outcomes, farm management and farm type, and satellite-derived vegetation indices from the Sentinel-2 sensor.\nWe’ll be using the crop cut maize yield measures from sample sub plots in the fields as our outcome variable here - this is referenced by the column cc_yield. The units are Mg/ha.\nLet’s look at the distribution of yield values.\n\nfig = px.histogram(\n    data_frame=df, \n    x=\"cc_yield\",  \n    marginal=\"box\"\n)\nfig.show()\n\n\n\n\nThe DataFrame stores Sentinel-2 derived vegetation indices in the following columns:\n\ngcvi_doy_151 - average field GCVI on day of year 151.\ngcvi_doy_171 - average field GCVI on day of year 171.\nndvi_doy_151 - average field NDVI on day of year 151.\nndvi_doy_171 - average field NDVI on day of year 171.\nmtci_doy_151 - average field MTCI on day of year 151.\nmtci_doy_171 - average field MTCI on day of year 171.\n\nNDVI is the normalised difference vegetation index. GCVI is the green chlorophyll index. MTCI is the meris terrestrial chlorophyll index. These will be the main features (predictors) in our model.\n\nRecap quiz\nCan you generate scatter plots to explore the correlation between vegetation index values and maize crop yield?\n## ADD CODE HERE ##\n\n\nanswer\n\nfig = px.scatter(\n    df,\n    x = \"gcvi_doy_151\", ## CHANGE THIS FOR DIFFERENT VEGETATION INDICES\n    y = \"cc_yield\",\n    trendline = \"ols\",\n    opacity=0.25,\n    labels={\"cc_yield\": \"Maize crop yield (Mg/ha)\",\n           \"gcvi_doy_151\": \"GCVI (DOY 151)\"} ## CHANGE THIS FOR DIFFERENT VEGETATION INDICES\n)\nfig.show()"
  },
  {
    "objectID": "lab-5-self-guided.html#cross-validation-1",
    "href": "lab-5-self-guided.html#cross-validation-1",
    "title": "Introduction",
    "section": "Cross-validation",
    "text": "Cross-validation\nWe’ll start by training a linear regression model that predicts maize crop yield as a function of vegetation indices and evaluate its performance using cross validation.\nMaize crop yield is a continuous variable and we need a metric to evaluate model performance. We’ll use the mean_absolute_error as the metric which is the mean absolute difference between predicted and observed crop yields. In this case, the mean absolute error will be computed using observations in the held out fold in cross-validation.\nWe’ll need to create a linear regression estimator object that we can train (using its fit() method). To evaluate the model using cross validation you call the cross_val_score() function on the dataset and the estimator. You pass in the metric you wish to use to evaluate the model to the scoring argument.\nWe’ll also need to use the dropna() method of pandas DataFrames to remove missing data before training the model. Scikit-learn models cannot be trained on datasets with NaN values.\n# get X and y data\n\n# drop nas as Linear Regression object cannot be trained on datasets with missing data\ndf_linear_reg = df.loc[: , [\n    \"cc_yield\",\n    \"gcvi_doy_151\", \n    \"gcvi_doy_171\", \n    \"ndvi_doy_151\", \n    \"ndvi_doy_171\", \n    \"mtci_doy_151\", \n    \"mtci_doy_171\"]].dropna()\n\n# get X\nX = df_linear_reg.loc[:, [\n    \"gcvi_doy_151\", \n    \"gcvi_doy_171\", \n    \"ndvi_doy_151\", \n    \"ndvi_doy_171\", \n    \"mtci_doy_151\", \n    \"mtci_doy_171\"]]\n\n# get Y\ny = df_linear_reg.loc[:, \"cc_yield\"]\n# create a LinearRegression estimator object\nreg = LinearRegression()\n\n# evaluate using 5-fold cross validation\ncv_scores = cross_val_score(reg, X, y, cv=5, scoring=\"neg_mean_absolute_error\")\ncv_scores should reference an array of values recording the mean absolute error for the predictions of maize crop yield for each fold. Scikit-learn returns negative mean absolute error values (becauase their convention is that a higher metric values are better than lower metric values which holds for metrics for categorical outcomes such as accuracy). Therefore, we’ll want to convert negative mean absolute error values to positive.\n\n# print cross validation test scores\nfor i, mae in enumerate(cv_scores):\n    print(f\"the mae for the {i}th fold is {round(abs(mae), 4)}\")\n\nthe mae for the 0th fold is 0.3982\nthe mae for the 1th fold is 0.4287\nthe mae for the 2th fold is 0.3966\nthe mae for the 3th fold is 0.4201\nthe mae for the 4th fold is 0.3331\n\n\nIf we want to use more than one metric to evaluate the model, we can pass in a list of metrics to the scoring argument. Let’s also estimate the mean squared error value as well as the mean absolute error. The mean squared error penalises the model more for predictions with larger error.\nTo use multiple metrics we need to use the cross_validate() function instead.\n\n# evaluate using 5-fold cross validation\ncv_scores = cross_validate(reg, X, y, cv=5, scoring=[\"neg_mean_absolute_error\", \"neg_mean_squared_error\"])\ncv_scores\n\n{'fit_time': array([0.00634956, 0.00422311, 0.00304842, 0.00510287, 0.00359941]),\n 'score_time': array([0.00296617, 0.00219154, 0.00176239, 0.00259161, 0.00240493]),\n 'test_neg_mean_absolute_error': array([-0.3982209 , -0.42870653, -0.39656073, -0.42009901, -0.33312728]),\n 'test_neg_mean_squared_error': array([-0.2645759 , -0.25151843, -0.24289755, -0.25937046, -0.18017087])}\n\n\n\nRecap quiz\nCan you estimate the mean mean absolute error and mean mean squared error across the five test folds using the cv_scores dictionary object?\n## ADD CODE HERE ##\n\n\nanswer\n\nprint(f\"mean mae: {abs(cv_scores['test_neg_mean_absolute_error'].mean())}\")\nprint(f\"mean mse: {cv_scores['test_neg_mean_squared_error'].mean()}\")\n\n\n\nCan you train and evaluate a random forests model using 5-fold cross-validation to see if it improves the predictive performance?\n## ADD CODE HERE ##\n\n\nanswer\n\nrf = RandomForestRegressor(n_estimators=20, random_state=rng)\nrf_cv_scores = cross_validate(rf, X, y, cv=5, scoring=[\"neg_mean_absolute_error\"])\nrf_cv_scores"
  },
  {
    "objectID": "lab-5-self-guided.html#categorical-features",
    "href": "lab-5-self-guided.html#categorical-features",
    "title": "Introduction",
    "section": "Categorical features",
    "text": "Categorical features\nIn our DataFrame there are some categorical variables that could help improve our predictions of crop yield. These include the slope, soil type, and soil quality variables. These variables are str type. We can only pass numeric data into our models; therefore, we’ll need to recode the text data to a numeric representation.\nOne approach for recoding categorical data is one hot encoding. Each unique value in a one hot encoded categorical variable is assigned a new column in the DataFrame. For rows when this value is present a value of one is assigned and zero otherwise.\nLet’s one hot encode the slope variable slope_sr to illustrate this concept.\nThe pandas get_dummies() function can be used to one hot encode a column in a DataFrame. The get_dummies() function has a columns argument that takes a list of column names that will be one hot encoded.\nFirst, let’s visualise our DataFrame df and inspect the values in the slope_sr column. You should see the values “FLAT”, “MODERATE SLOPE”, “SLIGHT SLOPE”, “STEEP SLOPE” as str data.\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      cc_yield\n      gcvi_doy_151\n      gcvi_doy_171\n      ndvi_doy_151\n      ndvi_doy_171\n      mtci_doy_151\n      mtci_doy_171\n      slope_sr\n      soiltype_sr\n      soilqual_sr\n      intercrop_legume\n      intercrop_cassava\n      crop_rotation\n      plot_area_GPS\n      tot_maize_area_ha\n      purestand\n    \n  \n  \n    \n      0\n      0.074381\n      1601.090909\n      1957.909091\n      470.818182\n      592.000000\n      4990.727273\n      5163.636364\n      FLAT\n      LOAM\n      GOOD\n      1.0\n      1.0\n      1\n      0.098254\n      0.052609\n      0\n    \n    \n      1\n      0.188531\n      1670.774194\n      1889.129032\n      500.387097\n      602.838710\n      4665.322581\n      4317.838710\n      MODERATE SLOPE\n      LOAM\n      POOR\n      0.0\n      1.0\n      0\n      0.312110\n      0.416826\n      0\n    \n    \n      2\n      1.848827\n      2394.454545\n      2321.090909\n      644.000000\n      665.545455\n      6014.818182\n      5643.272727\n      FLAT\n      LOAM\n      GOOD\n      NaN\n      NaN\n      0\n      0.114050\n      0.133546\n      1\n    \n    \n      3\n      2.175352\n      2130.333333\n      2082.666667\n      620.000000\n      651.000000\n      4708.000000\n      4502.000000\n      SLIGHT SLOPE\n      OTHER (SPECIFY)\n      GOOD\n      NaN\n      NaN\n      0\n      0.133263\n      0.101171\n      1\n    \n    \n      4\n      0.090876\n      2661.375000\n      1993.437500\n      662.093750\n      618.437500\n      5494.000000\n      4010.187500\n      FLAT\n      LOAM\n      GOOD\n      1.0\n      0.0\n      0\n      0.326660\n      0.404686\n      0\n    \n  \n\n\n\n\nNow, let’s one hot encode the slope_sr variable and see how it is represented as numeric data. (scroll to the far right of the displayed DataFrame).\ndf_cat = pd.get_dummies(df, columns=[\"slope_sr\"])\n\ndf_cat.head()\n\n\n\n\n\n  \n    \n      \n      cc_yield\n      gcvi_doy_151\n      gcvi_doy_171\n      ndvi_doy_151\n      ndvi_doy_171\n      mtci_doy_151\n      mtci_doy_171\n      soiltype_sr\n      soilqual_sr\n      intercrop_legume\n      intercrop_cassava\n      crop_rotation\n      plot_area_GPS\n      tot_maize_area_ha\n      purestand\n      slope_sr_FLAT\n      slope_sr_MODERATE SLOPE\n      slope_sr_SLIGHT SLOPE\n      slope_sr_STEEP SLOPE\n    \n  \n  \n    \n      0\n      0.074381\n      1601.090909\n      1957.909091\n      470.818182\n      592.000000\n      4990.727273\n      5163.636364\n      LOAM\n      GOOD\n      1.0\n      1.0\n      1\n      0.098254\n      0.052609\n      0\n      1\n      0\n      0\n      0\n    \n    \n      1\n      0.188531\n      1670.774194\n      1889.129032\n      500.387097\n      602.838710\n      4665.322581\n      4317.838710\n      LOAM\n      POOR\n      0.0\n      1.0\n      0\n      0.312110\n      0.416826\n      0\n      0\n      1\n      0\n      0\n    \n    \n      2\n      1.848827\n      2394.454545\n      2321.090909\n      644.000000\n      665.545455\n      6014.818182\n      5643.272727\n      LOAM\n      GOOD\n      NaN\n      NaN\n      0\n      0.114050\n      0.133546\n      1\n      1\n      0\n      0\n      0\n    \n    \n      3\n      2.175352\n      2130.333333\n      2082.666667\n      620.000000\n      651.000000\n      4708.000000\n      4502.000000\n      OTHER (SPECIFY)\n      GOOD\n      NaN\n      NaN\n      0\n      0.133263\n      0.101171\n      1\n      0\n      0\n      1\n      0\n    \n    \n      4\n      0.090876\n      2661.375000\n      1993.437500\n      662.093750\n      618.437500\n      5494.000000\n      4010.187500\n      LOAM\n      GOOD\n      1.0\n      0.0\n      0\n      0.326660\n      0.404686\n      0\n      1\n      0\n      0\n      0\n    \n  \n\n\n\n\n\ndf_cat.columns\n\nIndex(['cc_yield', 'gcvi_doy_151', 'gcvi_doy_171', 'ndvi_doy_151',\n       'ndvi_doy_171', 'mtci_doy_151', 'mtci_doy_171', 'soiltype_sr',\n       'soilqual_sr', 'intercrop_legume', 'intercrop_cassava', 'crop_rotation',\n       'plot_area_GPS', 'tot_maize_area_ha', 'purestand', 'slope_sr_FLAT',\n       'slope_sr_MODERATE SLOPE', 'slope_sr_SLIGHT SLOPE',\n       'slope_sr_STEEP SLOPE'],\n      dtype='object')\n\n\nNow, let’s retrain our linear regression model using slope as a feature.\n\n# get X and y data\n\n## NOTE WE ARE USING df_cat here!!\n# drop nas as Linear Regression object cannot be trained on datasets with missing data\ndf_linear_reg = df_cat.loc[: , [\n    \"cc_yield\",\n    \"gcvi_doy_151\", \n    \"gcvi_doy_171\", \n    \"ndvi_doy_151\", \n    \"ndvi_doy_171\", \n    \"mtci_doy_151\", \n    \"mtci_doy_171\",\n    \"slope_sr_FLAT\",\n    \"slope_sr_MODERATE SLOPE\",\n    \"slope_sr_SLIGHT SLOPE\",\n    \"slope_sr_STEEP SLOPE\"]].dropna()\n\n# get X\nX = df_linear_reg.loc[:, [\n    \"gcvi_doy_151\", \n    \"gcvi_doy_171\", \n    \"ndvi_doy_151\", \n    \"ndvi_doy_171\", \n    \"mtci_doy_151\", \n    \"mtci_doy_171\",\n    \"slope_sr_FLAT\",\n    \"slope_sr_MODERATE SLOPE\",\n    \"slope_sr_SLIGHT SLOPE\",\n    \"slope_sr_STEEP SLOPE\"]]\n\n# get Y\ny = df_linear_reg.loc[:, \"cc_yield\"]\n\n# create a LinearRegression estimator object\nreg = LinearRegression()\n\n# evaluate using 5-fold cross validation\ncv_scores = cross_validate(reg, X, y, cv=5, scoring=[\"neg_mean_absolute_error\", \"neg_mean_squared_error\"])\ncv_scores\n\n{'fit_time': array([0.00371838, 0.00338173, 0.0025816 , 0.00310421, 0.00281858]),\n 'score_time': array([0.0019598 , 0.00219989, 0.0025456 , 0.00225759, 0.00184798]),\n 'test_neg_mean_absolute_error': array([-0.39742585, -0.42726256, -0.40607374, -0.44134232, -0.34829396]),\n 'test_neg_mean_squared_error': array([-0.2604608 , -0.25148747, -0.24486727, -0.27746001, -0.18578002])}\n\n\n\nRecap quiz\nCan you also recode the soil type soiltype_sr and soilqual_sr variables from categorical to numeric using one hot encoding? Reference the result with the variable df_2.\n## ADD CODE HERE ##\n\n\nanswer\n\ndf_2 = pd.get_dummies(df, columns=[\"slope_sr\", \"soiltype_sr\", \"soilqual_sr\"])\ndf_2.head()\n\nCan you use df_2 with soiltype_sr, slope_sr, and soilqual_sr as training data in a random forests model?\n## ADD CODE HERE ##\n\n\nanswer\n\n# get X and y data\n\n# NOTE WE USE df_2 here!!\n# drop nas as Linear Regression object cannot be trained on datasets with missing data\ndf_linear_reg = df_2.loc[: , [\n    \"cc_yield\",\n    \"gcvi_doy_151\", \n    \"gcvi_doy_171\", \n    \"ndvi_doy_151\", \n    \"ndvi_doy_171\", \n    \"mtci_doy_151\", \n    \"mtci_doy_171\",\n    \"slope_sr_FLAT\",\n    \"slope_sr_MODERATE SLOPE\", \n    \"slope_sr_SLIGHT SLOPE\",\n    \"slope_sr_STEEP SLOPE\", \n    \"soiltype_sr_CLAY\", \n    \"soiltype_sr_LOAM\",\n    \"soiltype_sr_OTHER (SPECIFY)\", \n    \"soiltype_sr_SANDY\", \n    \"soilqual_sr_FAIR\",\n    \"soilqual_sr_GOOD\", \n    \"soilqual_sr_POOR\"]].dropna()\n\n# get X\nX = df_linear_reg.loc[:, [\n    \"gcvi_doy_151\", \n    \"gcvi_doy_171\", \n    \"ndvi_doy_151\", \n    \"ndvi_doy_171\", \n    \"mtci_doy_151\", \n    \"mtci_doy_171\",\n    \"slope_sr_FLAT\",\n    \"slope_sr_MODERATE SLOPE\", \n    \"slope_sr_SLIGHT SLOPE\",\n    \"slope_sr_STEEP SLOPE\", \n    \"soiltype_sr_CLAY\", \n    \"soiltype_sr_LOAM\",\n    \"soiltype_sr_OTHER (SPECIFY)\", \n    \"soiltype_sr_SANDY\", \n    \"soilqual_sr_FAIR\",\n    \"soilqual_sr_GOOD\", \n    \"soilqual_sr_POOR\"]]\n\n# get Y\ny = df_linear_reg.loc[:, \"cc_yield\"]\n\nrf = RandomForestRegressor(n_estimators=20, random_state=rng)\nrf_cv_scores = cross_validate(rf, X, y, cv=5, scoring=[\"neg_mean_absolute_error\"])\nrf_cv_scores"
  },
  {
    "objectID": "lab-5-self-guided.html#controlling-randomness",
    "href": "lab-5-self-guided.html#controlling-randomness",
    "title": "Introduction",
    "section": "Controlling randomness",
    "text": "Controlling randomness\nSome elements of the machine learning workflow are inherently random. For example, allocating data points to folds in k-fold cross-validation and bootstrap sampling of data to train decision trees in random forests.\nWhile this randomness is important (e.g. to ensure unbiased estimates of model performance when using cross-validation) it presents a challenge for reproducible results. The randomness of estimators (e.g. an instance of RandomForestsRegressor() or a cross-validation splitter is controlled by a random_state parameter.\nSome general tips on setting the random_state parameter:\n\nNever set random_state to None for reproducible results.\nCreate a RandomState variable at the start of your program and pass it to all functions that accept a random_state argument. Look at the start of this notebook and see if you can sport where we create a RandomState variable just after we import the modules.\nIf you’re generating cross validation splits, use an integer value instead of a RandomState instance.\n\nThis is quite an advanced topic, but important to ensure your results are reproducible. Generally, following the guidelines above is the best way to go. However, you can read more about this topic here."
  },
  {
    "objectID": "lab-5-self-guided.html#feature-importance",
    "href": "lab-5-self-guided.html#feature-importance",
    "title": "Introduction",
    "section": "Feature importance",
    "text": "Feature importance\nMachine learning models are often considered “black boxes”. That is, it is not clear how the model is using input features to make predictions and what relationships it has learnt to relate features to outcomes.\nOne strategy to make machine learning models more interpretable is to compute feature importance (or permutation importance). The feature importance is a measure of how much the error in a model’s prediction increases when a feature is omitted from the model. Features with larger importance scores are therefore more important for making accurate predictions.\nThe permutation feature importance score is computed as the decrease in a model’s performance when a feature is randomly shuffled (permuted). This should ensure there is no relationship between the feature and the outcome.\nYou can read more about feature importance in the Interpretable Machine Learning book and in the Scikit-learn docs.\nFirst, let’s set up and fit a linear regression model that predicts maize crop yield using vegetation indices and field characteristics.\n\n# NOTE we use df_cat here!!\n\n# drop nas as Linear Regression object cannot be trained on datasets with missing data\ndf_linear_reg = df_cat.loc[: , [\n    \"cc_yield\",\n    \"gcvi_doy_151\", \n    \"gcvi_doy_171\", \n    \"ndvi_doy_151\", \n    \"ndvi_doy_171\", \n    \"mtci_doy_151\", \n    \"mtci_doy_171\",\n    \"slope_sr_FLAT\",\n    \"slope_sr_MODERATE SLOPE\", \n    \"slope_sr_SLIGHT SLOPE\",\n    \"slope_sr_STEEP SLOPE\"]].dropna()\n\n# get X\nX = df_linear_reg.loc[:, [\n    \"gcvi_doy_151\", \n    \"gcvi_doy_171\", \n    \"ndvi_doy_151\", \n    \"ndvi_doy_171\", \n    \"mtci_doy_151\", \n    \"mtci_doy_171\",\n    \"slope_sr_FLAT\",\n    \"slope_sr_MODERATE SLOPE\", \n    \"slope_sr_SLIGHT SLOPE\",\n    \"slope_sr_STEEP SLOPE\"]]\n\n# get Y\ny = df_linear_reg.loc[:, \"cc_yield\"]\n\n# create a LinearRegression estimator object\nreg = LinearRegression()\n\n# fit the model\nreg.fit(X, y)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\nNow we compute permuation importance using 30 shuffles of each feature. The results referenced by p_imp is a dictionary object with arrays showing the model error when each feature was randomly shuffled and for each repeat of the random shuffling. It also has a property importances_mean which is the mean increase in error across all iterations when a feature was randomly shuffled.\nWe use the permutation_importance() function and pass in the LinearRegression() estimator, the features and labels data (X and y), the metric to evaluate model performance to the scoring argument, and specify the number of repeats with the n_repeats argument.\np_imp = permutation_importance(reg, X, y, scoring=\"neg_mean_absolute_error\", n_repeats=30, random_state=rng)\n\np_imp[\"importances_mean\"]\n\narray([ 1.15861873e-01,  1.17595302e-01,  1.46321198e-01,  6.36841158e-02,\n        3.75817560e-02,  2.71901988e-02, -7.23502021e-04, -5.62591591e-06,\n        2.77529578e-05,  1.15896277e-04])\n\n\nLet’s use this data to make a permutation importance plot that visualises the increase in error when a feature is randomly shuffled.\nFirst, let’s get a list of column headings for each feature and convert the negative mean absolute error values to positive.\ncolumns = X.columns\np_imp = abs(p_imp[\"importances_mean\"])\nNow, let’s combine the feature labels and importance values into a DataFrame, sort the DataFrame by the importance scores, and generate a bar plot.\n\np_imp_df = pd.DataFrame({\"feature\": columns, \"importance\": p_imp})\np_imp_df = p_imp_df.sort_values(by=[\"importance\"], ascending=True)\np_imp_df\n\n\n\n\n\n  \n    \n      \n      feature\n      importance\n    \n  \n  \n    \n      7\n      slope_sr_MODERATE SLOPE\n      0.000006\n    \n    \n      8\n      slope_sr_SLIGHT SLOPE\n      0.000028\n    \n    \n      9\n      slope_sr_STEEP SLOPE\n      0.000116\n    \n    \n      6\n      slope_sr_FLAT\n      0.000724\n    \n    \n      5\n      mtci_doy_171\n      0.027190\n    \n    \n      4\n      mtci_doy_151\n      0.037582\n    \n    \n      3\n      ndvi_doy_171\n      0.063684\n    \n    \n      0\n      gcvi_doy_151\n      0.115862\n    \n    \n      1\n      gcvi_doy_171\n      0.117595\n    \n    \n      2\n      ndvi_doy_151\n      0.146321\n    \n  \n\n\n\n\n\nfig = px.bar(p_imp_df, y=\"feature\", x=\"importance\", height=600)\nfig.show()\n\n\n\n\n\nRecap quiz\n\n\nDo the feature importance results make sense? Can you explain them?\n\nThe most important features for predictive importance are the vegetation indices. There is an established literature that vegetation indices are correlated with, and predictive of, crop yields.\nHowever, we should be cautious in interpreting the differences between vegetation indices as it is likely that the vegetation indices are correlated (even if they’re designed to capture different information about vegetation growth and condition). When one of the vegetation indices is permuted (shuffled), it is likely the model will still have access to information about this feature through other features in the model which it is correlated with. You can read more about this here.\n\n\n\n\n\nHere, we computed the feature importance scores using the training data. Can you think of a limit to computing feature importance with the training set compared to using the test set?\n\nComputing feature importance using a held-out test set would indicate which features are important for the model’s capacity to generalise well to unseen data. Features that are important for the training set migh be causing the model to overfit. You can read more about this here."
  },
  {
    "objectID": "lab-5-self-guided.html#final-activity",
    "href": "lab-5-self-guided.html#final-activity",
    "title": "Introduction",
    "section": "Final activity",
    "text": "Final activity\nYou will notice in df that there are some columns related to mixed cropping in some of the maize fields (e.g.intercrop_legume, intercrop_cassava, crop_rotation, purestand). One issue that could be affecting model performance is that we’re using average vegetation indices across the whole field but not all of the field is maize cropping. This means that our vegetation index data is not purely capturing a maize crop signal but also the condition of other crops. We might be able to improve the model’s performance if we restrict our analysis to pure maize fields or control for the effect of mixed cropping.\nCan you create a training set that will use one or more of the intercrop_legume, intercrop_cassava, crop_rotation, and purestand variables to train a model to predict maize yield that accounts for the mixed cropping practices inherent in smallholder systems in Uganda. Evaluate your model using cross-validation and justify the rationale for your approach.\n\n\nanswer 1\n\nHere, we filter out any data points representing mixed cropping fields using the condition df[purestand] == 1 where a value of 1 in the purestand column indicates pure maize cropping.\nThis approach means our vegetation indices should just be capturing information about maize crop condition.\n# get X and y data\n\n# drop mixed cropping fields\ndf_pure = df.loc[df[\"purestand\"] == 1, :]\n\n# one hot encode categorical predictors\ndf_pure = pd.get_dummies(df_pure, columns=[\"slope_sr\", \"soiltype_sr\", \"soilqual_sr\"])\n\n# drop nas as Linear Regression object cannot be trained on datasets with missing data\ndf_linear_reg = df_pure.loc[: , [\n    \"cc_yield\",\n    \"gcvi_doy_151\", \n    \"gcvi_doy_171\", \n    \"ndvi_doy_151\", \n    \"ndvi_doy_171\", \n    \"mtci_doy_151\", \n    \"mtci_doy_171\",\n    \"slope_sr_FLAT\",\n    \"slope_sr_MODERATE SLOPE\",\n    \"slope_sr_SLIGHT SLOPE\",\n    \"slope_sr_STEEP SLOPE\"]].dropna()\n\n# get X\nX = df_linear_reg.loc[:, [\n    \"gcvi_doy_151\", \n    \"gcvi_doy_171\", \n    \"ndvi_doy_151\", \n    \"ndvi_doy_171\", \n    \"mtci_doy_151\", \n    \"mtci_doy_171\",\n    \"slope_sr_FLAT\",\n    \"slope_sr_MODERATE SLOPE\",\n    \"slope_sr_SLIGHT SLOPE\",\n    \"slope_sr_STEEP SLOPE\"]]\n\n# get Y\ny = df_linear_reg.loc[:, \"cc_yield\"]\n\n# create a LinearRegression estimator object\nreg = LinearRegression()\n\n# evaluate using 5-fold cross validation\ncv_scores = cross_validate(reg, X, y, cv=5, scoring=[\"neg_mean_absolute_error\"])\ncv_scores\n\n\n\nanswer 2\n\nHere, we control for the presence of mixed cropping by using intercropping and crop rotation variables as features in the model.\nThis approach might be suited to generating a maize crop prediction model that’s applicable to the Ugandan context where mixed cropping is prevalent and pure maize fields are uncommon.\n# get X and y data\n\n# one hot encode categorical predictors\ndf_2 = pd.get_dummies(df, columns=[\"slope_sr\", \"soiltype_sr\", \"soilqual_sr\"])\n\n# drop nas as Linear Regression object cannot be trained on datasets with missing data\ndf_linear_reg = df_2.loc[: , [\n    \"cc_yield\",\n    \"gcvi_doy_151\", \n    \"gcvi_doy_171\", \n    \"ndvi_doy_151\", \n    \"ndvi_doy_171\", \n    \"mtci_doy_151\", \n    \"mtci_doy_171\",\n    \"slope_sr_FLAT\",\n    \"slope_sr_MODERATE SLOPE\",\n    \"slope_sr_SLIGHT SLOPE\",\n    \"slope_sr_STEEP SLOPE\",\n    \"intercrop_legume\",\n    \"intercrop_cassava\",\n    \"crop_rotation\"]].dropna()\n\n# get X\nX = df_linear_reg.loc[:, [\n    \"gcvi_doy_151\", \n    \"gcvi_doy_171\", \n    \"ndvi_doy_151\", \n    \"ndvi_doy_171\", \n    \"mtci_doy_151\", \n    \"mtci_doy_171\",\n    \"slope_sr_FLAT\",\n    \"slope_sr_MODERATE SLOPE\",\n    \"slope_sr_SLIGHT SLOPE\",\n    \"slope_sr_STEEP SLOPE\",\n    \"intercrop_legume\",\n    \"intercrop_cassava\",\n    \"crop_rotation\"]]\n\n# get Y\ny = df_linear_reg.loc[:, \"cc_yield\"]\n\n# create a LinearRegression estimator object\nreg = LinearRegression()\n\n# evaluate using 5-fold cross validation\ncv_scores = cross_validate(reg, X, y, cv=5, scoring=[\"neg_mean_absolute_error\"])\ncv_scores"
  },
  {
    "objectID": "lab-6-self-guided.html",
    "href": "lab-6-self-guided.html",
    "title": "Introduction",
    "section": "",
    "text": "This lab will demonstrate how to search for and download geospatial data in the cloud.\nIt will introduce SpatioTemporal Asset Catalogs (STAC), a specification that makes it easy to query and search through large collections of geospatial data assets stored in the cloud.\nYou will also learn to use the pystac_client package which provides tools for working with STAC in Python.\nFirst, let’s briefly outline what the STAC specification is before completing some data querying and downloading tasks to make the concepts concrete.\nspatiotemporal asset: this is a file comprising geospatial data for a location and point in time. For example, this could be Landsat or Sentinel-2 satellite images stored in the cloud such as in Microsoft Azure or Amazon Web Services. This is a file that we can download and use the data in our analysis and applications. However, if you look at Microsoft’s Planetary Computer Data Catalog, Amazon Web Services Open Data, or the Digital Earth Australia Open Data Cube you will see there are lots of spatiotemporal assets available (for free). The challenge is searching through these collections of assets to find the data you need and downloading it. The STAC specification provides a solution for this.\nThe STAC specification comprises:\n\nSTAC Item - a GeoJSON feature that represents a spatiotemporal asset with links to the spatiotemporal asset and additional metadata fields (e.g. bounding box, thumbnail, datetime, cloud cover).\nSTAC Catalog - a JSON file of links to STAC Items to support querying and retrieving STAC Items. STAC Catalogs can comprise sub-catalogs that group together related data within a larger structure. For example, Microsoft’s Planetary Computer might create a STAC Catalog for all its spatiotemporal assets and organise these assets in sub-catalogs (e.g. a catalog for Landsat 7, Landsat 8, Sentinel-2, SRTM DEM etc.).\nSTAC Collection - an extension of a STAC Catalog with additional metadata properties (e.g. extents, licences, providers) to describe STAC Items within the collection.\nSTAC API - an API that allows clients to query a STAC collection, search for STAC Items, and retrieve their links for downloading. The search endpoint is designed to recieve queries of STAC Catalogs that filter on location, date, and time as well as other fields. It returns a GeoJSON FeatureCollection object with of STAC Items that meet the search criteria.\n\n\n\nWe’re going to use the pystac_client package to query a range of STAC Catalogs hosted in the cloud. We’ll complete the following tasks:\n\nFind the least cloudy Sentinel-2 image for a field in Western Australia using the Microsoft Planetary Computer.\nFind the least cloudy Sentinel-2 image for a field in Western Australia using Amazon Web Services.\n\n\n\nOnce you have completed the main tasks for this lab, have a go at these follow-up examples to practice querying and retrieving data from STAC Collections.\n\nMake a cloud-free Monthly NDVI composite image for a field in Western Australia using the Microsoft Planetary Computer.\nCompute the average NDVI of different land cover classes using Sentinel-2 images and land cover maps retrieved from the Microsoft Planetaary Computer.\nMap surface water after a flood with Sentinel-1 radar data using the Microsoft Planetary Computer.\nQuery a Landsat 8 STAC Collection to see if there are there any cloud-free post-Flood images.\n\n\n\n\n\nThese are some tips for working with STAC here.\n\nuse rectangular bounding boxes or area-of-interest geometries to quickly identify STAC Items that intersect with their extent.\nfor exploratory work use small areas-of-interest to minimise the size of searches of STAC Collections and the amount of data transmitted over the network.\n\n\n\n\n\nSTAC website: the STAC homepage with details about STAC, tutorials, and links to STAC catalogs.\nSTAC Browser: a web browser to search for STAC catalogs.\nSTAC Index: an index of STAC catalogs and tutorials.\nMicrosoft Planetary Computer Catalog: Microsoft Planetary Computer’s STAC catalogs."
  },
  {
    "objectID": "lab-6-self-guided.html#setup",
    "href": "lab-6-self-guided.html#setup",
    "title": "Introduction",
    "section": "Setup",
    "text": "Setup\n\nRun the labs\nYou can run the labs locally on your machine or you can use cloud environments provided by Google Colab. If you’re working with Google Colab be aware that your sessions are temporary and you’ll need to take care to save, backup, and download your work.\n  \n\n\nDownload data\nIf you need to download the date for this lab, run the following code snippet.\nimport os\n\nif \"week-6\" not in os.listdir(os.getcwd()):\n    os.system('wget \"https://github.com/data-analysis-3300-3003/data/raw/main/data/week-6.zip\"')\n    os.system('unzip \"week-6.zip\"')\n\n\nWorking in Colab\nIf you’re working in Google Colab, you’ll need to install the required packages that don’t come with the colab environment.\nif 'google.colab' in str(get_ipython()):\n    !pip install geopandas\n    !pip install pyarrow\n    !pip install mapclassify\n    !pip install rasterio\n    !pip install planetary-computer\n    !pip install pystac-client\n\n\nImport modules\nimport os\nimport json\nimport geopandas as gpd\nimport pandas as pd\nimport numpy as np\nimport pystac_client\nimport planetary_computer as pc\nimport plotly.express as px\nimport plotly.io as pio\nimport rasterio\nfrom rasterio import windows\nfrom rasterio import features\nfrom rasterio import warp\nfrom skimage import io\n\nfrom pystac.extensions.eo import EOExtension as eo\n\n# setup renderer\nif 'google.colab' in str(get_ipython()):\n    pio.renderers.default = \"colab\"\nelse:\n    pio.renderers.default = \"jupyterlab\""
  },
  {
    "objectID": "lab-6-self-guided.html#sentinel-2-and-microsoft-planetary-computer",
    "href": "lab-6-self-guided.html#sentinel-2-and-microsoft-planetary-computer",
    "title": "Introduction",
    "section": "Sentinel-2 and Microsoft Planetary Computer",
    "text": "Sentinel-2 and Microsoft Planetary Computer\nTo provide an introducion to the STAC specification and using it to search for spatiotemporal assets, we’ll use it to query Microsoft’s Planetary Computer to find a cloud free Sentinel-2 satellite image for a field in Western Australia.\nWe’ll be using the pystac_client package which is a STAC Python Client providing classes for working with STAC Catalogs and APIs.\nFirst, we need to create a pystac_client.Client object with methods and attributes to interact with a given STAC Catalog. Using the pystac_client.Client.open() method we can open a STAC Catalog or API and read the root catalog.\nThe pystac_client.Client.open() method requires a url which points to the STAC catalog or api. The url for the Microsoft Planetary Computer STAC API is \"https://planetarycomputer.microsoft.com/api/stac/v1\". When working with the Microsoft Planetary Computer we also need to pass in a modifier which modifies children of the collection and items returned by the Client - planetary_computer.sign_inplace. This signs each of the STAC Items retrieved from the Planetary Computer allowing Microsoft to maintain some control on the number of requests made to the service.\n# open a connection to the Microsoft Planetary Computer's root STAC catalog\npc_catalog = pystac_client.Client.open(\n    url=\"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    # modifier=planetary_computer.sign_inplace\n)\nA pystac_client object has a search() method that can be used to specify a query to search a STAC Collection for STAC Items that meet certain conditions. The search() method has the following parameters that can be used to define scope of the query:\n\nmax_items - maximum number of items to return from the search.\nbbox - a list or tuple of of bounding box coordinates. STAC Items that intersect the bounding box will be returned.\nintersects - a str or dict representation of a GeoJSON geometry or Shapely geometry. STAC Items that intersect the geometry will be returned.\ndatetime - a single datetime or datetime range used to filter STAC Items.\nquery - list of JSON or query parameters using the STAC API query extension.\n\nYou can see the full details for the search() method here.\n\nArea of interest\nBefore we can search() the Planetary Computer STAC Catalog we need to create the geographic extent for our query.\nWe’re going to start by reading in a geometry for the field boundary stored in a shapefile. We need to convert the shapefile to one of:\n\nbounding box coordinates\na GeoJSON geometry\n\nWe’ll demonstrate how to do each of these conversions for your reference.\nFirst let’s read the data from file. Then, we’ll compute the envelope of the field’s geometry. The envelope is the smallest rectangular geometry to cover the field’s geometry. It is often beneficial to pass in simpler geometries than more complex shapes for identifying STAC Items that intersect with an area-of-interest.\n\n# load field boundary from shapefile\ndata_path = os.path.join(os.getcwd(), \"week-6\", \"BF66_bdy.shp\")\naoi = gpd.read_file(data_path)\n\n# add the field boundary to a map object\nm = aoi.explore()\naoi_env = aoi[\"geometry\"].envelope\n# draw envelope in red\naoi_env.explore(m=m, color=\"red\", style_kwds={\"fillOpacity\": 0})\n\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\nA GeoSeries is a sequence of Shapely geometry objects. Thus, we can just extract the first and only element of the aoi_env GeoSeries to obtain a Shapely geometry.\n\n# get Shapely geometry object\naoi_shapely = aoi_env[0]\nprint(aoi_shapely)\n\nPOLYGON ((117.47847020738 -31.6059444159889, 117.503591091284 -31.6059444159889, 117.503591091284 -31.5913653675164, 117.47847020738 -31.5913653675164, 117.47847020738 -31.6059444159889))\n\n\nThe process to obtain a GeoJSON str or dict representation of the envelope is more involved. First, we use the GeoPandas to_json() method to convert the GeoSeries to a GeoJSON FeatureCollection in str format.\nThen, we use the json.loads() to function to parse the JSON string data to a Python dict.\nFinally, we can subset the geometry property out of the dict.\n\naoi_json = json.loads(aoi_env.to_json())\nprint(\"AOI Envelope as GeoJSON FeatureCollection\")\nprint(\"\")\nprint(aoi_json)\naoi_geometry = dict(aoi_json[\"features\"][0])[\"geometry\"]\nprint(\"\")\nprint(\"AOI Envelope as GeoJSON Geometry\")\nprint(\"\")\nprint(aoi_geometry)\n\nAOI Envelope as GeoJSON FeatureCollection\n\n{'type': 'FeatureCollection', 'features': [{'id': '0', 'type': 'Feature', 'properties': {}, 'geometry': {'type': 'Polygon', 'coordinates': [[[117.47847020738, -31.6059444159889], [117.503591091284, -31.6059444159889], [117.503591091284, -31.5913653675164], [117.47847020738, -31.5913653675164], [117.47847020738, -31.6059444159889]]]}, 'bbox': [117.47847020738, -31.6059444159889, 117.503591091284, -31.5913653675164]}], 'bbox': [117.47847020738, -31.6059444159889, 117.503591091284, -31.5913653675164]}\n\nAOI Envelope as GeoJSON Geometry\n\n{'type': 'Polygon', 'coordinates': [[[117.47847020738, -31.6059444159889], [117.503591091284, -31.6059444159889], [117.503591091284, -31.5913653675164], [117.47847020738, -31.5913653675164], [117.47847020738, -31.6059444159889]]]}\n\n\nFinally, it is simple to obtain a list of coordinates for the bounding box by using the total_bounds property of the GeoSeries and converting it to a list object.\n\nbbox = aoi_env.total_bounds.tolist()\nbbox\n\n[117.47847020738, -31.6059444159889, 117.503591091284, -31.5913653675164]\n\n\n\n\nDatetime\nLet’s specify a datetime range to search. Here, we’ll look for all Sentinel-2 STAC Items that intersect our area-of-interest from the month of October 2019.\ntime_of_interest = \"2019-10-01/2019-11-01\"\n\n\nExtensions\nThe STAC specification permits extensions which allow for more description of STAC Items in a collection. A commonly used extension is the Electro-Optical Extension Specification for describing snapshots of the Earth for a point-in-time and designed for data that’s captured for one or more wavelengths of the electromagnetic spectrum (i.e. remote sensing data).\nIt includes the following item properties:\n\neo:bands: an array of available bands (i.e. different spectral wavebands for a remote sensing image).\neo:cloud_cover: an estimate of cloud cover for the STAC Item.\neo:snow_cover: an estimate of snow and ice cover for the STAC Item.\n\nThe eo:cloud_cover property could be useful to help with searching a STAC Collection for cloud free scenes.\nWe can set up a query of eo properties as: {\"eo:cloud_cover\": {\"lt\": 10}}. This will find all STAC Items with a property of eo:cloud_cover less than 10%.\n\n\nSearch\nWe’re now ready to search the Planetary Computer STAC Catalog’s sentinel-2-l2a for all images with low cloud cover in October 2019 that intersect our area-of-interest.\nThe s2_search object is an ItemSearch instance which represents the search of a STAC API. We can retrieve the STAC Items returned by the search as an ItemCollection using the item_collection() method.\nWe can print the ItemCollection an interactively explore its contents. This helpfully illustrates the structure of the STAC specification. Our search of the sentinel-2-l2a collection returned 2 STAC Items. Each STAC Item corresponds to a Sentinel-2 image.\nWe can explore each of the STAC Items and see that it has several metadata properties (e.g. Bounding Box, Datetime, platform, proj:epsg, eo:cloud_cover), it also has an Assets slot which stores links to the underlying data referenced by the STAC Item. In this case it is a cloud-optimised GeoTIFF files stored in Microsoft Azure.\n\n# Search the Planetary Computers S2 Catalog\ns2_search = pc_catalog.search(\n    collections=[\"sentinel-2-l2a\"],\n    bbox=bbox,\n    datetime=time_of_interest,\n    query={\"eo:cloud_cover\": {\"lt\": 10}},\n)\n\n# Check how many items were returned\ns2_items = s2_search.item_collection()\nprint(f\"Returned {len(s2_items)} Items\")\n\nReturned 2 Items\n\n\n\ns2_items\n\n\n\n\n\n    \n    \n    \n        \n            \n                \n                    ItemCollection\n                \n            \n            \n                \n            \n\n            \n                \n                    \n                    \n                        Items\n                    \n                    \n                        \n\n\n    \n    \n    \n        \n            \n                Item: S2B_MSIL2A_20191026T020449_R017_T50JNL_20201004T062410\n            \n            \n                ID: S2B_MSIL2A_20191026T020449_R017_T50JNL_20201004T062410 \n                \n                \n                    Bounding Box: [116.99978889138299, -31.723243569451945, 118.15867410019476, -30.72746336187748] \n                \n                \n                    Datetime: 2019-10-26 02:04:49.024000+00:00 \n                \n                \n                    \n                        datetime: 2019-10-26T02:04:49.024000Z \n                    \n                        platform: Sentinel-2B \n                    \n                        proj:epsg: 32750 \n                    \n                        instruments: ['msi'] \n                    \n                        s2:mgrs_tile: 50JNL \n                    \n                        constellation: Sentinel 2 \n                    \n                        s2:granule_id: S2B_OPER_MSI_L2A_TL_ESRI_20201004T062412_A013771_T50JNL_N02.12 \n                    \n                        eo:cloud_cover: 3.310938 \n                    \n                        s2:datatake_id: GS2B_20191026T020449_013771_N02.12 \n                    \n                        s2:product_uri: S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE \n                    \n                        s2:datastrip_id: S2B_OPER_MSI_L2A_DS_ESRI_20201004T062412_S20191026T021058_N02.12 \n                    \n                        s2:product_type: S2MSI2A \n                    \n                        sat:orbit_state: descending \n                    \n                        s2:datatake_type: INS-NOBS \n                    \n                        s2:generation_time: 2020-10-04T06:24:10.879Z \n                    \n                        sat:relative_orbit: 17 \n                    \n                        s2:water_percentage: 0.046828 \n                    \n                        s2:mean_solar_zenith: 29.3431796304929 \n                    \n                        s2:mean_solar_azimuth: 55.2222313966405 \n                    \n                        s2:processing_baseline: 02.12 \n                    \n                        s2:snow_ice_percentage: 0.0 \n                    \n                        s2:vegetation_percentage: 0.119897 \n                    \n                        s2:thin_cirrus_percentage: 3.133344 \n                    \n                        s2:cloud_shadow_percentage: 0.0001 \n                    \n                        s2:nodata_pixel_percentage: 0.0 \n                    \n                        s2:unclassified_percentage: 0.205129 \n                    \n                        s2:dark_features_percentage: 0.005033 \n                    \n                        s2:not_vegetated_percentage: 96.312076 \n                    \n                        s2:degraded_msi_data_percentage: 0.0 \n                    \n                        s2:high_proba_clouds_percentage: 0.087943 \n                    \n                        s2:reflectance_conversion_factor: 1.01016666205721 \n                    \n                        s2:medium_proba_clouds_percentage: 0.089651 \n                    \n                        s2:saturated_defective_pixel_percentage: 0.0 \n                    \n                \n                \n        \n            stac_extensions: ['https://stac-extensions.github.io/eo/v1.0.0/schema.json', 'https://stac-extensions.github.io/sat/v1.0.0/schema.json', 'https://stac-extensions.github.io/projection/v1.0.0/schema.json'] \n        \n    \n            \n            \n        \n            \n                STAC Extensions\n            \n            \n                \n                    https://stac-extensions.github.io/eo/v1.0.0/schema.json\n                \n                    https://stac-extensions.github.io/sat/v1.0.0/schema.json\n                \n                    https://stac-extensions.github.io/projection/v1.0.0/schema.json\n                \n            \n        \n    \n            \n        \n            \n                Assets\n            \n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Aerosol optical thickness (AOT)\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/GRANULE/L2A_T50JNL_A013771_20191026T021058/IMG_DATA/R10m/T50JNL_20191026T020449_AOT_10m.tif \n                \n                    Title: Aerosol optical thickness (AOT) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 1 - Coastal aerosol - 60m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/GRANULE/L2A_T50JNL_A013771_20191026T021058/IMG_DATA/R60m/T50JNL_20191026T020449_B01_60m.tif \n                \n                    Title: Band 1 - Coastal aerosol - 60m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [1830, 1830] \n        \n            proj:transform: [60.0, 0.0, 499980.0, 0.0, -60.0, 6600040.0] \n        \n            gsd: 60.0 \n        \n            eo:bands: [{'name': 'B01', 'common_name': 'coastal', 'description': 'Band 1 - Coastal aerosol', 'center_wavelength': 0.443, 'full_width_half_max': 0.027}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 2 - Blue - 10m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/GRANULE/L2A_T50JNL_A013771_20191026T021058/IMG_DATA/R10m/T50JNL_20191026T020449_B02_10m.tif \n                \n                    Title: Band 2 - Blue - 10m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n            eo:bands: [{'name': 'B02', 'common_name': 'blue', 'description': 'Band 2 - Blue', 'center_wavelength': 0.49, 'full_width_half_max': 0.098}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 3 - Green - 10m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/GRANULE/L2A_T50JNL_A013771_20191026T021058/IMG_DATA/R10m/T50JNL_20191026T020449_B03_10m.tif \n                \n                    Title: Band 3 - Green - 10m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n            eo:bands: [{'name': 'B03', 'common_name': 'green', 'description': 'Band 3 - Green', 'center_wavelength': 0.56, 'full_width_half_max': 0.045}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 4 - Red - 10m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/GRANULE/L2A_T50JNL_A013771_20191026T021058/IMG_DATA/R10m/T50JNL_20191026T020449_B04_10m.tif \n                \n                    Title: Band 4 - Red - 10m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n            eo:bands: [{'name': 'B04', 'common_name': 'red', 'description': 'Band 4 - Red', 'center_wavelength': 0.665, 'full_width_half_max': 0.038}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 5 - Vegetation red edge 1 - 20m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/GRANULE/L2A_T50JNL_A013771_20191026T021058/IMG_DATA/R20m/T50JNL_20191026T020449_B05_20m.tif \n                \n                    Title: Band 5 - Vegetation red edge 1 - 20m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20.0, 0.0, 499980.0, 0.0, -20.0, 6600040.0] \n        \n            gsd: 20.0 \n        \n            eo:bands: [{'name': 'B05', 'common_name': 'rededge', 'description': 'Band 5 - Vegetation red edge 1', 'center_wavelength': 0.704, 'full_width_half_max': 0.019}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 6 - Vegetation red edge 2 - 20m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/GRANULE/L2A_T50JNL_A013771_20191026T021058/IMG_DATA/R20m/T50JNL_20191026T020449_B06_20m.tif \n                \n                    Title: Band 6 - Vegetation red edge 2 - 20m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20.0, 0.0, 499980.0, 0.0, -20.0, 6600040.0] \n        \n            gsd: 20.0 \n        \n            eo:bands: [{'name': 'B06', 'common_name': 'rededge', 'description': 'Band 6 - Vegetation red edge 2', 'center_wavelength': 0.74, 'full_width_half_max': 0.018}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 7 - Vegetation red edge 3 - 20m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/GRANULE/L2A_T50JNL_A013771_20191026T021058/IMG_DATA/R20m/T50JNL_20191026T020449_B07_20m.tif \n                \n                    Title: Band 7 - Vegetation red edge 3 - 20m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20.0, 0.0, 499980.0, 0.0, -20.0, 6600040.0] \n        \n            gsd: 20.0 \n        \n            eo:bands: [{'name': 'B07', 'common_name': 'rededge', 'description': 'Band 7 - Vegetation red edge 3', 'center_wavelength': 0.783, 'full_width_half_max': 0.028}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 8 - NIR - 10m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/GRANULE/L2A_T50JNL_A013771_20191026T021058/IMG_DATA/R10m/T50JNL_20191026T020449_B08_10m.tif \n                \n                    Title: Band 8 - NIR - 10m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n            eo:bands: [{'name': 'B08', 'common_name': 'nir', 'description': 'Band 8 - NIR', 'center_wavelength': 0.842, 'full_width_half_max': 0.145}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 9 - Water vapor - 60m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/GRANULE/L2A_T50JNL_A013771_20191026T021058/IMG_DATA/R60m/T50JNL_20191026T020449_B09_60m.tif \n                \n                    Title: Band 9 - Water vapor - 60m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [1830, 1830] \n        \n            proj:transform: [60.0, 0.0, 499980.0, 0.0, -60.0, 6600040.0] \n        \n            gsd: 60.0 \n        \n            eo:bands: [{'name': 'B09', 'description': 'Band 9 - Water vapor', 'center_wavelength': 0.945, 'full_width_half_max': 0.026}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 11 - SWIR (1.6) - 20m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/GRANULE/L2A_T50JNL_A013771_20191026T021058/IMG_DATA/R20m/T50JNL_20191026T020449_B11_20m.tif \n                \n                    Title: Band 11 - SWIR (1.6) - 20m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20.0, 0.0, 499980.0, 0.0, -20.0, 6600040.0] \n        \n            gsd: 20.0 \n        \n            eo:bands: [{'name': 'B11', 'common_name': 'swir16', 'description': 'Band 11 - SWIR (1.6)', 'center_wavelength': 1.61, 'full_width_half_max': 0.143}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 12 - SWIR (2.2) - 20m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/GRANULE/L2A_T50JNL_A013771_20191026T021058/IMG_DATA/R20m/T50JNL_20191026T020449_B12_20m.tif \n                \n                    Title: Band 12 - SWIR (2.2) - 20m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20.0, 0.0, 499980.0, 0.0, -20.0, 6600040.0] \n        \n            gsd: 20.0 \n        \n            eo:bands: [{'name': 'B12', 'common_name': 'swir22', 'description': 'Band 12 - SWIR (2.2)', 'center_wavelength': 2.19, 'full_width_half_max': 0.242}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 8A - Vegetation red edge 4 - 20m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/GRANULE/L2A_T50JNL_A013771_20191026T021058/IMG_DATA/R20m/T50JNL_20191026T020449_B8A_20m.tif \n                \n                    Title: Band 8A - Vegetation red edge 4 - 20m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20.0, 0.0, 499980.0, 0.0, -20.0, 6600040.0] \n        \n            gsd: 20.0 \n        \n            eo:bands: [{'name': 'B8A', 'common_name': 'rededge', 'description': 'Band 8A - Vegetation red edge 4', 'center_wavelength': 0.865, 'full_width_half_max': 0.033}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Scene classfication map (SCL)\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/GRANULE/L2A_T50JNL_A013771_20191026T021058/IMG_DATA/R20m/T50JNL_20191026T020449_SCL_20m.tif \n                \n                    Title: Scene classfication map (SCL) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20.0, 0.0, 499980.0, 0.0, -20.0, 6600040.0] \n        \n            gsd: 20.0 \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Water vapour (WVP)\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/GRANULE/L2A_T50JNL_A013771_20191026T021058/IMG_DATA/R10m/T50JNL_20191026T020449_WVP_10m.tif \n                \n                    Title: Water vapour (WVP) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: True color image\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/GRANULE/L2A_T50JNL_A013771_20191026T021058/IMG_DATA/R10m/T50JNL_20191026T020449_TCI_10m.tif \n                \n                    Title: True color image \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n            eo:bands: [{'name': 'B04', 'common_name': 'red', 'description': 'Band 4 - Red', 'center_wavelength': 0.665, 'full_width_half_max': 0.038}, {'name': 'B03', 'common_name': 'green', 'description': 'Band 3 - Green', 'center_wavelength': 0.56, 'full_width_half_max': 0.045}, {'name': 'B02', 'common_name': 'blue', 'description': 'Band 2 - Blue', 'center_wavelength': 0.49, 'full_width_half_max': 0.098}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Thumbnail\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/GRANULE/L2A_T50JNL_A013771_20191026T021058/QI_DATA/T50JNL_20191026T020449_PVI.tif \n                \n                    Title: Thumbnail \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['thumbnail'] \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: SAFE manifest\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/manifest.safe \n                \n                    Title: SAFE manifest \n                \n                \n                \n                    Media type: application/xml \n                \n                \n                    Roles: ['metadata'] \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Granule metadata\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/GRANULE/L2A_T50JNL_A013771_20191026T021058/MTD_TL.xml \n                \n                    Title: Granule metadata \n                \n                \n                \n                    Media type: application/xml \n                \n                \n                    Roles: ['metadata'] \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: INSPIRE metadata\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/INSPIRE.xml \n                \n                    Title: INSPIRE metadata \n                \n                \n                \n                    Media type: application/xml \n                \n                \n                    Roles: ['metadata'] \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Product metadata\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/MTD_MSIL2A.xml \n                \n                    Title: Product metadata \n                \n                \n                \n                    Media type: application/xml \n                \n                \n                    Roles: ['metadata'] \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Datastrip metadata\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/26/S2B_MSIL2A_20191026T020449_N0212_R017_T50JNL_20201004T062410.SAFE/DATASTRIP/DS_ESRI_20201004T062412_S20191026T021058/MTD_DS.xml \n                \n                    Title: Datastrip metadata \n                \n                \n                \n                    Media type: application/xml \n                \n                \n                    Roles: ['metadata'] \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: TileJSON with default rendering\n            \n            \n                href: https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=sentinel-2-l2a&item=S2B_MSIL2A_20191026T020449_R017_T50JNL_20201004T062410&assets=visual&asset_bidx=visual%7C1%2C2%2C3&nodata=0&format=png \n                \n                    Title: TileJSON with default rendering \n                \n                \n                \n                    Media type: application/json \n                \n                \n                    Roles: ['tiles'] \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Rendered preview\n            \n            \n                href: https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=sentinel-2-l2a&item=S2B_MSIL2A_20191026T020449_R017_T50JNL_20201004T062410&assets=visual&asset_bidx=visual%7C1%2C2%2C3&nodata=0&format=png \n                \n                    Title: Rendered preview \n                \n                \n                \n                    Media type: image/png \n                \n                \n                    Roles: ['overview'] \n                \n                \n                    Owner:  \n                \n                \n        \n            rel: preview \n        \n    \n            \n        \n    \n\n            \n        \n    \n            \n        \n            \n                Links\n            \n            \n                \n\n\n    \n    \n    \n        Link: \n        \n        \n            Rel: collection \n            Target: https://planetarycomputer.microsoft.com/api/stac/v1/collections/sentinel-2-l2a \n            \n                Media Type: application/json \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n        \n            Rel: parent \n            Target: https://planetarycomputer.microsoft.com/api/stac/v1/collections/sentinel-2-l2a \n            \n                Media Type: application/json \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n            Microsoft Planetary Computer STAC API\n        \n        \n            Rel: root \n            Target:  \n            \n                Media Type: application/json \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n        \n            Rel: self \n            Target: https://planetarycomputer.microsoft.com/api/stac/v1/collections/sentinel-2-l2a/items/S2B_MSIL2A_20191026T020449_R017_T50JNL_20201004T062410 \n            \n                Media Type: application/geo+json \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n        \n            Rel: license \n            Target: https://sentinel.esa.int/documents/247904/690755/Sentinel_Data_Legal_Notice \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n            Map of item\n        \n        \n            Rel: preview \n            Target: https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=sentinel-2-l2a&item=S2B_MSIL2A_20191026T020449_R017_T50JNL_20201004T062410 \n            \n                Media Type: text/html \n            \n            \n        \n        \n    \n\n            \n        \n    \n        \n    \n\n                    \n                        \n\n\n    \n    \n    \n        \n            \n                Item: S2A_MSIL2A_20191021T020451_R017_T50JNL_20201004T043402\n            \n            \n                ID: S2A_MSIL2A_20191021T020451_R017_T50JNL_20201004T043402 \n                \n                \n                    Bounding Box: [116.99978889138299, -31.723243569451945, 118.15867410019476, -30.813798578542475] \n                \n                \n                    Datetime: 2019-10-21 02:04:51.024000+00:00 \n                \n                \n                    \n                        datetime: 2019-10-21T02:04:51.024000Z \n                    \n                        platform: Sentinel-2A \n                    \n                        proj:epsg: 32750 \n                    \n                        instruments: ['msi'] \n                    \n                        s2:mgrs_tile: 50JNL \n                    \n                        constellation: Sentinel 2 \n                    \n                        s2:granule_id: S2A_OPER_MSI_L2A_TL_ESRI_20201004T043403_A022608_T50JNL_N02.12 \n                    \n                        eo:cloud_cover: 0.433066 \n                    \n                        s2:datatake_id: GS2A_20191021T020451_022608_N02.12 \n                    \n                        s2:product_uri: S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE \n                    \n                        s2:datastrip_id: S2A_OPER_MSI_L2A_DS_ESRI_20201004T043403_S20191021T021617_N02.12 \n                    \n                        s2:product_type: S2MSI2A \n                    \n                        sat:orbit_state: descending \n                    \n                        s2:datatake_type: INS-NOBS \n                    \n                        s2:generation_time: 2020-10-04T04:34:02.554Z \n                    \n                        sat:relative_orbit: 17 \n                    \n                        s2:water_percentage: 0.084995 \n                    \n                        s2:mean_solar_zenith: 30.6956916818927 \n                    \n                        s2:mean_solar_azimuth: 52.9759250366361 \n                    \n                        s2:processing_baseline: 02.12 \n                    \n                        s2:snow_ice_percentage: 0.0 \n                    \n                        s2:vegetation_percentage: 0.219855 \n                    \n                        s2:thin_cirrus_percentage: 0.005976 \n                    \n                        s2:cloud_shadow_percentage: 0.001119 \n                    \n                        s2:nodata_pixel_percentage: 19.059283 \n                    \n                        s2:unclassified_percentage: 0.603301 \n                    \n                        s2:dark_features_percentage: 0.030829 \n                    \n                        s2:not_vegetated_percentage: 98.626834 \n                    \n                        s2:degraded_msi_data_percentage: 0.0 \n                    \n                        s2:high_proba_clouds_percentage: 0.127769 \n                    \n                        s2:reflectance_conversion_factor: 1.007352582888 \n                    \n                        s2:medium_proba_clouds_percentage: 0.29932 \n                    \n                        s2:saturated_defective_pixel_percentage: 0.0 \n                    \n                \n                \n        \n            stac_extensions: ['https://stac-extensions.github.io/eo/v1.0.0/schema.json', 'https://stac-extensions.github.io/sat/v1.0.0/schema.json', 'https://stac-extensions.github.io/projection/v1.0.0/schema.json'] \n        \n    \n            \n            \n        \n            \n                STAC Extensions\n            \n            \n                \n                    https://stac-extensions.github.io/eo/v1.0.0/schema.json\n                \n                    https://stac-extensions.github.io/sat/v1.0.0/schema.json\n                \n                    https://stac-extensions.github.io/projection/v1.0.0/schema.json\n                \n            \n        \n    \n            \n        \n            \n                Assets\n            \n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Aerosol optical thickness (AOT)\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R10m/T50JNL_20191021T020451_AOT_10m.tif \n                \n                    Title: Aerosol optical thickness (AOT) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 1 - Coastal aerosol - 60m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R60m/T50JNL_20191021T020451_B01_60m.tif \n                \n                    Title: Band 1 - Coastal aerosol - 60m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [1830, 1830] \n        \n            proj:transform: [60.0, 0.0, 499980.0, 0.0, -60.0, 6600040.0] \n        \n            gsd: 60.0 \n        \n            eo:bands: [{'name': 'B01', 'common_name': 'coastal', 'description': 'Band 1 - Coastal aerosol', 'center_wavelength': 0.443, 'full_width_half_max': 0.027}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 2 - Blue - 10m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R10m/T50JNL_20191021T020451_B02_10m.tif \n                \n                    Title: Band 2 - Blue - 10m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n            eo:bands: [{'name': 'B02', 'common_name': 'blue', 'description': 'Band 2 - Blue', 'center_wavelength': 0.49, 'full_width_half_max': 0.098}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 3 - Green - 10m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R10m/T50JNL_20191021T020451_B03_10m.tif \n                \n                    Title: Band 3 - Green - 10m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n            eo:bands: [{'name': 'B03', 'common_name': 'green', 'description': 'Band 3 - Green', 'center_wavelength': 0.56, 'full_width_half_max': 0.045}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 4 - Red - 10m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R10m/T50JNL_20191021T020451_B04_10m.tif \n                \n                    Title: Band 4 - Red - 10m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n            eo:bands: [{'name': 'B04', 'common_name': 'red', 'description': 'Band 4 - Red', 'center_wavelength': 0.665, 'full_width_half_max': 0.038}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 5 - Vegetation red edge 1 - 20m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R20m/T50JNL_20191021T020451_B05_20m.tif \n                \n                    Title: Band 5 - Vegetation red edge 1 - 20m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20.0, 0.0, 499980.0, 0.0, -20.0, 6600040.0] \n        \n            gsd: 20.0 \n        \n            eo:bands: [{'name': 'B05', 'common_name': 'rededge', 'description': 'Band 5 - Vegetation red edge 1', 'center_wavelength': 0.704, 'full_width_half_max': 0.019}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 6 - Vegetation red edge 2 - 20m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R20m/T50JNL_20191021T020451_B06_20m.tif \n                \n                    Title: Band 6 - Vegetation red edge 2 - 20m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20.0, 0.0, 499980.0, 0.0, -20.0, 6600040.0] \n        \n            gsd: 20.0 \n        \n            eo:bands: [{'name': 'B06', 'common_name': 'rededge', 'description': 'Band 6 - Vegetation red edge 2', 'center_wavelength': 0.74, 'full_width_half_max': 0.018}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 7 - Vegetation red edge 3 - 20m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R20m/T50JNL_20191021T020451_B07_20m.tif \n                \n                    Title: Band 7 - Vegetation red edge 3 - 20m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20.0, 0.0, 499980.0, 0.0, -20.0, 6600040.0] \n        \n            gsd: 20.0 \n        \n            eo:bands: [{'name': 'B07', 'common_name': 'rededge', 'description': 'Band 7 - Vegetation red edge 3', 'center_wavelength': 0.783, 'full_width_half_max': 0.028}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 8 - NIR - 10m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R10m/T50JNL_20191021T020451_B08_10m.tif \n                \n                    Title: Band 8 - NIR - 10m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n            eo:bands: [{'name': 'B08', 'common_name': 'nir', 'description': 'Band 8 - NIR', 'center_wavelength': 0.842, 'full_width_half_max': 0.145}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 9 - Water vapor - 60m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R60m/T50JNL_20191021T020451_B09_60m.tif \n                \n                    Title: Band 9 - Water vapor - 60m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [1830, 1830] \n        \n            proj:transform: [60.0, 0.0, 499980.0, 0.0, -60.0, 6600040.0] \n        \n            gsd: 60.0 \n        \n            eo:bands: [{'name': 'B09', 'description': 'Band 9 - Water vapor', 'center_wavelength': 0.945, 'full_width_half_max': 0.026}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 11 - SWIR (1.6) - 20m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R20m/T50JNL_20191021T020451_B11_20m.tif \n                \n                    Title: Band 11 - SWIR (1.6) - 20m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20.0, 0.0, 499980.0, 0.0, -20.0, 6600040.0] \n        \n            gsd: 20.0 \n        \n            eo:bands: [{'name': 'B11', 'common_name': 'swir16', 'description': 'Band 11 - SWIR (1.6)', 'center_wavelength': 1.61, 'full_width_half_max': 0.143}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 12 - SWIR (2.2) - 20m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R20m/T50JNL_20191021T020451_B12_20m.tif \n                \n                    Title: Band 12 - SWIR (2.2) - 20m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20.0, 0.0, 499980.0, 0.0, -20.0, 6600040.0] \n        \n            gsd: 20.0 \n        \n            eo:bands: [{'name': 'B12', 'common_name': 'swir22', 'description': 'Band 12 - SWIR (2.2)', 'center_wavelength': 2.19, 'full_width_half_max': 0.242}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 8A - Vegetation red edge 4 - 20m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R20m/T50JNL_20191021T020451_B8A_20m.tif \n                \n                    Title: Band 8A - Vegetation red edge 4 - 20m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20.0, 0.0, 499980.0, 0.0, -20.0, 6600040.0] \n        \n            gsd: 20.0 \n        \n            eo:bands: [{'name': 'B8A', 'common_name': 'rededge', 'description': 'Band 8A - Vegetation red edge 4', 'center_wavelength': 0.865, 'full_width_half_max': 0.033}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Scene classfication map (SCL)\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R20m/T50JNL_20191021T020451_SCL_20m.tif \n                \n                    Title: Scene classfication map (SCL) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20.0, 0.0, 499980.0, 0.0, -20.0, 6600040.0] \n        \n            gsd: 20.0 \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Water vapour (WVP)\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R10m/T50JNL_20191021T020451_WVP_10m.tif \n                \n                    Title: Water vapour (WVP) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: True color image\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R10m/T50JNL_20191021T020451_TCI_10m.tif \n                \n                    Title: True color image \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n            eo:bands: [{'name': 'B04', 'common_name': 'red', 'description': 'Band 4 - Red', 'center_wavelength': 0.665, 'full_width_half_max': 0.038}, {'name': 'B03', 'common_name': 'green', 'description': 'Band 3 - Green', 'center_wavelength': 0.56, 'full_width_half_max': 0.045}, {'name': 'B02', 'common_name': 'blue', 'description': 'Band 2 - Blue', 'center_wavelength': 0.49, 'full_width_half_max': 0.098}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Thumbnail\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/QI_DATA/T50JNL_20191021T020451_PVI.tif \n                \n                    Title: Thumbnail \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['thumbnail'] \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: SAFE manifest\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/manifest.safe \n                \n                    Title: SAFE manifest \n                \n                \n                \n                    Media type: application/xml \n                \n                \n                    Roles: ['metadata'] \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Granule metadata\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/MTD_TL.xml \n                \n                    Title: Granule metadata \n                \n                \n                \n                    Media type: application/xml \n                \n                \n                    Roles: ['metadata'] \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: INSPIRE metadata\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/INSPIRE.xml \n                \n                    Title: INSPIRE metadata \n                \n                \n                \n                    Media type: application/xml \n                \n                \n                    Roles: ['metadata'] \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Product metadata\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/MTD_MSIL2A.xml \n                \n                    Title: Product metadata \n                \n                \n                \n                    Media type: application/xml \n                \n                \n                    Roles: ['metadata'] \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Datastrip metadata\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/DATASTRIP/DS_ESRI_20201004T043403_S20191021T021617/MTD_DS.xml \n                \n                    Title: Datastrip metadata \n                \n                \n                \n                    Media type: application/xml \n                \n                \n                    Roles: ['metadata'] \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: TileJSON with default rendering\n            \n            \n                href: https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=sentinel-2-l2a&item=S2A_MSIL2A_20191021T020451_R017_T50JNL_20201004T043402&assets=visual&asset_bidx=visual%7C1%2C2%2C3&nodata=0&format=png \n                \n                    Title: TileJSON with default rendering \n                \n                \n                \n                    Media type: application/json \n                \n                \n                    Roles: ['tiles'] \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Rendered preview\n            \n            \n                href: https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=sentinel-2-l2a&item=S2A_MSIL2A_20191021T020451_R017_T50JNL_20201004T043402&assets=visual&asset_bidx=visual%7C1%2C2%2C3&nodata=0&format=png \n                \n                    Title: Rendered preview \n                \n                \n                \n                    Media type: image/png \n                \n                \n                    Roles: ['overview'] \n                \n                \n                    Owner:  \n                \n                \n        \n            rel: preview \n        \n    \n            \n        \n    \n\n            \n        \n    \n            \n        \n            \n                Links\n            \n            \n                \n\n\n    \n    \n    \n        Link: \n        \n        \n            Rel: collection \n            Target: https://planetarycomputer.microsoft.com/api/stac/v1/collections/sentinel-2-l2a \n            \n                Media Type: application/json \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n        \n            Rel: parent \n            Target: https://planetarycomputer.microsoft.com/api/stac/v1/collections/sentinel-2-l2a \n            \n                Media Type: application/json \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n            Microsoft Planetary Computer STAC API\n        \n        \n            Rel: root \n            Target:  \n            \n                Media Type: application/json \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n        \n            Rel: self \n            Target: https://planetarycomputer.microsoft.com/api/stac/v1/collections/sentinel-2-l2a/items/S2A_MSIL2A_20191021T020451_R017_T50JNL_20201004T043402 \n            \n                Media Type: application/geo+json \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n        \n            Rel: license \n            Target: https://sentinel.esa.int/documents/247904/690755/Sentinel_Data_Legal_Notice \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n            Map of item\n        \n        \n            Rel: preview \n            Target: https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=sentinel-2-l2a&item=S2A_MSIL2A_20191021T020451_R017_T50JNL_20201004T043402 \n            \n                Media Type: text/html \n            \n            \n        \n        \n    \n\n            \n        \n    \n        \n    \n\n                    \n                \n            \n        \n    \n\n\n\n\n\nDownload data\nNo we’ve completed a search of the STAC API and identified that there are two Sentinel-2 images that meet our search criteria, we’re in a position to download these images and use their data.\nAs these are optical images of the Earth’s surface, we’d like to use the least cloudy image. We can write a small routine to find the STAC Item with the lowest eo:cloud_cover value and download that item.\nWe imported the EOExtension module as eo at the start of the notebook. We can use call the eo.ext() method on a STAC Item to extend it with properties from the eo extension. This allows us to get the eo item properties such as cloud_cover easily.\nLet’s loop over all the STAC Items in our search, retrieve their eo:cloud_cover value, and append that value to a list.\n# empty list\ncloud_cover = []\nfor i in s2_items:\n    cloud_cover.append(eo.ext(i).cloud_cover)\nNext, we’ll find the minimum cloud cover value and that STAC Item’s position in our ItemCollection s2_items.\n\nmin_cloud_cover = min(cloud_cover)\nmin_cloud_cover_idx = cloud_cover.index(min_cloud_cover)\nprint(f\"The STAC Item with lowest cloud cover had {min_cloud_cover}% cloud cover\")\nprint(f\"The index postion of the STAC Item with lowest cloud cover in our ItemCollection is {min_cloud_cover_idx}\")\n\nThe STAC Item with lowest cloud cover had 0.433066% cloud cover\nThe index postion of the STAC Item with lowest cloud cover in our ItemCollection is 1\n\n\nLet’s subset the the STAC Item with the lowest cloud cover from our ItemCollection. This should give us a single STAC Item which we can inspect.\n\nleast_cloudy_s2 = s2_items[min_cloud_cover_idx]\nleast_cloudy_s2\n\n\n\n\n\n    \n    \n    \n        \n            \n                Item: S2A_MSIL2A_20191021T020451_R017_T50JNL_20201004T043402\n            \n            \n                ID: S2A_MSIL2A_20191021T020451_R017_T50JNL_20201004T043402 \n                \n                \n                    Bounding Box: [116.99978889138299, -31.723243569451945, 118.15867410019476, -30.813798578542475] \n                \n                \n                    Datetime: 2019-10-21 02:04:51.024000+00:00 \n                \n                \n                    \n                        datetime: 2019-10-21T02:04:51.024000Z \n                    \n                        platform: Sentinel-2A \n                    \n                        proj:epsg: 32750 \n                    \n                        instruments: ['msi'] \n                    \n                        s2:mgrs_tile: 50JNL \n                    \n                        constellation: Sentinel 2 \n                    \n                        s2:granule_id: S2A_OPER_MSI_L2A_TL_ESRI_20201004T043403_A022608_T50JNL_N02.12 \n                    \n                        eo:cloud_cover: 0.433066 \n                    \n                        s2:datatake_id: GS2A_20191021T020451_022608_N02.12 \n                    \n                        s2:product_uri: S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE \n                    \n                        s2:datastrip_id: S2A_OPER_MSI_L2A_DS_ESRI_20201004T043403_S20191021T021617_N02.12 \n                    \n                        s2:product_type: S2MSI2A \n                    \n                        sat:orbit_state: descending \n                    \n                        s2:datatake_type: INS-NOBS \n                    \n                        s2:generation_time: 2020-10-04T04:34:02.554Z \n                    \n                        sat:relative_orbit: 17 \n                    \n                        s2:water_percentage: 0.084995 \n                    \n                        s2:mean_solar_zenith: 30.6956916818927 \n                    \n                        s2:mean_solar_azimuth: 52.9759250366361 \n                    \n                        s2:processing_baseline: 02.12 \n                    \n                        s2:snow_ice_percentage: 0.0 \n                    \n                        s2:vegetation_percentage: 0.219855 \n                    \n                        s2:thin_cirrus_percentage: 0.005976 \n                    \n                        s2:cloud_shadow_percentage: 0.001119 \n                    \n                        s2:nodata_pixel_percentage: 19.059283 \n                    \n                        s2:unclassified_percentage: 0.603301 \n                    \n                        s2:dark_features_percentage: 0.030829 \n                    \n                        s2:not_vegetated_percentage: 98.626834 \n                    \n                        s2:degraded_msi_data_percentage: 0.0 \n                    \n                        s2:high_proba_clouds_percentage: 0.127769 \n                    \n                        s2:reflectance_conversion_factor: 1.007352582888 \n                    \n                        s2:medium_proba_clouds_percentage: 0.29932 \n                    \n                        s2:saturated_defective_pixel_percentage: 0.0 \n                    \n                \n                \n        \n            stac_extensions: ['https://stac-extensions.github.io/eo/v1.0.0/schema.json', 'https://stac-extensions.github.io/sat/v1.0.0/schema.json', 'https://stac-extensions.github.io/projection/v1.0.0/schema.json'] \n        \n    \n            \n            \n        \n            \n                STAC Extensions\n            \n            \n                \n                    https://stac-extensions.github.io/eo/v1.0.0/schema.json\n                \n                    https://stac-extensions.github.io/sat/v1.0.0/schema.json\n                \n                    https://stac-extensions.github.io/projection/v1.0.0/schema.json\n                \n            \n        \n    \n            \n        \n            \n                Assets\n            \n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Aerosol optical thickness (AOT)\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R10m/T50JNL_20191021T020451_AOT_10m.tif \n                \n                    Title: Aerosol optical thickness (AOT) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 1 - Coastal aerosol - 60m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R60m/T50JNL_20191021T020451_B01_60m.tif \n                \n                    Title: Band 1 - Coastal aerosol - 60m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [1830, 1830] \n        \n            proj:transform: [60.0, 0.0, 499980.0, 0.0, -60.0, 6600040.0] \n        \n            gsd: 60.0 \n        \n            eo:bands: [{'name': 'B01', 'common_name': 'coastal', 'description': 'Band 1 - Coastal aerosol', 'center_wavelength': 0.443, 'full_width_half_max': 0.027}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 2 - Blue - 10m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R10m/T50JNL_20191021T020451_B02_10m.tif \n                \n                    Title: Band 2 - Blue - 10m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n            eo:bands: [{'name': 'B02', 'common_name': 'blue', 'description': 'Band 2 - Blue', 'center_wavelength': 0.49, 'full_width_half_max': 0.098}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 3 - Green - 10m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R10m/T50JNL_20191021T020451_B03_10m.tif \n                \n                    Title: Band 3 - Green - 10m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n            eo:bands: [{'name': 'B03', 'common_name': 'green', 'description': 'Band 3 - Green', 'center_wavelength': 0.56, 'full_width_half_max': 0.045}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 4 - Red - 10m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R10m/T50JNL_20191021T020451_B04_10m.tif \n                \n                    Title: Band 4 - Red - 10m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n            eo:bands: [{'name': 'B04', 'common_name': 'red', 'description': 'Band 4 - Red', 'center_wavelength': 0.665, 'full_width_half_max': 0.038}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 5 - Vegetation red edge 1 - 20m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R20m/T50JNL_20191021T020451_B05_20m.tif \n                \n                    Title: Band 5 - Vegetation red edge 1 - 20m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20.0, 0.0, 499980.0, 0.0, -20.0, 6600040.0] \n        \n            gsd: 20.0 \n        \n            eo:bands: [{'name': 'B05', 'common_name': 'rededge', 'description': 'Band 5 - Vegetation red edge 1', 'center_wavelength': 0.704, 'full_width_half_max': 0.019}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 6 - Vegetation red edge 2 - 20m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R20m/T50JNL_20191021T020451_B06_20m.tif \n                \n                    Title: Band 6 - Vegetation red edge 2 - 20m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20.0, 0.0, 499980.0, 0.0, -20.0, 6600040.0] \n        \n            gsd: 20.0 \n        \n            eo:bands: [{'name': 'B06', 'common_name': 'rededge', 'description': 'Band 6 - Vegetation red edge 2', 'center_wavelength': 0.74, 'full_width_half_max': 0.018}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 7 - Vegetation red edge 3 - 20m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R20m/T50JNL_20191021T020451_B07_20m.tif \n                \n                    Title: Band 7 - Vegetation red edge 3 - 20m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20.0, 0.0, 499980.0, 0.0, -20.0, 6600040.0] \n        \n            gsd: 20.0 \n        \n            eo:bands: [{'name': 'B07', 'common_name': 'rededge', 'description': 'Band 7 - Vegetation red edge 3', 'center_wavelength': 0.783, 'full_width_half_max': 0.028}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 8 - NIR - 10m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R10m/T50JNL_20191021T020451_B08_10m.tif \n                \n                    Title: Band 8 - NIR - 10m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n            eo:bands: [{'name': 'B08', 'common_name': 'nir', 'description': 'Band 8 - NIR', 'center_wavelength': 0.842, 'full_width_half_max': 0.145}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 9 - Water vapor - 60m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R60m/T50JNL_20191021T020451_B09_60m.tif \n                \n                    Title: Band 9 - Water vapor - 60m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [1830, 1830] \n        \n            proj:transform: [60.0, 0.0, 499980.0, 0.0, -60.0, 6600040.0] \n        \n            gsd: 60.0 \n        \n            eo:bands: [{'name': 'B09', 'description': 'Band 9 - Water vapor', 'center_wavelength': 0.945, 'full_width_half_max': 0.026}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 11 - SWIR (1.6) - 20m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R20m/T50JNL_20191021T020451_B11_20m.tif \n                \n                    Title: Band 11 - SWIR (1.6) - 20m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20.0, 0.0, 499980.0, 0.0, -20.0, 6600040.0] \n        \n            gsd: 20.0 \n        \n            eo:bands: [{'name': 'B11', 'common_name': 'swir16', 'description': 'Band 11 - SWIR (1.6)', 'center_wavelength': 1.61, 'full_width_half_max': 0.143}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 12 - SWIR (2.2) - 20m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R20m/T50JNL_20191021T020451_B12_20m.tif \n                \n                    Title: Band 12 - SWIR (2.2) - 20m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20.0, 0.0, 499980.0, 0.0, -20.0, 6600040.0] \n        \n            gsd: 20.0 \n        \n            eo:bands: [{'name': 'B12', 'common_name': 'swir22', 'description': 'Band 12 - SWIR (2.2)', 'center_wavelength': 2.19, 'full_width_half_max': 0.242}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 8A - Vegetation red edge 4 - 20m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R20m/T50JNL_20191021T020451_B8A_20m.tif \n                \n                    Title: Band 8A - Vegetation red edge 4 - 20m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20.0, 0.0, 499980.0, 0.0, -20.0, 6600040.0] \n        \n            gsd: 20.0 \n        \n            eo:bands: [{'name': 'B8A', 'common_name': 'rededge', 'description': 'Band 8A - Vegetation red edge 4', 'center_wavelength': 0.865, 'full_width_half_max': 0.033}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Scene classfication map (SCL)\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R20m/T50JNL_20191021T020451_SCL_20m.tif \n                \n                    Title: Scene classfication map (SCL) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20.0, 0.0, 499980.0, 0.0, -20.0, 6600040.0] \n        \n            gsd: 20.0 \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Water vapour (WVP)\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R10m/T50JNL_20191021T020451_WVP_10m.tif \n                \n                    Title: Water vapour (WVP) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: True color image\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R10m/T50JNL_20191021T020451_TCI_10m.tif \n                \n                    Title: True color image \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n            eo:bands: [{'name': 'B04', 'common_name': 'red', 'description': 'Band 4 - Red', 'center_wavelength': 0.665, 'full_width_half_max': 0.038}, {'name': 'B03', 'common_name': 'green', 'description': 'Band 3 - Green', 'center_wavelength': 0.56, 'full_width_half_max': 0.045}, {'name': 'B02', 'common_name': 'blue', 'description': 'Band 2 - Blue', 'center_wavelength': 0.49, 'full_width_half_max': 0.098}] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Thumbnail\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/QI_DATA/T50JNL_20191021T020451_PVI.tif \n                \n                    Title: Thumbnail \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['thumbnail'] \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: SAFE manifest\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/manifest.safe \n                \n                    Title: SAFE manifest \n                \n                \n                \n                    Media type: application/xml \n                \n                \n                    Roles: ['metadata'] \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Granule metadata\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/MTD_TL.xml \n                \n                    Title: Granule metadata \n                \n                \n                \n                    Media type: application/xml \n                \n                \n                    Roles: ['metadata'] \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: INSPIRE metadata\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/INSPIRE.xml \n                \n                    Title: INSPIRE metadata \n                \n                \n                \n                    Media type: application/xml \n                \n                \n                    Roles: ['metadata'] \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Product metadata\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/MTD_MSIL2A.xml \n                \n                    Title: Product metadata \n                \n                \n                \n                    Media type: application/xml \n                \n                \n                    Roles: ['metadata'] \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Datastrip metadata\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/DATASTRIP/DS_ESRI_20201004T043403_S20191021T021617/MTD_DS.xml \n                \n                    Title: Datastrip metadata \n                \n                \n                \n                    Media type: application/xml \n                \n                \n                    Roles: ['metadata'] \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: TileJSON with default rendering\n            \n            \n                href: https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=sentinel-2-l2a&item=S2A_MSIL2A_20191021T020451_R017_T50JNL_20201004T043402&assets=visual&asset_bidx=visual%7C1%2C2%2C3&nodata=0&format=png \n                \n                    Title: TileJSON with default rendering \n                \n                \n                \n                    Media type: application/json \n                \n                \n                    Roles: ['tiles'] \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Rendered preview\n            \n            \n                href: https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=sentinel-2-l2a&item=S2A_MSIL2A_20191021T020451_R017_T50JNL_20201004T043402&assets=visual&asset_bidx=visual%7C1%2C2%2C3&nodata=0&format=png \n                \n                    Title: Rendered preview \n                \n                \n                \n                    Media type: image/png \n                \n                \n                    Roles: ['overview'] \n                \n                \n                    Owner:  \n                \n                \n        \n            rel: preview \n        \n    \n            \n        \n    \n\n            \n        \n    \n            \n        \n            \n                Links\n            \n            \n                \n\n\n    \n    \n    \n        Link: \n        \n        \n            Rel: collection \n            Target: https://planetarycomputer.microsoft.com/api/stac/v1/collections/sentinel-2-l2a \n            \n                Media Type: application/json \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n        \n            Rel: parent \n            Target: https://planetarycomputer.microsoft.com/api/stac/v1/collections/sentinel-2-l2a \n            \n                Media Type: application/json \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n            Microsoft Planetary Computer STAC API\n        \n        \n            Rel: root \n            Target:  \n            \n                Media Type: application/json \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n        \n            Rel: self \n            Target: https://planetarycomputer.microsoft.com/api/stac/v1/collections/sentinel-2-l2a/items/S2A_MSIL2A_20191021T020451_R017_T50JNL_20201004T043402 \n            \n                Media Type: application/geo+json \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n        \n            Rel: license \n            Target: https://sentinel.esa.int/documents/247904/690755/Sentinel_Data_Legal_Notice \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n            Map of item\n        \n        \n            Rel: preview \n            Target: https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=sentinel-2-l2a&item=S2A_MSIL2A_20191021T020451_R017_T50JNL_20201004T043402 \n            \n                Media Type: text/html \n            \n            \n        \n        \n    \n\n            \n        \n    \n        \n    \n\n\n\nNow we’ve identified the STAC Item with the lowest cloud cover, we need to download it. This is where we head to the Assets property of the STAC Item where we see a series of href properties with hyperlinks to where that data is physically stored (here, this is in Azure Blob Storage as cloud-optimised GeoTIFF files).\nWe can print out the list of Assets associated with the STAC Item.\n\n# print assets properties of STAC Item\nleast_cloudy_s2.assets.keys()\n\ndict_keys(['AOT', 'B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B09', 'B11', 'B12', 'B8A', 'SCL', 'WVP', 'visual', 'preview', 'safe-manifest', 'granule-metadata', 'inspire-metadata', 'product-metadata', 'datastrip-metadata', 'tilejson', 'rendered_preview'])\n\n\n\n# lets look at the property for B02 - blue band reflectance\nleast_cloudy_s2.assets[\"B02\"]\n\n\n\n\n\n    \n    \n    \n        \n            \n                Asset: Band 2 - Blue - 10m\n            \n            \n                href: https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R10m/T50JNL_20191021T020451_B02_10m.tif \n                \n                    Title: Band 2 - Blue - 10m \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                    Roles: ['data'] \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:bbox: [499980.0, 6490240.0, 609780.0, 6600040.0] \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10.0, 0.0, 499980.0, 0.0, -10.0, 6600040.0] \n        \n            gsd: 10.0 \n        \n            eo:bands: [{'name': 'B02', 'common_name': 'blue', 'description': 'Band 2 - Blue', 'center_wavelength': 0.49, 'full_width_half_max': 0.098}] \n        \n    \n            \n        \n    \n\n\n\nLet’s download the red band data to a NumPy ndarray. The href points to a cloud-optmised GeoTIFF (COG) file stored in Azure Blob Storage (i.e. in the cloud). A COG file is similar to a regular GeoTIFF file, but it can receive HTTP requests to retrieve portions of data that correspond to a geographic extent and at a particular zoom level.\nPlanet (a commercial CubeSat company that make use of STAC and GeoTIFFs in their products) have a blog post that introduce COGs.\n\n\nRecap quiz\n\n\nWhy do these features of a cloud-optimised GeoTIFF make them more suited to working with big geospatial datasets than regular GeoTIFF files?\n\nAs geospatial datasets increase in size (e.g. satellites capturing data with ever finer spatial resolutions and with a higher cadence) the amount of data we’d need to store and read into memory increases. This might exceed our computer’s capacity or result in long runtimes for our program. COGs allow us to just read the data that corresponds to our area-of-interest and not the entire file. This means we can make use of the larger storage capacity of cloud providers and just retrieve the data we need.\n\nTo download the data for the red band we need to get its link or href\n\nleast_cloudy_red_href = least_cloudy_s2.assets[\"B04\"].href\nleast_cloudy_red_href\n\n'https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R10m/T50JNL_20191021T020451_B04_10m.tif'\n\n\n\nSigning links\nTo download data from the Planetary Computer the link needs to be “signed”. This allows Microsoft to manage traffic and use of the Planetary Computer’s resources in the cloud.\nThe planetary_computer package was imported as pc and has a sign() function we can use to sign links. You should see a code has been appended to the link to the COG - it has been signed.\n\nleast_cloudy_red_href = pc.sign(least_cloudy_red_href)\nleast_cloudy_red_href\n\n'https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/50/J/NL/2019/10/21/S2A_MSIL2A_20191021T020451_N0212_R017_T50JNL_20201004T043402.SAFE/GRANULE/L2A_T50JNL_A022608_20191021T021617/IMG_DATA/R10m/T50JNL_20191021T020451_B04_10m.tif?st=2023-03-03T06%3A46%3A56Z&se=2023-03-04T07%3A31%3A56Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-03-04T03%3A39%3A45Z&ske=2023-03-11T03%3A39%3A45Z&sks=b&skv=2021-06-08&sig=id6vJwk1341q6bqcpZ6jfUT9gMdNuN8G4F3i8SyFRXQ%3D'\n\n\n\n\nDownload COG data\nWe can read data from COG files in the cloud using rasterio in a similar way to how we’ve been reading local GeoTIFF files on our machine.\nWe use the rasterio.open() function to open a file connection to the COG in the cloud and use the connection objects read() method to read data from the COG in the cloud to a NumPy ndarray on our machine.\nHowever, to read in a subset of the data we use the window argument of read() and pass in a window object.\nA Window object is a rectangular subset of raster defined as Window(column_offset, row_offset, width, height).\nThe rasterio.windows module has a from_bounds() function which converts bounding coordinates to a Window object.\nrasterio has a features module which has as a bounds() function which takes in a GeoJSON geometry and returns a (left, bottom, right, top) bounding box which we can use to create a Window.\nHowever, our GeoJSON geometry will likely be in EPSG:4326 (geographic) coordinate system which could be different from the project system of the COG we’re trying to read data from. This requires us to use rasterio transform_bounds() function to transform our bounding box coordinates to the coordinates of the COG data.\nTo summarise this process:\n\nuse features.bounds() to convert GeoJSON to a bounding box.\nuse warp.transform_bounds() to convert the bounding box to the CRS of the COG data.\nuse windows.from_bounds() to convert the reprojected bounding box to a Window object.\npass the Window object to read() to read only data from the COG within the Window.\n\n# open a connection to the COG using its signed link\nwith rasterio.open(least_cloudy_red_href) as ds:\n    aoi_bounds = features.bounds(aoi_geometry)\n    warped_aoi_bounds = warp.transform_bounds(\"epsg:4326\", ds.crs, *aoi_bounds)\n    aoi_window = windows.from_bounds(transform=ds.transform, *warped_aoi_bounds)\n    meta = ds.meta\n    band_data = ds.read(1, window=aoi_window)\n\n# check the meta object for the COG metadata\nmeta\n\n{'driver': 'GTiff',\n 'dtype': 'uint16',\n 'nodata': None,\n 'width': 10980,\n 'height': 10980,\n 'count': 1,\n 'crs': CRS.from_epsg(32750),\n 'transform': Affine(10.0, 0.0, 499980.0,\n        0.0, -10.0, 6600040.0)}\n\n\n\n# let's visualise the data to check it looks ok\npx.imshow(band_data, color_continuous_scale=\"Reds\")\n\n\n\n\n\n\n\nRecap quiz\nCan you download and visualise near infrared reflectance from the same STAC Item? near infrared reflectance is band 8.\n## ADD CODE HERE ##\n\n\nanswer\n\nleast_cloudy_nir_href = least_cloudy_s2.assets[\"B08\"].href\nleast_cloudy_nir_href = pc.sign(least_cloudy_nir_href)\n\nwith rasterio.open(least_cloudy_nir_href) as ds:\n    aoi_bounds = features.bounds(aoi_geometry)\n    warped_aoi_bounds = warp.transform_bounds(\"epsg:4326\", ds.crs, *aoi_bounds)\n    aoi_window = windows.from_bounds(transform=ds.transform, *warped_aoi_bounds)\n    meta = ds.meta\n    band_data = ds.read(1, window=aoi_window)\n    \npx.imshow(band_data, color_continuous_scale=\"viridis\")"
  },
  {
    "objectID": "lab-6-self-guided.html#sentinel-2-and-amazon-web-services",
    "href": "lab-6-self-guided.html#sentinel-2-and-amazon-web-services",
    "title": "Introduction",
    "section": "Sentinel-2 and Amazon Web Services",
    "text": "Sentinel-2 and Amazon Web Services\nOne of the advantages of the STAC specification is that it’s a common format for describing spatiotemporal assets. This means we can repeat our workflow to retrieve data from other locations (e.g. other cloud providers). Let’s demonstrate this by downloading Sentinel-2 data for the same location and datetime from Amazon Web Services instead.\nFree Sentinel-2 cloud-optimised GeoTIFFs can be found on AWS here and the url for the STAC API is \"https://earth-search.aws.element84.com/v0\".\nFirst, we create a pystac_client.Client object and open the STAC API.\naws_catalog = pystac_client.Client.open(\n    \"https://earth-search.aws.element84.com/v0\"\n)\nA pystac_client.Client object has a get_collections() method which lists the STAC Collections within the STAC Catalog. Let’s use the aws_catalog’s get_collections() method to list of STAC Collections in AWS’s Earth Search.\n\n# search a catalog by listing its collections\ncollections = list(aws_catalog.get_collections())\n\nprint(f\"Number of collections: {len(collections)}\")\nprint(\"Collections IDs:\")\nfor collection in collections:\n    print(f\"- {collection.id}\")\n\nNumber of collections: 4\nCollections IDs:\n- sentinel-s2-l2a\n- sentinel-s2-l1c\n- sentinel-s2-l2a-cogs\n- landsat-8-l1-c1\n\n\nWe’re after the sentinel-s2-l2a-cogs collection. However, this is an example of how you can query a root catalog to find out what sub-catalogs it contains and could be useful for your analysis. For example, we can also see there is some Landsat 8 data available on AWS.\nLet’s create a search of AWS STAC Catalog using the sentinel-s2-l2a-cogs collection.\n\naws_search = aws_catalog.search(\n    collections=[\"sentinel-s2-l2a-cogs\"],\n    bbox=bbox,\n    datetime=time_of_interest,\n    query={\"eo:cloud_cover\": {\"lt\": 10}},\n)\n\n# Check how many items were returned\naws_items = aws_search.item_collection()\nprint(f\"Returned {len(aws_items)} Items\")\n\nReturned 2 Items\n\n\n\naws_items\n\n\n\n\n\n    \n    \n    \n        \n            \n                \n                    ItemCollection\n                \n            \n            \n                \n            \n\n            \n                \n                    \n                    \n                        Items\n                    \n                    \n                        \n\n\n    \n    \n    \n        \n            \n                Item: S2B_50JNL_20191026_0_L2A\n            \n            \n                ID: S2B_50JNL_20191026_0_L2A \n                \n                \n                    Bounding Box: [116.99979944683326, -31.72323454687613, 118.15866343531508, -30.727472475558006] \n                \n                \n                    Datetime: 2019-10-26 02:16:24+00:00 \n                \n                \n                    \n                        datetime: 2019-10-26T02:16:24Z \n                    \n                        platform: sentinel-2b \n                    \n                        constellation: sentinel-2 \n                    \n                        instruments: ['msi'] \n                    \n                        gsd: 10 \n                    \n                        view:off_nadir: 0 \n                    \n                        proj:epsg: 32750 \n                    \n                        sentinel:utm_zone: 50 \n                    \n                        sentinel:latitude_band: J \n                    \n                        sentinel:grid_square: NL \n                    \n                        sentinel:sequence: 0 \n                    \n                        sentinel:product_id: S2B_MSIL2A_20191026T020449_N0213_R017_T50JNL_20191026T054559 \n                    \n                        sentinel:data_coverage: 100 \n                    \n                        eo:cloud_cover: 0.64 \n                    \n                        sentinel:valid_cloud_cover: True \n                    \n                        created: 2020-08-23T07:56:25.769Z \n                    \n                        updated: 2020-08-23T07:56:25.769Z \n                    \n                \n                \n        \n            stac_extensions: ['eo', 'view', 'proj'] \n        \n    \n            \n            \n        \n            \n                STAC Extensions\n            \n            \n                \n                    eo\n                \n                    view\n                \n                    proj\n                \n            \n        \n    \n            \n        \n            \n                Assets\n            \n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Thumbnail\n            \n            \n                href: https://roda.sentinel-hub.com/sentinel-s2-l1c/tiles/50/J/NL/2019/10/26/0/preview.jpg \n                \n                    Title: Thumbnail \n                \n                \n                \n                    Media type: image/png \n                \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: True color image\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2B_50JNL_20191026_0_L2A/L2A_PVI.tif \n                \n                    Title: True color image \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [343, 343] \n        \n            proj:transform: [320, 0, 499980, 0, -320, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Original JSON metadata\n            \n            \n                href: https://roda.sentinel-hub.com/sentinel-s2-l2a/tiles/50/J/NL/2019/10/26/0/tileInfo.json \n                \n                    Title: Original JSON metadata \n                \n                \n                \n                    Media type: application/json \n                \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Original XML metadata\n            \n            \n                href: https://roda.sentinel-hub.com/sentinel-s2-l2a/tiles/50/J/NL/2019/10/26/0/metadata.xml \n                \n                    Title: Original XML metadata \n                \n                \n                \n                    Media type: application/xml \n                \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: True color image\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2B_50JNL_20191026_0_L2A/TCI.tif \n                \n                    Title: True color image \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10, 0, 499980, 0, -10, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 1 (coastal)\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2B_50JNL_20191026_0_L2A/B01.tif \n                \n                    Title: Band 1 (coastal) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [1830, 1830] \n        \n            proj:transform: [60, 0, 499980, 0, -60, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 2 (blue)\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2B_50JNL_20191026_0_L2A/B02.tif \n                \n                    Title: Band 2 (blue) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10, 0, 499980, 0, -10, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 3 (green)\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2B_50JNL_20191026_0_L2A/B03.tif \n                \n                    Title: Band 3 (green) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10, 0, 499980, 0, -10, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 4 (red)\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2B_50JNL_20191026_0_L2A/B04.tif \n                \n                    Title: Band 4 (red) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10, 0, 499980, 0, -10, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 5\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2B_50JNL_20191026_0_L2A/B05.tif \n                \n                    Title: Band 5 \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20, 0, 499980, 0, -20, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 6\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2B_50JNL_20191026_0_L2A/B06.tif \n                \n                    Title: Band 6 \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20, 0, 499980, 0, -20, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 7\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2B_50JNL_20191026_0_L2A/B07.tif \n                \n                    Title: Band 7 \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20, 0, 499980, 0, -20, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 8 (nir)\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2B_50JNL_20191026_0_L2A/B08.tif \n                \n                    Title: Band 8 (nir) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10, 0, 499980, 0, -10, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 8A\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2B_50JNL_20191026_0_L2A/B8A.tif \n                \n                    Title: Band 8A \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20, 0, 499980, 0, -20, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 9\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2B_50JNL_20191026_0_L2A/B09.tif \n                \n                    Title: Band 9 \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [1830, 1830] \n        \n            proj:transform: [60, 0, 499980, 0, -60, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 11 (swir16)\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2B_50JNL_20191026_0_L2A/B11.tif \n                \n                    Title: Band 11 (swir16) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20, 0, 499980, 0, -20, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 12 (swir22)\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2B_50JNL_20191026_0_L2A/B12.tif \n                \n                    Title: Band 12 (swir22) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20, 0, 499980, 0, -20, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Aerosol Optical Thickness (AOT)\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2B_50JNL_20191026_0_L2A/AOT.tif \n                \n                    Title: Aerosol Optical Thickness (AOT) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [1830, 1830] \n        \n            proj:transform: [60, 0, 499980, 0, -60, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Water Vapour (WVP)\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2B_50JNL_20191026_0_L2A/WVP.tif \n                \n                    Title: Water Vapour (WVP) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10, 0, 499980, 0, -10, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Scene Classification Map (SCL)\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2B_50JNL_20191026_0_L2A/SCL.tif \n                \n                    Title: Scene Classification Map (SCL) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20, 0, 499980, 0, -20, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n        \n    \n            \n        \n            \n                Links\n            \n            \n                \n\n\n    \n    \n    \n        Link: \n        \n        \n            Rel: self \n            Target: https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_50JNL_20191026_0_L2A \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n            Source STAC Item\n        \n        \n            Rel: derived_from \n            Target: s3://cirrus-v0-data-1qm7gekzjucbq/sentinel-s2-l2a/50/J/NL/2019/10/S2B_50JNL_20191026_0_L2A/S2B_50JNL_20191026_0_L2A.json \n            \n                Media Type: application/json \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n        \n            Rel: parent \n            Target: https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n        \n            Rel: collection \n            Target: https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n            Earth Search\n        \n        \n            Rel: root \n            Target:  \n            \n                Media Type: application/json \n            \n            \n        \n        \n    \n\n            \n        \n    \n        \n    \n\n                    \n                        \n\n\n    \n    \n    \n        \n            \n                Item: S2A_50JNL_20191021_1_L2A\n            \n            \n                ID: S2A_50JNL_20191021_1_L2A \n                \n                \n                    Bounding Box: [116.99979944683326, -31.72323454687613, 118.15866343531508, -30.814675185272606] \n                \n                \n                    Datetime: 2019-10-21 02:16:27+00:00 \n                \n                \n                    \n                        datetime: 2019-10-21T02:16:27Z \n                    \n                        platform: sentinel-2a \n                    \n                        constellation: sentinel-2 \n                    \n                        instruments: ['msi'] \n                    \n                        gsd: 10 \n                    \n                        view:off_nadir: 0 \n                    \n                        proj:epsg: 32750 \n                    \n                        sentinel:utm_zone: 50 \n                    \n                        sentinel:latitude_band: J \n                    \n                        sentinel:grid_square: NL \n                    \n                        sentinel:sequence: 1 \n                    \n                        sentinel:product_id: S2A_MSIL2A_20191021T020451_N0213_R017_T50JNL_20191021T053632 \n                    \n                        sentinel:data_coverage: 80.81 \n                    \n                        eo:cloud_cover: 0 \n                    \n                        sentinel:valid_cloud_cover: True \n                    \n                        created: 2020-08-23T07:49:11.094Z \n                    \n                        updated: 2020-08-23T07:49:11.094Z \n                    \n                \n                \n        \n            stac_extensions: ['eo', 'view', 'proj'] \n        \n    \n            \n            \n        \n            \n                STAC Extensions\n            \n            \n                \n                    eo\n                \n                    view\n                \n                    proj\n                \n            \n        \n    \n            \n        \n            \n                Assets\n            \n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Thumbnail\n            \n            \n                href: https://roda.sentinel-hub.com/sentinel-s2-l1c/tiles/50/J/NL/2019/10/21/1/preview.jpg \n                \n                    Title: Thumbnail \n                \n                \n                \n                    Media type: image/png \n                \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: True color image\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2A_50JNL_20191021_1_L2A/L2A_PVI.tif \n                \n                    Title: True color image \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [343, 343] \n        \n            proj:transform: [320, 0, 499980, 0, -320, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Original JSON metadata\n            \n            \n                href: https://roda.sentinel-hub.com/sentinel-s2-l2a/tiles/50/J/NL/2019/10/21/1/tileInfo.json \n                \n                    Title: Original JSON metadata \n                \n                \n                \n                    Media type: application/json \n                \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Original XML metadata\n            \n            \n                href: https://roda.sentinel-hub.com/sentinel-s2-l2a/tiles/50/J/NL/2019/10/21/1/metadata.xml \n                \n                    Title: Original XML metadata \n                \n                \n                \n                    Media type: application/xml \n                \n                \n                \n                    Owner:  \n                \n                \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: True color image\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2A_50JNL_20191021_1_L2A/TCI.tif \n                \n                    Title: True color image \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10, 0, 499980, 0, -10, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 1 (coastal)\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2A_50JNL_20191021_1_L2A/B01.tif \n                \n                    Title: Band 1 (coastal) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [1830, 1830] \n        \n            proj:transform: [60, 0, 499980, 0, -60, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 2 (blue)\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2A_50JNL_20191021_1_L2A/B02.tif \n                \n                    Title: Band 2 (blue) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10, 0, 499980, 0, -10, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 3 (green)\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2A_50JNL_20191021_1_L2A/B03.tif \n                \n                    Title: Band 3 (green) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10, 0, 499980, 0, -10, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 4 (red)\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2A_50JNL_20191021_1_L2A/B04.tif \n                \n                    Title: Band 4 (red) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10, 0, 499980, 0, -10, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 5\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2A_50JNL_20191021_1_L2A/B05.tif \n                \n                    Title: Band 5 \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20, 0, 499980, 0, -20, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 6\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2A_50JNL_20191021_1_L2A/B06.tif \n                \n                    Title: Band 6 \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20, 0, 499980, 0, -20, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 7\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2A_50JNL_20191021_1_L2A/B07.tif \n                \n                    Title: Band 7 \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20, 0, 499980, 0, -20, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 8 (nir)\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2A_50JNL_20191021_1_L2A/B08.tif \n                \n                    Title: Band 8 (nir) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10, 0, 499980, 0, -10, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 8A\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2A_50JNL_20191021_1_L2A/B8A.tif \n                \n                    Title: Band 8A \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20, 0, 499980, 0, -20, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 9\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2A_50JNL_20191021_1_L2A/B09.tif \n                \n                    Title: Band 9 \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [1830, 1830] \n        \n            proj:transform: [60, 0, 499980, 0, -60, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 11 (swir16)\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2A_50JNL_20191021_1_L2A/B11.tif \n                \n                    Title: Band 11 (swir16) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20, 0, 499980, 0, -20, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Band 12 (swir22)\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2A_50JNL_20191021_1_L2A/B12.tif \n                \n                    Title: Band 12 (swir22) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20, 0, 499980, 0, -20, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Aerosol Optical Thickness (AOT)\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2A_50JNL_20191021_1_L2A/AOT.tif \n                \n                    Title: Aerosol Optical Thickness (AOT) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [1830, 1830] \n        \n            proj:transform: [60, 0, 499980, 0, -60, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Water Vapour (WVP)\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2A_50JNL_20191021_1_L2A/WVP.tif \n                \n                    Title: Water Vapour (WVP) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [10980, 10980] \n        \n            proj:transform: [10, 0, 499980, 0, -10, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        \n            \n                Asset: Scene Classification Map (SCL)\n            \n            \n                href: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/J/NL/2019/10/S2A_50JNL_20191021_1_L2A/SCL.tif \n                \n                    Title: Scene Classification Map (SCL) \n                \n                \n                \n                    Media type: image/tiff; application=geotiff; profile=cloud-optimized \n                \n                \n                \n                    Owner:  \n                \n                \n        \n            proj:shape: [5490, 5490] \n        \n            proj:transform: [20, 0, 499980, 0, -20, 6600040, 0, 0, 1] \n        \n    \n            \n        \n    \n\n            \n        \n    \n            \n        \n            \n                Links\n            \n            \n                \n\n\n    \n    \n    \n        Link: \n        \n        \n            Rel: self \n            Target: https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2A_50JNL_20191021_1_L2A \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n            Source STAC Item\n        \n        \n            Rel: derived_from \n            Target: s3://cirrus-v0-data-1qm7gekzjucbq/sentinel-s2-l2a/50/J/NL/2019/10/S2A_50JNL_20191021_1_L2A/S2A_50JNL_20191021_1_L2A.json \n            \n                Media Type: application/json \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n        \n            Rel: parent \n            Target: https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n        \n            Rel: collection \n            Target: https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs \n            \n            \n        \n        \n    \n\n            \n                \n\n\n    \n    \n    \n        Link: \n        \n            Earth Search\n        \n        \n            Rel: root \n            Target:  \n            \n                Media Type: application/json \n            \n            \n        \n        \n    \n\n            \n        \n    \n        \n    \n\n                    \n                \n            \n        \n    \n\n\n\nInspecting the ItemCollection from AWS you notice similarities to the organisation of STAC Items as was returned from Microsoft’s Planetary Computer. One of the Assets is a Thumbnail which is a preview image in PNG format. This is useful if we want to visually inspect the satellite image without needing to download all the raw data. Let’s demonstrate how to download and visualise the Thumbnail image.\nWe can use io from the scikit-image package to read a PNG file.\nHere, we’ll get the first STAC Item from aws_items and access its Assets to get the link to the Thumbnail PNG file. Note, this thumbnail is for the Sentinel-2 tile and not just the area-of-interest for our field.\n\nimg = io.imread(aws_items[0].assets[\"thumbnail\"].href)\npx.imshow(img)"
  }
]